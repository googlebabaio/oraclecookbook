{"./":{"url":"./","title":"Introduction","keywords":"","body":"中年人的Oracle枸杞 记录一些日常工作中常用的部署安装、troubleshooting、performance tuning的过程。 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-12-17 17:24:54 "},"install/1.11gsingleasm.html":{"url":"install/1.11gsingleasm.html","title":"11g单机安装asm","keywords":"","body":" 0.概述 1. 主机准备 2. 创建用户和用户组 3. 创建目录和赋予权限 4. 系统配置 5. 配置cluster所需要的磁盘组或者裸设备 6. 安装grid组件 7. 安装oracle组件 8. 配置实例 9.常用命令 10.相关视图 0.概述 在单机上安装asm，和安装集群类似，用grid用户安装cluster相关软件，用oracle用户安装 1. 主机准备 1.1 主机名和网络配置 hostname vi /etc/sysconfig/network vi /etc/hosts 1.2 磁盘准备 1.3 如果为非桌面环境，考虑先安装桌面相应的包（非必须） yum -y groupinstall \"X Window System\" \"Chinese Support\" \"Desktop\" yum -y install xterm 1.4 安装相应的rpm包 yum -y install binutils compat-libstdc++-33 elfutils-libelf elfutils-libelf-devel glibc glibc-common glibc-devel gcc- gcc-c++ libaio-devel libaio libgcc libstdc++ libstdc++-devel make sysstat unixODBC unixODBC-devel pdksh ksh compat-libcap1 1.5 关闭防火墙等 service iptables stop chkconfig iptables off service NetworkManager stop chkconfig NetworkManager off 2. 创建用户和用户组 groupadd oinstall groupadd dba groupadd oper groupadd asmadmin groupadd asmdba groupadd asmoper useradd -g oinstall -G dba,asmdba,oper oracle useradd -g oinstall -G dba,asmadmin,asmdba,asmoper grid passwd grid passwd oracle 3. 创建目录和赋予权限 mkdir -p /u01/app/11.2.0.4/grid mkdir -p /u01/app/grid mkdir -p /u01/app/oracle/product/11.2.0.4/db_1 chown -R oracle:oinstall /u01/app chmod -R 775 /u01/app 4. 系统配置 4.1 内核参数 vi /etc/sysctl.conf fs.aio-max-nr = 1048576 fs.file-max = 6815744 kernel.shmall = 2097152 #kernel.shmmax = 4398046511104 //一般设置为系统内存75%单位是字节 kernel.shmmni = 4096 kernel.sem = 250 32000 100 128 net.ipv4.ip_local_port_range = 9000 65500 net.core.rmem_default = 262144 net.core.rmem_max = 4194304 net.core.wmem_default = 262144 net.core.wmem_max = 1048586 使内核设置立即生效： shell> /sbin/sysctl -p 4.2 limit限制 vi /etc/security/limits.conf oracle soft nproc 2047 oracle hard nproc 16384 oracle soft nofile 1024 oracle hard nofile 65536 oracle soft stack 10240 grid soft nproc 2047 grid hard nproc 16384 grid soft nofile 1024 grid hard nofile 65536 grid soft stack 1024 4.3 login限制 vi /etc/pam.d/login session required /lib64/security/pam_limits.so session required pam_limits.so 4.4 grid用户环境变量 export ORACLE_BASE=/u01/app/grid export ORACLE_HOME=/u01/app/11.2.0.4/grid export LD_LIBRARY_PATH=$ORACLE_HOME/lib:. export NLS_LANG=American_america.ZHS16GBK export PATH=$PATH:$ORACLE_HOME/bin:. export ORACLE_SID=+ASM 4.5 oracle用户环境变量 export ORACLE_BASE=/u01/app/oracle export ORACLE_HOME=/u01/app/oracle/product/11.2.0.4/db_1 export LD_LIBRARY_PATH=$ORACLE_HOME/lib:. export NLS_LANG=AMERICAN_AMERICA.ZHS16GBK export ORACLE_SID=nazeebo export PATH=$PATH:$ORACLE_HOME/bin:. 5. 配置cluster所需要的磁盘组或者裸设备 [root@nazeebo ~]# fdisk -l Disk /dev/vda: 42.9 GB, 42949672960 bytes 255 heads, 63 sectors/track, 5221 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x00020f78 Device Boot Start End Blocks Id System /dev/vda1 * 1 5222 41940992 83 Linux Disk /dev/vdb: 21.5 GB, 21474836480 bytes 16 heads, 63 sectors/track, 41610 cylinders Units = cylinders of 1008 * 512 = 516096 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x00000000 Disk /dev/vdc: 26.8 GB, 26843545600 bytes 16 heads, 63 sectors/track, 52012 cylinders Units = cylinders of 1008 * 512 = 516096 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x00000000 Disk /dev/vdd: 26.8 GB, 26843545600 bytes 16 heads, 63 sectors/track, 52012 cylinders Units = cylinders of 1008 * 512 = 516096 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x00000000 在这儿有几种方法： 5.1 用scsi的方式获取到设备的uuid 在这儿，我将用lvm的方式模拟 pvcreate /dev/vdb vgcreate ora_vg /dev/vdb lvcreate -L 2g -n lv_asm_ocr ora_vg lvcreate -L 20g -n lv_asm_data ora_vg lvcreate -L 20g -n lv_asm_arch ora_vg vgdisplay ora_vg 5.2 用raw的方式，有个坏处是系统重启后有可能会是的盘符错乱，使cluster起不来 所谓raw 设备，就是通过字符方式访问的设备，也就是读写设备不需要缓冲区。 在Linux 下，对磁盘值提供了块方式的访问。要想通过字符方式访问，必须配置raw 设备服务，并且Oracle 用户对这些raw 设备必须有访问的权限。 在2个节点上做如下操作： 1）修改/etc/udev/rules.d/60-raw.rules 文件 添加如下内容： ACTION==\"add\", KERNEL==\"vdb\",RUN+=\"/bin/raw /dev/raw/raw1 %N\" ACTION==\"add\", KERNEL==\"vdc\",RUN+=\"/bin/raw /dev/raw/raw2 %N\" ACTION==\"add\", KERNEL==\"vdd\",RUN+=\"/bin/raw /dev/raw/raw3 %N\" ACTION==\"add\",KERNEL==\"raw1\", OWNER=\"grid\", GROUP=\"oinstall\", MODE=\"660\" ACTION==\"add\",KERNEL==\"raw[2-3]\", OWNER=\"oracle\", GROUP=\"oinstall\", MODE=\"660\" 2） 重启服务： shell> start_udev Starting udev: [ OK ] 3） 查看raw设备： shell> raw -qa /dev/raw/raw1: bound to major 252, minor 16 /dev/raw/raw2: bound to major 252, minor 32 /dev/raw/raw3: bound to major 252, minor 48 shell> ls -lrt /dev/raw total 0 crw-rw---- 1 root disk 162, 0 May 9 14:30 rawctl crw-rw---- 1 oracle oinstall 162, 3 May 9 14:30 raw3 crw-rw---- 1 oracle oinstall 162, 2 May 9 14:30 raw2 crw-rw---- 1 grid oinstall 162, 1 May 9 14:30 raw1 5.3安装asmlib，用oracle 提供的操作系统层面的asm管理工具来进行asm磁盘的创建 6. 安装grid组件 [root@nazeebo softdb]# ll total 3664224 drwxr-xr-x 7 root root 4096 Aug 27 2013 database drwxr-xr-x 7 root root 4096 Aug 27 2013 grid -rw-r--r-- 1 root root 1395582860 May 9 14:40 p13390677_112040_Linux-x86-64_1of7.zip -rw-r--r-- 1 root root 1151304589 May 9 14:47 p13390677_112040_Linux-x86-64_2of7.zip -rw-r--r-- 1 root root 1205251894 May 9 14:53 p13390677_112040_Linux-x86-64_3of7.zip [root@nazeebo softdb]# [root@nazeebo softdb]# chown -R grid:oinstall grid [root@nazeebo softdb]# chown -R oracle:oinstall database/ [root@nazeebo softdb]# ll total 3664224 drwxr-xr-x 7 oracle oinstall 4096 Aug 27 2013 database drwxr-xr-x 7 grid oinstall 4096 Aug 27 2013 grid -rw-r--r-- 1 root root 1395582860 May 9 14:40 p13390677_112040_Linux-x86-64_1of7.zip -rw-r--r-- 1 root root 1151304589 May 9 14:47 p13390677_112040_Linux-x86-64_2of7.zip -rw-r--r-- 1 root root 1205251894 May 9 14:53 p13390677_112040_Linux-x86-64_3of7.zip [root@nazeebo softdb]# 用grid用户安装 6.1 图形化界面安装过程如图（仅列举关键的图）： p13390677_112040_Linux-x86-64_3of7.zip 根据提示 用root执行两个脚本 [root@nazeebo ~]# /u01/app/oraInventory/orainstRoot.sh Changing permissions of /u01/app/oraInventory. Adding read,write permissions for group. Removing read,write,execute permissions for world. Changing groupname of /u01/app/oraInventory to oinstall. The execution of the script is complete. [root@nazeebo ~]# /u01/app/11.2.0.4/grid/root.sh Performing root user operation for Oracle 11g The following environment variables are set as: ORACLE_OWNER= grid ORACLE_HOME= /u01/app/11.2.0.4/grid Enter the full pathname of the local bin directory: [/usr/local/bin]: Copying dbhome to /usr/local/bin ... Copying oraenv to /usr/local/bin ... Copying coraenv to /usr/local/bin ... Creating /etc/oratab file... Entries will be added to the /etc/oratab file as needed by Database Configuration Assistant when a database is created Finished running generic part of root script. Now product-specific root actions will be performed. Using configuration parameter file: /u01/app/11.2.0.4/grid/crs/install/crsconfig_params Creating trace directory LOCAL ADD MODE Creating OCR keys for user 'grid', privgrp 'oinstall'.. Operation successful. LOCAL ONLY MODE Successfully accumulated necessary OCR keys. Creating OCR keys for user 'root', privgrp 'root'.. Operation successful. CRS-4664: Node nazeebo successfully pinned. Adding Clusterware entries to upstart nazeebo 2018/05/09 16:11:36 /u01/app/11.2.0.4/grid/cdata/nazeebo/backup_20180509_161136.olr Successfully configured Oracle Grid Infrastructure for a Standalone Server [root@nazeebo ~]# 6.2 用asmca来创建asm磁盘组 切换到grid用户，用asmca图形化工具来创建asm磁盘供之后的database使用 安装过程如图（仅仅列出关键步骤） 用asmcmd也可以看见 [grid@nazeebo grid]$ asmcmd ASMCMD> lsdg State Type Rebal Sector Block AU Total_MB Free_MB Req_mir_free_MB Usable_file_MB Offline_disks Voting_files Name MOUNTED EXTERN N 512 4096 1048576 25600 25548 0 25548 0 N ARCH/ MOUNTED EXTERN N 512 4096 1048576 25600 25548 0 25548 0 N DATA/ MOUNTED EXTERN N 512 4096 1048576 20480 20421 0 20421 0 N OCR/ ASMCMD> 7. 安装oracle组件 将安装包解压在同一个目录 unzip p13390677_112040_Linux-x86-64_1of7.zip unzip p13390677_112040_Linux-x86-64_2of7.zip 安装过程如图（仅仅列出关键步骤） 根据提示 用root执行脚本 [root@nazeebo ~]# /u01/app/oracle/product/11.2.0.4/db_1/root.sh Performing root user operation for Oracle 11g The following environment variables are set as: ORACLE_OWNER= oracle ORACLE_HOME= /u01/app/oracle/product/11.2.0.4/db_1 Enter the full pathname of the local bin directory: [/usr/local/bin]: The contents of \"dbhome\" have not changed. No need to overwrite. The contents of \"oraenv\" have not changed. No need to overwrite. The contents of \"coraenv\" have not changed. No need to overwrite. Entries will be added to the /etc/oratab file as needed by Database Configuration Assistant when a database is created Finished running generic part of root script. Now product-specific root actions will be performed. Finished product-specific root actions. [root@nazeebo ~]# 8. 配置实例 8.1配置监听 因为用grid安装了cluster的组件用于asm管理，而这一步中，grid已经创建了监听，故不再需要新建监听了。 查看已经创建了的监听的状态 [grid@nazeebo ~]$ lsnrctl status LSNRCTL for Linux: Version 11.2.0.4.0 - Production on 10-MAY-2018 15:48:55 Copyright (c) 1991, 2013, Oracle. All rights reserved. Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521))) STATUS of the LISTENER ------------------------ Alias LISTENER Version TNSLSNR for Linux: Version 11.2.0.4.0 - Production Start Date 09-MAY-2018 16:15:18 Uptime 0 days 0 hr. 5 min. 38 sec Trace Level off Security ON: Local OS Authentication SNMP OFF Listener Parameter File /u01/app/11.2.0.4/grid/network/admin/listener.ora Listener Log File /u01/app/grid/diag/tnslsnr/nazeebo/listener/alert/log.xml Listening Endpoints Summary... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC1521))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=nazeebo)(PORT=1521))) Services Summary... Service \"+ASM\" has 1 instance(s). Instance \"+ASM\", status READY, has 1 handler(s) for this service... The command completed successfully 8.2dbca建库 安装过程如图（仅仅列出关键步骤） 9.常用命令 9.1检查crs相关的状态 因为是单机的，所以crsctl check crs和crsctl check cluster都无效 [grid@nazeebo ~]$ crsctl check css CRS-4529: Cluster Synchronization Services is online [grid@nazeebo ~]$ crsctl check has CRS-4638: Oracle High Availability Services is online [grid@nazeebo ~]$ crsctl check evm CRS-4533: Event Manager is online 9.2查看资源状态(nodeapps节点应用程序，ASM实例，数据库实例等) [grid@nazeebo ~]$ crsctl status res -t -------------------------------------------------------------------------------- NAME TARGET STATE SERVER STATE_DETAILS -------------------------------------------------------------------------------- Local Resources -------------------------------------------------------------------------------- ora.ARCH.dg ONLINE ONLINE nazeebo ora.DATA.dg ONLINE ONLINE nazeebo ora.LISTENER.lsnr ONLINE ONLINE nazeebo ora.OCR.dg ONLINE ONLINE nazeebo ora.asm ONLINE ONLINE nazeebo Started ora.ons OFFLINE OFFLINE nazeebo -------------------------------------------------------------------------------- Cluster Resources -------------------------------------------------------------------------------- ora.cssd 1 ONLINE ONLINE nazeebo ora.diskmon 1 OFFLINE OFFLINE ora.evmd 1 ONLINE ONLINE nazeebo ora.nazeebo.db 1 ONLINE ONLINE nazeebo Open 若资源以ora.开头的 用srvctl 来维护 否则用crsctl srvctl 维护的资源包括：ASM，database，instance，service，node applications ,listener,vip address,gns,scan vip ,scan listener ,oracle home, oc4j, server,server pool, asm disk group, asm file system 11.2的cluster的 正确启动集群： crsctl start cluster -all crsctl stop cluster -all crsctl check cluster -all 9.3查看各资源状态(nodeapps节点应用程序，ASM实例，数据库实例等) [grid@nazeebo ~]$ crs_stat -t -v Name Type R/RA F/FT Target State Host ---------------------------------------------------------------------- ora.ARCH.dg ora....up.type 0/5 0/ ONLINE ONLINE nazeebo ora.DATA.dg ora....up.type 0/5 0/ ONLINE ONLINE nazeebo ora....ER.lsnr ora....er.type 0/5 0/ ONLINE ONLINE nazeebo ora.OCR.dg ora....up.type 0/5 0/ ONLINE ONLINE nazeebo ora.asm ora.asm.type 0/5 0/ ONLINE ONLINE nazeebo ora.cssd ora.cssd.type 0/5 0/5 ONLINE ONLINE nazeebo ora.diskmon ora....on.type 0/10 0/5 OFFLINE OFFLINE ora.evmd ora.evm.type 0/10 0/5 ONLINE ONLINE nazeebo ora.nazeebo.db ora....se.type 0/2 0/1 ONLINE ONLINE nazeebo ora.ons ora.ons.type 0/3 0/ OFFLINE OFFLINE 9.4查看数据库的配置新 [grid@nazeebo ~]$ srvctl config database nazeebo [grid@nazeebo ~]$ srvctl config database -d nazeebo -a Database unique name: nazeebo Database name: nazeebo Oracle home: /u01/app/oracle/product/11.2.0.4/db_1 Oracle user: oracle Spfile: +DATA/nazeebo/spfilenazeebo.ora Domain: Start options: open Stop options: immediate Database role: PRIMARY Management policy: AUTOMATIC Database instance: nazeebo Disk Groups: DATA,ARCH Services: Database is enabled 9.5查看asm的配置信息 [grid@nazeebo ~]$ srvctl status asm ASM is running on nazeebo [grid@nazeebo ~]$ srvctl status asm -a ASM is running on nazeebo ASM is enabled. [grid@nazeebo ~]$ srvctl config asm -a ASM home: /u01/app/11.2.0.4/grid ASM listener: LISTENER Spfile: +OCR/asm/asmparameterfile/registry.253.975687351 ASM diskgroup discovery string: ASM is enabled. 9.6查看ocr的配置信息 [grid@nazeebo ~]$ ocrcheck Status of Oracle Cluster Registry is as follows : Version : 3 Total space (kbytes) : 262120 Used space (kbytes) : 152 Available space (kbytes) : 261968 ID : 1642006547 Device/File Name : /u01/app/11.2.0.4/grid/cdata/localhost/local.ocr Device/File integrity check succeeded Device/File not configured Device/File not configured Device/File not configured Device/File not configured Cluster registry integrity check succeeded Logical corruption check bypassed due to non-privileged user 10.相关视图 v$asm_disk(_stat) --查看磁盘及其状态信息 v$asm_diskgroup(_stat) --查看磁盘组及其状态信息 v$asm_operation --查看当前磁盘的操作信息 v$asm_client --返回当前连接的客户端实例信息 v$asm_file --返回asm文件的相关信息 v$asm_template --返回asm文件样本的相关信息 v$asm_alias --返回asm文件的别名信息 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-24 10:26:29 "},"rac/5.11gRAC-intsall.html":{"url":"rac/5.11gRAC-intsall.html","title":"11gRAC安装","keywords":"","body":" 一、准备工作 1. 服务器信息 2. 系统磁盘规划 3. 网络检查 4. 创建用户和组 5. 创建ssh免密码 5.1 使用工具ssh-copy-id 5.2 原始方法 5.3 做完之后必须验证 6. 创建目录 7. 配置环境变量 7.1 grid环境变量设置 7.2 oracle用户换机变量 8. 安装需要的系统包安装 9. 配置内核参数 9.1 编辑/etc/sysctl.conf 9.2 编辑/etc/security/limits.conf 9.3 编辑/etc/pam.d/login 10. 配置共享磁盘 10.1 方法1:直接raw 10.2 方法2：用wwid来绑定设备 10.3 一个实际的例子作为参考： 11. cvu验证 二、RAC安装 1. GI的安装 2. Oracle的安装 三、打补丁 1. 升级opatch: 2. GI打补丁： 2.1 检查opatch的版本 2.2 检查 Inventory有效性： 2.3 生成ocm.rsp文件 2.4 解压patch文件，给成grid的权限 2.5 用root用户执行如下 2.6 在第二个节点也执行【三、四、五】步骤 2.7 检查GI的打补丁情况 3. 数据库打补丁： 3.1 更新opatch的版本 3.2 检查 Inventory有效性： 3.3 apply补丁 3.4 检查打的补丁 四、创建实例 五、常用命令 一、准备工作 1. 服务器信息 机器名 public-ip private-ip virtual-ip testdb01 10.238.218.246 192.168.3.10 10.238.218.51 testdb02 10.238.218.236 192.168.3.11 10.238.218.25 机器名 public-ip private-ip virtual-ip testdb01 10.238.218.246 192.168.3.10 10.238.218.51 testdb02 10.238.218.236 192.168.3.11 10.238.218.25 2. 系统磁盘规划 位置 用处 说明 asm-ocr ocr盘 大小至少为2G asm-arch1 归档数据盘 用于存放归档日志等 asm-data1 数据文件盘 用于存放数据文件 3. 网络检查 检查网卡的编号是否一致、配置好的public-ip和private-ip是否能够ping通 /etc/hosts 参考配置如下： 127.0.0.1 localhost.localdomain localhost #Public 10.238.218.246 testdb01 10.238.218.236 testdb02 #Private 192.168.3.10 testdb01-priv 192.168.3.11 testdb02-priv #Virtual 10.238.218.51 testdb01-vip 10.238.218.25 testdb02-vip #SCAN 10.238.218.29 rac-cluster-scan 4. 创建用户和组 在两台节点分别操作： groupadd -g 501 oinstall groupadd -g 502 dba groupadd -g 503 asmadmin groupadd -g 504 asmoper groupadd -g 505 asmdba useradd -u 501 -g oinstall -G dba,asmdba oracle useradd -u 502 -g oinstall -G asmadmin,asmdba,asmoper,dba grid 执行检查： id oracle (检查所有节点的用户ID，对应的组ID是否都相同) id grid (检查所有节点的用户ID，对应的组ID是否都相同) id nobody (如果用户不存在需要新建nobody用户：usr/sbin/useradd nobody) 5. 创建ssh免密码 两种方法：第一种是使用工具ssh-copy-id，第二种是最原始的配置方法 5.1 使用工具ssh-copy-id 首先保证安装了 首先保证安装了包：openssh openssh-client 使用方法： 1.用 grid用户 和 oracle用户 生成ssh公钥和ssh私钥： ssh-keygen -t rsa 2.传输 su - grid ssh-copy-id -i ~/.ssh/id_rsa.pub grid@testdb01 ssh-copy-id -i ~/.ssh/id_rsa.pub grid@testdb02 su - oracle ssh-copy-id -i ~/.ssh/id_rsa.pub oracle@testdb01 ssh-copy-id -i ~/.ssh/id_rsa.pub oracle@testdb02 注意：ssh-copy-id 将key写到远程机器的 ~/ .ssh/authorized_key.文件中 5.2 原始方法 1.每台服务器以grid/Oracle身份执行： mkdir ~/.ssh chmod 700 ~/.ssh /usr/bin/ssh-keygen -t rsa /usr/bin/ssh-keygen -t dsa 2.testdb01节点以Oracle身份执行： cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys scp ~/.ssh/authorized_keys testdb02:~/.ssh/authorized_keys 3.testdb02节点以Oracle身份执行： cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys scp ~/.ssh/authorized_keys testdb01:~/.ssh/authorized_keys 5.3 做完之后必须验证 ssh testdb01 date ssh testdb02 date ssh testdb01-priv date ssh testdb02-priv date 6. 创建目录 mkdir -p /u01/app/grid chown -R grid:oinstall /u01/app/grid mkdir -p /u01/app/11.2.0/grid chown -R grid:oinstall /u01/app/11.2.0/grid mkdir -p /u01/app/oracle chown oracle:oinstall /u01/app/oracle chmod -R 775 /u01/ 7. 配置环境变量 7.1 grid环境变量设置 ORACLE_SID=+ASM1; export ORACLE_SID JAVA_HOME=/usr/local/java; export JAVA_HOME ORACLE_BASE=/u01/app/grid; export ORACLE_BASE ORACLE_HOME=/u01/app/11.2.0/grid; export ORACLE_HOME ORACLE_PATH=/u01/app/oracle/common/oracle/sql; export ORACLE_PATH ORACLE_TERM=xterm; export ORACLE_TERM NLS_DATE_FORMAT=\"YYYY-MON-DD HH24:MI:SS\"; export NLS_DATE_FORMAT PATH=.:${JAVA_HOME}/bin:${PATH}:$HOME/bin:$ORACLE_HOME/bin PATH=${PATH}:/usr/bin:/bin:/usr/bin/X11:/usr/local/bin PATH=${PATH}:/u01/app/common/oracle/bin export PATH LD_LIBRARY_PATH=$ORACLE_HOME/lib LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:$ORACLE_HOME/oracm/lib LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/lib:/usr/lib:/usr/local/lib export LD_LIBRARY_PATH CLASSPATH=$ORACLE_HOME/JRE CLASSPATH=${CLASSPATH}:$ORACLE_HOME/jlib CLASSPATH=${CLASSPATH}:$ORACLE_HOME/rdbms/jlib CLASSPATH=${CLASSPATH}:$ORACLE_HOME/network/jlib export CLASSPATH THREADS_FLAG=native; export THREADS_FLAG export TEMP=/tmp export TMPDIR=/tmp umask 022 7.2 oracle用户换机变量 ORACLE_SID=rac1; export ORACLE_SID ORACLE_HOSTNAME=testdb01; export ORACLE_HOSTNAME JAVA_HOME=/usr/local/java; export JAVA_HOME ORACLE_BASE=/u01/app/oracle; export ORACLE_BASE ORACLE_HOME=$ORACLE_BASE/product/11.2.0/db_1; export ORACLE_HOME ORACLE_TERM=xterm; export ORACLE_TERM NLS_DATE_FORMAT=\"YYYY-MON-DD HH24:MI:SS\"; export NLS_DATE_FORMAT PATH=.:${JAVA_HOME}/bin:${PATH}:$HOME/bin:$ORACLE_HOME/bin PATH=${PATH}:/usr/bin:/bin:/usr/bin/X11:/usr/local/bin PATH=${PATH}:/u01/app/common/oracle/bin export PATH LD_LIBRARY_PATH=$ORACLE_HOME/lib LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:$ORACLE_HOME/oracm/lib LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/lib:/usr/lib:/usr/local/lib export LD_LIBRARY_PATH CLASSPATH=$ORACLE_HOME/JRE CLASSPATH=${CLASSPATH}:$ORACLE_HOME/jlib CLASSPATH=${CLASSPATH}:$ORACLE_HOME/rdbms/jlib CLASSPATH=${CLASSPATH}:$ORACLE_HOME/network/jlib export CLASSPATH THREADS_FLAG=native; export THREADS_FLAG export TEMP=/tmp export TMPDIR=/tmp umask 022 8. 安装需要的系统包安装 配置本地源，然后用yum命令来安装 yum -y install compat-db compat-gcc-34 compat-gcc-34-c++ compat-libstdc++-33 glibc-* glibc-*.i686 libXpm-*.i686 libXp.so.6 libXt.so.6 libXtst.so.6 libgcc_s.so.1 libXp libaio-devel numactl numactl-devel unixODBC unixODBC-devel binutils compat-db control-center gcc gcc-c++ glibc glibc-common glibc-devel compat-libf2c compat-libgcc libstdc++ libstdc++-devel make sysstat libaio compat-libstdc++ compat-libstdc++-33 glibc-headers kernel-headers libXp openmotif22 libgomp libXmu elfutils-libelf libaio-devel unixODBC unixODBC-devel libgcc compat-libstdc++ elfutils-libelf elfutils-libelf-devel gcc gcc-c++ glibc glibc-common glibc-devel glibc-headers libaio libaio-devel libgcc libstdc++ libstdc++-devel make numactl-devel sysstat unixODBC unixODBC-devel compat-libcap1 9. 配置内核参数 9.1 编辑/etc/sysctl.conf kernel.shmall = 16777216 #单位是页 kernel.shmmax = 125829120 # 单位是byte kernel.shmmni = 4096 kernel.sem = 1000 143420 100 142 fs.file-max = 6815744 net.ipv4.ip_local_port_range = 9000 65500 net.core.rmem_default=1048576 net.core.rmem_max=4194304 net.core.wmem_default=262144 net.core.wmem_max=1048576 fs.aio-max-nr=1048576 执行 sysctl -p立即生效 9.2 编辑/etc/security/limits.conf grid soft nproc 2047 grid hard nproc 16384 grid soft nofile 65536 grid hard nofile 65536 oracle soft nproc 2047 oracle hard nproc 16384 oracle soft nofile 65536 oracle hard nofile 65536 9.3 编辑/etc/pam.d/login session required /lib64/security/pam_limits.so 10. 配置共享磁盘 提供两种方式的参考： 第一种是直接fdisk磁盘后，拿到/dev/xda1之类的盘，然后利用udev绑定raw 第二种是生产常用的获取固定的wwid来绑定udev设备 10.1 方法1:直接raw 在2个节点上做如下操作： 1.修改/etc/udev/rules.d/60-raw.rules 文件 添加如下内容： ACTION==\"add\", KERNEL==\"sdb1\",RUN+=\"/bin/raw /dev/raw/raw1 %N\" ACTION==\"add\", KERNEL==\"sdb2\",RUN+=\"/bin/raw /dev/raw/raw2 %N\" ACTION==\"add\", KERNEL==\"sdb3\",RUN+=\"/bin/raw /dev/raw/raw3 %N\" ACTION==\"add\", KERNEL==\"sdb4\",RUN+=\"/bin/raw /dev/raw/raw4 %N\" ACTION==\"add\",KERNEL==\"raw[1-3]\", OWNER=\"grid\", GROUP=\"oinstall\", MODE=\"660\" ACTION==\"add\",KERNEL==\"raw4\", OWNER=\"oracle\", GROUP=\"oinstall\", MODE=\"660\" 2.重启服务： [root@rac1 ~]# start_udev Starting udev: [ OK ] 3.查看raw设备： [root@rac1 ~]# ls -lrt /dev/raw total 0 crw-rw---- 1 oracle oinstall 162, 1 Sep 8 03:18 raw1 crw-rw---- 1 oracle oinstall 162, 3 Sep 8 03:18 raw2 crw-rw---- 1 oracle oinstall 162, 2 Sep 8 03:18 raw3 crw-rw---- 1 oracle oinstall 162, 2 Sep 8 03:18 raw4 crw-rw---- 1 oracle oinstall 162, 2 Sep 8 03:18 raw5 crw-rw---- 1 oracle oinstall 162, 2 Sep 8 03:18 raw6 10.2 方法2：用wwid来绑定设备 [root@vrh6 dev]# echo \"options=--whitelisted --replace-whitespace\" >> /etc/scsi_id.config [root@vrh6 dev]# for i in b c d e f ; > do > echo \"KERNEL==\\\"sd*\\\", BUS==\\\"scsi\\\", PROGRAM==\\\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/\\$name\\\", RESULT==\\\"`/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/sd$i`\\\", NAME=\\\"asm-disk$i\\\", OWNER=\\\"grid\\\", GROUP=\\\"asmadmin\\\", MODE=\\\"0660\\\"\" >> /etc/udev/rules.d/99-oracle-asmdevices.rules > done [root@vrh6 dev]# [root@vrh6 dev]# cat /etc/udev/rules.d/99-oracle-asmdevices.rules KERNEL==\"sd*\", BUS==\"scsi\", PROGRAM==\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\", RESULT==\"1ATA_VBOX_HARDDISK_VB09cadb31-cfbea255\", NAME=\"asm-diskb\", OWNER=\"grid\", GROUP=\"asmadmin\", MODE=\"0660\" KERNEL==\"sd*\", BUS==\"scsi\", PROGRAM==\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\", RESULT==\"1ATA_VBOX_HARDDISK_VB5f097069-59efb82f\", NAME=\"asm-diskc\", OWNER=\"grid\", GROUP=\"asmadmin\", MODE=\"0660\" KERNEL==\"sd*\", BUS==\"scsi\", PROGRAM==\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\", RESULT==\"1ATA_VBOX_HARDDISK_VB4e1a81c0-20478bc4\", NAME=\"asm-diskd\", OWNER=\"grid\", GROUP=\"asmadmin\", MODE=\"0660\" KERNEL==\"sd*\", BUS==\"scsi\", PROGRAM==\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\", RESULT==\"1ATA_VBOX_HARDDISK_VBdcce9285-b13c5a27\", NAME=\"asm-diske\", OWNER=\"grid\", GROUP=\"asmadmin\", MODE=\"0660\" KERNEL==\"sd*\", BUS==\"scsi\", PROGRAM==\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\", RESULT==\"1ATA_VBOX_HARDDISK_VB82effe1a-dbca7dff\", NAME=\"asm-diskf\", OWNER=\"grid\", GROUP=\"asmadmin\", MODE=\"0660\" [root@vrh6 dev]# /sbin/start_udev Starting udev: [ OK ] [root@vrh6 dev]# ls -l asm* brw-rw----. 1 grid asmadmin 8, 16 Jun 30 09:34 asm-diskb brw-rw----. 1 grid asmadmin 8, 32 Jun 30 09:34 asm-diskc brw-rw----. 1 grid asmadmin 8, 48 Jun 30 09:34 asm-diskd brw-rw----. 1 grid asmadmin 8, 64 Jun 30 09:34 asm-diske brw-rw----. 1 grid asmadmin 8, 80 Jun 30 09:34 asm-diskf 10.3 一个实际的例子作为参考： 10.3.1 查看设备信息 # multipath –ll mpathe (14f504e46494c4552356c626256732d466464302d6450647a) dm-8 OPNFILER,VIRTUAL-DISK size=30G features='0' hwhandler='0' wp=rw `-+- policy='round-robin 0' prio=1 status=active `- 16:0:0:0 sdg 8:96 active ready running mpathd (14f504e46494c45524e46337547362d48506c372d71596558) dm-7 OPNFILER,VIRTUAL-DISK size=10G features='0' hwhandler='0' wp=rw `-+- policy='round-robin 0' prio=1 status=active `- 14:0:0:0 sde 8:64 active ready running mpathc (14f504e46494c455263456c7146562d47564e772d794b6757) dm-6 OPNFILER,VIRTUAL-DISK size=100G features='0' hwhandler='0' wp=rw `-+- policy='round-robin 0' prio=1 status=active `- 11:0:0:0 sdb 8:16 active ready running mpathb (14f504e46494c4552626b705754662d41456c642d5970694d) dm-5 OPNFILER,VIRTUAL-DISK size=30G features='0' hwhandler='0' wp=rw `-+- policy='round-robin 0' prio=1 status=active `- 13:0:0:0 sdd 8:48 active ready running mpathg (14f504e46494c455246584a5474542d436c486a2d47463230) dm-13 OPNFILER,VIRTUAL-DISK size=10G features='0' hwhandler='0' wp=rw `-+- policy='round-robin 0' prio=1 status=active `- 15:0:0:0 sdf 8:80 active ready running mpathf (14f504e46494c45524731506e45522d374f58672d4c644354) dm-9 OPNFILER,VIRTUAL-DISK size=10G features='0' hwhandler='0' wp=rw `-+- policy='round-robin 0' prio=1 status=active `- 12:0:0:0 sdc 8:32 active ready running 10.3.2 获取设备号 # /sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/dm-1 10.3.3 配置设备名 采用下面的命令，添加到想要的udev的文件中，具体文件名见下面： KERNEL==\"dm-*\", PROGRAM=\"scsi_id --page=0x83 --whitelisted --device=/dev/%k\",RESULT==\"$uid\",NAME:=\"asm-ocr\" OWNER:=\"grid\", GROUP:=\"asmadmin\" ,MODE=\"0660\" 10.3.4 参考一个配置好的文件 # cat /etc/udev/rules.d/99-oracle-asmdisk.rules KERNEL==\"dm-*\", PROGRAM=\"scsi_id --page=0x83 --whitelisted --device=/dev/%k\",RESULT==\"$UID\",NAME:=\"asm-ocr\" OWNER:=\"grid\", GROUP:=\"asmadmin\" ,MODE=\"0660\" KERNEL==\"dm-*\", PROGRAM=\"scsi_id --page=0x83 --whitelisted --device=/dev/%k\",RESULT==\"$UID\",NAME:=\"asm-arch1\" OWNER:=\"grid\", GROUP:=\"asmadmin\" ,MODE=\"0660\" KERNEL==\"dm-*\", PROGRAM=\"scsi_id --page=0x83 --whitelisted--device=/dev/%k\",RESULT==\"$UID\",NAME:=\"asm-data1\" OWNER:=\"grid\", GROUP:=\"asmadmin\" ,MODE=\"0660\" 11. cvu验证 用grid用户执行： $ ./runcluvfy.sh stage -pre crsinst -n testdb01,testdb02 -fixup -verbose 二、RAC安装 1. GI的安装 略 2. Oracle的安装 略 三、打补丁 下载最新的PSU补丁11.2.0.4.8，GI补丁p21523375_112040_Linux-x86-64.zip 和数据库补丁p21352635_112040_Linux-x86-64.zip, opatch为p6880880_112000_Linux-x86-64.zip 打补丁步骤： 升级opatch 升级GI 升级数据库 1. 升级opatch: mv OPatch OPatch.bak unzip p6880880_112000_Linux-x86-64.zip -d /u01/app/11.2.0/grid chown -R grid:oinstall OPatch 2. GI打补丁： 2.1 检查opatch的版本 $ /u01/app/11.2.0/grid/OPatch/opatch version 2.2 检查 Inventory有效性： $ /u01/app/11.2.0/grid/OPatch/opatch lsinventory -detail -oh $ORACLE_HOME 2.3 生成ocm.rsp文件 用root用户在/u01/app/11.2.0/grid/OPatch/ocm/bin/下，用emocmrsp生成ocm.rsp文件（该文件会生成在当前目录） 将生成的ocm.rsp放到/u01/app/11.2.0/grid/OPatch/ocm/bin/目录下 2.4 解压patch文件，给成grid的权限 2.5 用root用户执行如下 # /u01/app/11.2.0/grid/OPatch/opatch auto /softdb/psu/21523375/ -oh /u01/app/11.2.0/grid -ocmrf /u01/app/11.2.0/grid/OPatch/ocm/bin/ocm.rsp 2.6 在第二个节点也执行【三、四、五】步骤 2.7 检查GI的打补丁情况 $ /u01/app/11.2.0/grid/OPatch/opatch lsinventory 3. 数据库打补丁： 3.1 更新opatch的版本 [root@dbtest1 psu]# cd /u01/app/oracle/product/11.2.0/db_1/ [root@dbtest1 db_1]# mv OPatch OPatch.bak [root@dbtest1 db_1]# cd /softdb/psu/ [root@dbtest1 psu]# unzip p6880880_112000_Linux-x86-64.zip -d /u01/app/oracle/product/11.2.0/db_1 [root@dbtest1 psu]# chown -R oracle:oinstall /u01/app/oracle/product/11.2.0/db_1/OPatch /u01/app/oracle/product/11.2.0/db_1/OPatch/opatch version 3.2 检查 Inventory有效性： $ /u01/app/oracle/product/11.2.0/db_1/OPatch/opatch lsinventory -detail -oh $ORACLE_HOME 3.3 apply补丁 1.unzip p20299013_112040_.zip cd 20299013 opatch prereq CheckConflictAgainstOHWithDetail -ph ./ 2.停数据库，停监听器，停em(emctl stop dbconsole) 用ps -ef | grep ora来检查是否还有遗留的进程，grid的不用管 3.unzip p20299013_112040_.zip cd 20299013 opatch apply 以上操作只需在一个节点执行即可。会有提示，先local再remote。 4. cd $ORACLE_HOME/rdbms/admin sqlplus /nolog SQL> CONNECT / AS SYSDBA SQL> STARTUP SQL> @catbundle.sql psu apply SQL> QUIT 5. cd $ORACLE_HOME/rdbms/admin sqlplus /nolog SQL> CONNECT / AS SYSDBA SQL> @utlrp.sql 3.4 检查打的补丁 /u01/app/oracle/product/11.2.0/db_1/OPatch/opatch lsinventory 四、创建实例 略 五、常用命令 参看：11gRAC常用命令 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-02-19 14:47:53 "},"install/26.apply-psu.html":{"url":"install/26.apply-psu.html","title":"RAC环境打PSU补丁步骤","keywords":"","body":" PSU补丁概述 打补丁步骤： GI打补丁 (grid用户下操作) 1. 升级opatch: 2. GI打补丁： 2.1 检查opatch的版本 2.2 检查 Inventory有效性： 2.3 生成ocm.rsp文件 2.4 解压patch文件，给成grid的权限 2.5 用root用户执行如下 2.6 在第二个节点也执行【2.1--2.5】步骤 2.7 检查GI的打补丁情况 数据库打补丁(oracle)： 1.更新opatch的版本 2.检查 Inventory有效性： 3.apply补丁(包括软件和实例) 4.检查打的补丁 PSU补丁概述 下载最新的PSU补丁和GI补丁 在本文例子用的补丁如下,实际情况请下载最新的补丁 因为RAC集群环境打补丁分别要给集群软件GI和数据库DB打补丁,所以对于的PSU补丁就是两个。另外补丁的时候需要OPatch这个工具，所以也需要下载最新的OPatch的补丁。 PSU补丁版本为11.2.0.4.181016 对应的GI补丁为:p28429134_112040_Linux-x86-64.zip 对应的数据库补丁为:p28204707_112040_Linux-x86-64.zip opatch为p6880880_112000_Linux-x86-64.zip 注意,在打database的psu的时候,如果没有建立实例,那么需要在两个节点分别打psu；如果创建了实例的，那么就可以直接remote打PSU补丁了。 打补丁步骤： GI打补丁 数据库打补丁 GI打补丁 (grid用户下操作) 1. 升级opatch: cd /app/11.2.0/grid mv OPatch OPatch.bak cd /softdb/psu unzip p6880880_112000_Linux-x86-64.zip -d /app/11.2.0/grid chown -R grid:oinstall OPatch 2. GI打补丁： 2.1 检查opatch的版本 $ /app/11.2.0/grid/OPatch/opatch version 2.2 检查 Inventory有效性： $ /app/11.2.0/grid/OPatch/opatch lsinventory -detail -oh $ORACLE_HOME 2.3 生成ocm.rsp文件 用root用户在/app/11.2.0/grid/OPatch/ocm/bin/下，用emocmrsp生成ocm.rsp文件（该文件会生成在当前目录） 将生成的ocm.rsp放到/app/11.2.0/grid/OPatch/ocm/bin/目录下 2.4 解压patch文件，给成grid的权限 2.5 用root用户执行如下 # /app/11.2.0/grid/OPatch/opatch auto /softdb/psu/28429134/ -oh /app/11.2.0/grid -ocmrf /app/11.2.0/grid/OPatch/ocm/bin/ocm.rsp 2.6 在第二个节点也执行【2.1--2.5】步骤 2.7 检查GI的打补丁情况 $ /app/11.2.0/grid/OPatch/opatch lsinventory 数据库打补丁(oracle)： 1.更新opatch的版本 [root@dbtest1 psu]# cd /app/oracle/product/11.2.0/ [root@dbtest1 db_1]# mv OPatch OPatch.bak [root@dbtest1 db_1]# cd /softdb/psu/ [root@dbtest1 psu]# unzip p6880880_112000_Linux-x86-64.zip -d /app/oracle/product/11.2.0 [root@dbtest1 psu]# chown -R oracle:oinstall /app/oracle/product/11.2.0/OPatch $ /app/oracle/product/11.2.0/OPatch/opatch version 2.检查 Inventory有效性： $ /app/oracle/product/11.2.0/OPatch/opatch lsinventory -detail -oh $ORACLE_HOME 3.apply补丁(包括软件和实例) 1.unzip p20299013_112040_.zip cd 28204707 opatch prereq CheckConflictAgainstOHWithDetail -ph ./ 2.停数据库，停监听器，停em(emctl stop dbconsole) 用ps -ef | grep ora来检查是否还有遗留的进程，grid的不用管 3.unzip p20299013_112040_.zip cd 28204707 opatch apply 以上操作只需在一个节点执行即可。会有提示，先local再remote。 4.给实例apply psu cd $ORACLE_HOME/rdbms/admin sqlplus /nolog SQL> CONNECT / AS SYSDBA SQL> STARTUP SQL> @catbundle.sql psu apply SQL> QUIT 5. cd $ORACLE_HOME/rdbms/admin sqlplus /nolog SQL> CONNECT / AS SYSDBA SQL> @utlrp.sql 4.检查打的补丁 /app/oracle/product/11.2.0/OPatch/opatch lsinventory Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-02-26 16:35:20 "},"dataguard/2.11g-single-asm-dg.html":{"url":"dataguard/2.11g-single-asm-dg.html","title":"11g单机环境下配置基于asm的dg","keywords":"","body":" 一、环境说明 二、采用技术说明 三、简要配置流程说明 四、详细搭建过程 4.1.环境准备 4.2 主备库都需要做的工作 4.3 主库准备工作 4.4 备库配置 4.5 配置dataguard 4.6 配置dg broker 4.7 切换操作 五、常用维护操作 5.1 备库退出redo应用状态 5.2 打开standby上的oracle库 5.3 查看Data Guard数据库运行在哪种模式下： 5.4 在备机查看日志序列和被应用的状态 5.5 查看Data Guard Standby 后台恢复进程是否正常 5.6 查询主库日志与备库是否一致 5.7 查看主库的归档日志的状态： 5.8 备库需要手工生成standby redo log吗？ 5.9 检查Standby数据库上是否归档有被应用： 一、环境说明 本文给出了 模拟asm环境下的dataguard搭建的过程，主备库均采用单实例+asm。 为了模拟可能遇到的情况，增加一个难度，让主备两边的磁盘组的名字不一样。 主库：+DATA , +ARCH 备库：+ORADATA ， +ARCHDATA dg搭建前提：主库已经创建了实例nazeebo，备库已经安装好数据库软件，两个库都采用asm进行管理。 如何在11g单机采用asm管理，请参考：11g单机安装asm 二、采用技术说明 序号 技术选型 理由说明 1 备库的恢复采用rman的全备+增量备份进行恢复 (1)考虑到数据量较大和网络因素，故而不采用man的特性duplicate for standby database；(2)考虑到一次时间窗口有不能完成dataguard备库的配置，故而可以考虑利用rman全备先去做恢复，然后在实际时间窗口前用追补归档的方式恢复备库，使得备库的数据尽可能和主库一致，减少采用的时间操作的时间窗口 2 使用dg broker进行配置 (1)因为要考虑到切换，而如果是采用命令行的方式可能会造成被初始化参数搞混，所以采用Oracle官方推荐的dg broker进行配置和管理 ；(2)考虑到配置的简洁性，采用dg broker仅仅需要配置很少的几个初始化参数 3 使用dg broker进行管理(如切换) 操作简单易用 三、简要配置流程说明 步骤 操作内容 备注 1 提前对备库进行数据库环境的安装以及相应目录的创建，不需要创建实例 此项工作不占用双活配置操作时间窗口 2 提前配置好主库以及备库的listener.ora 和 tnsnames.ora，并需要确保能互相之间tnsping通 此项工作不占用双活配置操作时间窗口 3 对主库和dataguard相关的初始化参数进行配置，并在主库上创建standby redo log group 4 生成主库的pfile.bak、创建standby control file 5 将主库的pfile.bak、standby control file和密码文件传到备库的相应位置上 6 在备库修改传过来的pfile.bak ，修改好用这个pfile将数据库启动到nomount状态，创建spfile，再重启备库到nomount状态 7 对主库进行rman全备 8 将主库的全备传输到备库上 9 在备库上利用rman进行standby control file的恢复，并将备库修改到mount状态 10 用rman对备库进行restore恢复，恢复完成后不打开备库 （在这个过场中如果主库没有停止业务，那么有可能会有新的归档日志生成，那么需要将新生成的归档日志传递过来并进行恢复） rman恢复不会生成redo log，这个在之后调用broker会帮这创建，这个时候的alert报错可以暂时不用去管 11 在主库做全备到在备库传输以及恢复这段时间，业务会产生相应的日志，将这些日志归档(归档日志)传输到备库，进行归档日志的追补 12 在备库打开日志应用 alter database recover managed standby database using current logfile disconnect; 13 在主库和备库分别打开dg_broker_start alter system set dg_broker_start=true; 14 在主库上登录dg broker的命令行管理端 dgmgrl sys/密码@tnsnames 15 创建配置信息 create configuration 16 添加备库的信息 add database 17 启用配置 这一步很重要，所有的参数修改都是在这个命令发出后才进行实质的修改，这个时候可以对alert日志进行跟踪 18 检查主库备库的alert日志是否有报错 19 测试主库与备库的dataguard是否配置成功 20 做一些switchover的相关测试 21 根据需要看是否需要加上归档日志的清理脚本等 四、详细搭建过程 4.1.环境准备 序号 角色 操作系统 数据库版本 主机名 实例名 tnsnames 备注 1 主库 Redhat6.8 11.2.0.4 nazeebo nazeebo nazeebo 2 备库 Redhat6.8 11.2.0.4 lowa lowa lowa 4.2 主备库都需要做的工作 4.2.1 监听配置 修改监听，配置静态监听，因为后面要用到的dg broker，所以静态监听中添加GLOBAL_DBNAME = 实例名_DGMGRL 这一个监听。又因为采用了asm管理，需要将ORACLE_HOME修改为oracle用户的ORACLE_HOME的路径（默认为grid用户的ORACLE_HOME路径） 主库监听 [grid@nazeebo admin]$ more listener.ora # listener.ora Network Configuration File: /u01/app/11.2.0.4/grid/network/admin/listener.ora # Generated by Oracle configuration tools. LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) (ADDRESS = (PROTOCOL = TCP)(HOST = nazeebo)(PORT = 1521)) ) ) SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (GLOBAL_DBNAME = nazeebo) (ORACLE_HOME = /u01/app/oracle/product/11.2.0.4/db_1) (SID_NAME = nazeebo) ) (SID_DESC = (GLOBAL_DBNAME = nazeebo_DGMGRL) (ORACLE_HOME = /u01/app/oracle/product/11.2.0.4/db_1) (SID_NAME = nazeebo) ) ) ADR_BASE_LISTENER = /u01/app/grid ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER=ON # line added by Agent 备库监听 [grid@lowa admin]$ more listener.ora # listener.ora Network Configuration File: /u01/app/11.2.0.4/grid/network/admin/listener.ora # Generated by Oracle configuration tools. LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) (ADDRESS = (PROTOCOL = TCP)(HOST = lowa)(PORT = 1521)) ) ) SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (GLOBAL_DBNAME = lowa) (ORACLE_HOME = /u01/app/oracle/product/11.2.0.4/db_1) (SID_NAME = lowa) ) (SID_DESC = (GLOBAL_DBNAME = lowa_DGMGRL) (ORACLE_HOME = /u01/app/oracle/product/11.2.0.4/db_1) (SID_NAME = lowa) ) ) ADR_BASE_LISTENER = /u01/app/grid ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER=ON # line added by Agent 4.2.2 配置tnsnames.ora 主库和备库保持一致 [oracle@nazeebo admin]$ cat tnsnames.ora # tnsnames.ora Network Configuration File: /u01/app/oracle/product/11.2.0.4/db_1/network/admin/tnsnames.ora # Generated by Oracle configuration tools. NAZEEBO = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = nazeebo)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = nazeebo) ) ) lowa = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = lowa)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = lowa) ) ) 4.3 主库准备工作 4.3.1 修改初始化参数 只需要配置简简单单的5个参数，就可以搞定（剩下的broker会帮你补全） 参数1：alter system set log_archive_dest_1='location=+ARCH MANDATORY'; 参数2：alter system set log_archive_dest_2='service=lowa LGWR ASYNC'; 参数3：alter system set db_file_name_convert='+ORADATA/lowa','+DATA/nazeebo','+ARCHDATA/lowa','+ARCH/nazeebo' scope=spfile; 参数4：alter system set log_file_name_convert='+ORADATA/lowa','+DATA/nazeebo','+ARCHDATA/lowa','+ARCH/nazeebo' scope=spfile; 参数5：alter system set standby_file_management=AUTO; 说明一点，参数1设置本地归档路径，只需要设置归档的磁盘，剩下的asm会自动帮助补全，以下为验证这一点： SQL> alter system set log_archive_dest_1='location=+ARCH MANDATORY'; System altered. SQL> SQL> alter system switch logfile; System altered. ============================================================ ASMCMD> pwd +arch/nazeebo/archivelog/2018_05_10 ASMCMD> ls thread_1_seq_59.260.975790853 thread_1_seq_60.261.975791067 thread_1_seq_61.262.975791103 thread_1_seq_62.263.975791337 ASMCMD> ls thread_1_seq_59.260.975790853 thread_1_seq_60.261.975791067 thread_1_seq_61.262.975791103 thread_1_seq_62.263.975791337 如上所示，修改为+ARCH后，磁盘组相对应的目录自己生成了全路径“+arch/nazeebo/archivelog/” 另外，对应xxx_file_convert的顺序可能会记错，有一个诀窍：对端写前面。 4.3.2 数据库级的一些设置 4.3.2.1 强制归档 alter database force logging; 4.3.2.2 启用最小补充日志 alter database add supplemental log data ; select supplemental_log_data_min min from v$database ; 需要注意的是，凡是启用或者关闭数据库级补充日志(包括最小补充日志和另外几种日志)都会导致共享池中所有SQL命令游标非法，也就是短期之内应解析会显著上升。 4.3.2.3 开启闪回 alter database flashback on; 后期如果有可能开启snapshot standby的话，建议开启 4.3.3 添加standby redo log 因为需要做switchover的切换，所以需要配置standby redo log，这个的组数是(redo的个数+1)*每组成员数，这个测试环境是3组redo log，所以就建立4组standby redo log就可以了。注意日志大小参照redo log的大小，保持一致。 RAC环境两个节点分别都要添加同样多的组数以及同样大小，用thread关键字来确定是哪一个节点。 RAC环境下，主库应该添加（N+1）*2组，其中N 为主库两个分区中配置的最大redolog 组数。 ALTER DATABASE ADD STANDBY LOGFILE GROUP 4 ('+DATA','+ARCH') size 50M; ALTER DATABASE ADD STANDBY LOGFILE GROUP 5 ('+DATA','+ARCH') size 50M; ALTER DATABASE ADD STANDBY LOGFILE GROUP 6 ('+DATA','+ARCH') size 50M; ALTER DATABASE ADD STANDBY LOGFILE GROUP 7 ('+DATA','+ARCH') size 50M; 4.3.4 创建pfile的备份 create pfile='/home/oracle/pfile.bak' from spfile; 4.3.5 创建standby control file alter database create standby controlfile as '/home/oracle/standby.ctl'; 4.3.6 传递相关文件到备库 传递pfile.bak到备库 传递密码文件到备库，并修改密码文件的名字为备库的实例 传递standby control file到备库 给一个主库的参考pfile [oracle@nazeebo ~]$ cat pfile.bak nazeebo.__db_cache_size=1929379840 nazeebo.__java_pool_size=16777216 nazeebo.__large_pool_size=33554432 nazeebo.__pga_aggregate_target=838860800 nazeebo.__sga_target=2516582400 nazeebo.__shared_io_pool_size=0 nazeebo.__shared_pool_size=503316480 nazeebo.__streams_pool_size=0 *.audit_file_dest='/u01/app/oracle/admin/nazeebo/adump' *.audit_trail='db' *.compatible='11.2.0.4.0' *.control_files='+DATA/nazeebo/controlfile/current.259.975754453','+ARCH/nazeebo/controlfile/current.256.975754453' *.db_block_size=8192 *.db_create_file_dest='+DATA' *.db_domain='' *.db_file_name_convert='+ORADATA/lowa','+DATA/nazeebo','+ARCHDATA/lowa','+ARCH/nazeebo' *.db_name='nazeebo' *.db_recovery_file_dest='+ARCH' *.db_recovery_file_dest_size=5218762752 *.diagnostic_dest='/u01/app/oracle' *.dispatchers='(PROTOCOL=TCP) (SERVICE=nazeeboXDB)' *.log_archive_dest_1='location=+ARCH MANDATORY' *.log_archive_dest_2='service=lowa LGWR ASYNC' *.log_archive_format='%t_%s_%r.dbf' *.log_file_name_convert='+ORADATA/lowa','+DATA/nazeebo','+ARCHDATA/lowa','+ARCH/nazeebo' *.open_cursors=300 *.pga_aggregate_target=838860800 *.processes=150 *.remote_login_passwordfile='EXCLUSIVE' *.sga_target=2516582400 *.standby_file_management='AUTO' *.undo_tablespace='UNDOTBS1' 4.4 备库配置 4.4.1 修改pfile文件 主要注意几个参数必需修改： 序号 修改参数 说明 1 .db_name 保持和主库的一致，只有一致了，物理standby才能正确配置。参考值：nazeebo 2 .db_unique_name 写备库的实例名，要区别主库的实例名。参考值：lowa 3 log_archive_dest_1 写本地的归档路径，参考值：Location= `+ARCHDATA` 4 log_archive_dest_2 写主库的归档路径，参考值：log_archive_dest_2='service=nazeebo LGWR ASYNC' 。注意：service对应的名字写的tnsnames的名字，而非实例名。 5 db_file_name_convert 参考值：db_file_name_convert='+DATA/nazeebo','+ORADATA/lowa','+ARCH/nazeebo','+ARCHDATA/lowa' 6 log_file_name_convert 同db_file_name_convert 7 audit_file_dest 填写实际想放置的位置，如果在RAC+ASM，需要先提前创建磁盘组，再修改 8 control_files 填写实际想放置的位置，如果在RAC+ASM，需要先提前创建磁盘组，再修改 给一个备库的参考pfile [oracle@lowa ~]$ cat pfile.bak lowa.__db_cache_size=1929379840 lowa.__java_pool_size=16777216 lowa.__large_pool_size=33554432 lowa.__pga_aggregate_target=838860800 lowa.__sga_target=2516582400 lowa.__shared_io_pool_size=0 lowa.__shared_pool_size=503316480 lowa.__streams_pool_size=0 *.audit_file_dest='/u01/app/oracle/admin/lowa/adump' *.audit_trail='db' *.compatible='11.2.0.4.0' *.control_files='+ORADATA/lowa/controlfile/control.ctl','+ARCHDATA/lowa/controlfile/control.ctl' *.db_block_size=8192 *.db_create_file_dest='+ORADATA' *.db_domain='' *.db_file_name_convert='+DATA/nazeebo','+ORADATA/lowa','+ARCH/nazeebo','+ARCHDATA/lowa' *.db_name='nazeebo' *.db_unique_name='lowa' *.db_recovery_file_dest='+ARCHDATA' *.db_recovery_file_dest_size=5218762752 *.diagnostic_dest='/u01/app/oracle' #*.dispatchers='(PROTOCOL=TCP) (SERVICE=lowaXDB)' *.log_archive_dest_1='location=+ARCHDATA MANDATORY' *.log_archive_dest_2='service=nazeebo LGWR ASYNC' *.log_archive_format='%t_%s_%r.dbf' *.log_file_name_convert='+DATA/nazeebo','+ORADATA/lowa','+ARCH/nazeebo','+ARCHDATA/lowa' *.open_cursors=300 *.pga_aggregate_target=838860800 *.processes=150 *.remote_login_passwordfile='EXCLUSIVE' *.sga_target=2516582400 *.standby_file_management='AUTO' *.undo_tablespace='UNDOTBS1' 4.4.2 创建相应的目录 备库有些目录是没有建立好的，需要提前建立，非asm的参考如下： 至少应该添加的目录有：数据文件、adump、归档日志、闪回区 mkdir -p /u01/app/oracle/oradata/nazeebo mkdir -p /u01/app/oracle/admin/nazeebo/adump mkdir -p /u01/app/oracle/archivelog/nazeebo mkdir -p /u01/app/oracle/fast_recovery_area/nazeebo 而asm管理的数据库，需要进入到相应的磁盘组创建或者用sqlplus的命令进行创建 用asmcmd命令添加目录，示例： shell> asmcmd shell> cd +DATA shell> mkdir archivelog shell> cd archivelog shell> mkdir nazeebo 用sql命令添加目录，示例： --首先添加nazeebo SQL> alter diskgroup datadg01 add directory '+datadg01/nazeebo/'; 然后添加datafile SQL> alter diskgroup datadg01 add directory '+datadg01/nazeebo/datafile'; 4.4.3 通过spfile启动数据库到nomount状态 sql> startup pfile=’/home/oracle/pfile.bak’ nomount 在这一步也可以顺便检查之前的目录有没有创建正确 启动完成无异常后，创建spfile，再以spfile的方式启动到nomount状态 sql> create spfile from pfile=’/home/oracle/pfile.bak’; sql> startup nomount 4.4.4 恢复standby控制文件 rman > restore controlfile from '/home/oracle/standby.ctl'; 这一步可以检查control放置的路径是否正确创建了的，如果有报错请troubleshooting 4.4.5 启动备库到mount状态 sql> alter database mount; 备注：只有在mount状态了，才可以利用rman进行数据库的恢复，来达到初始化的目的 4.5 配置dataguard 4.5.1 对主库进行全备，并将备份传递到备库 参考脚本如下： run { allocate channel c1 type disk; allocate channel c2 type disk; allocate channel c3 type disk; allocate channel c4 type disk; backup database format '/home/oracle/rmandir/FULL_%U.bak' ; backup archivelog all format '/home/oracle/rmandir/ARC_%U.bak'; release channel c1; release channel c2; release channel c3; release channel c4; } 备注： 在本文中，是在主备库创建了一个/home/oracle/rmandir目录，所有的备份文件都放在这个目录中。对于分配的channel，以根据实际的情况来进行增删。 另外，需要注意的是准备足够的磁盘空间进行rman的全备。 4.5.2 在备库进行restore的恢复 进入到备份的目录，然后在备库进行restore的恢复，参考脚本如下： rman> run { allocate channel c1 type disk; allocate channel c2 type disk; allocate channel c3 type disk; allocate channel c4 type disk; restore database ; release channel c1; release channel c2; release channel c3; release channel c4; } 因为restore会将主库创建的standby redo log也恢复到备库，所以务必保证主库初始化参数log_file_name_convert的正确性。 4.5.3 追补日志 RMAN> restore archivelog all; 4.5.4 在备库开始redo apply 在保证恢复正常之后，在备库开始redo apply SQL> alter database recover managed standby database using current logfile disconnect; 4.6 配置dg broker 以上的步骤只是完成了一半的配置，接下来需要利用dg broker完成剩下的一半工作 4.6.1 分别在主备库开启dg broker alter system set dg_broker_start=true; 4.6.2 在主库登陆dg broker 所有的操作都只需要在主库上进行 [oracle@nazeebo ~]$ dgmgrl sys/Oracle123@nazeebo DGMGRL for Linux: Version 11.2.0.4.0 - 64bit Production Copyright (c) 2000, 2009, Oracle. All rights reserved. Welcome to DGMGRL, type \"help\" for information. Connected. 4.6.3 创建配置信息 DGMGRL> create CONFIGURATION cfg_1 as PRIMARY DATABASE IS nazeebo CONNECT IDENTIFIER IS nazeebo; Configuration \"cfg_1\" created with primary database \"nazeebo\" 4.6.4 添加备库信息 DGMGRL> add DATABASE lowa as CONNECT IDENTIFIER IS lowa ; Database \" lowa \" added 4.6.5 启动配置 这一步是真正的使得配置生效 DGMGRL> ENABLE CONFIGURATION; 备注： 这个时候，最好将主库和备库的alert日志都打开进行跟踪 4.6.6 查看配置信息 DGMGRL> show CONFIGURATION; Configuration - cfg_1 Protection Mode: MaxPerformance Databases: nazeebo - Primary database lowa - Physical standby database Fast-Start Failover: DISABLED Configuration Status: SUCCESS DGMGRL> 4.6.7 测试配置是否正确生效 在主库进行测试表的创建，看在备库上是否能看到。 4.7 切换操作 通过broker可以很容易的坐到切换snapshot db，switchover切换，failover切换。 在以前通过命令切换的时候，首先要检查状态，然后在主库和备库都要敲命令才能实现以上说的切换。 而通过dg broker来进行切换，只需要一条命令： 1.查看当前配置信息 DGMGRL> show configuration Configuration - cfg_1 Protection Mode: MaxPerformance Databases: lowa - Primary database nazeebo - Physical standby database Fast-Start Failover: DISABLED Configuration Status: SUCCESS 2.做switchover DGMGRL> help switchover Switches roles between a primary and standby database Syntax: SWITCHOVER TO ; DGMGRL> switchover to lowa; Performing switchover NOW, please wait... Operation requires a connection to instance \"lowa\" on database \"lowa\" Connecting to instance \"lowa\"... Connected. New primary database \"lowa\" is opening... Operation requires startup of instance \"nazeebo\" on database \"nazeebo\" Starting instance \"nazeebo\"... ORACLE instance started. Database mounted. Database opened. Switchover succeeded, new primary is \"lowa\" 3.做完之后查看新的配置信息 DGMGRL> show configuration Configuration - cfg_1 Protection Mode: MaxPerformance Databases: lowa - Primary database nazeebo - Physical standby database Fast-Start Failover: DISABLED Configuration Status: SUCCESS 五、常用维护操作 5.1 备库退出redo应用状态 SQL> alter database recover managed standby database cancel; Database altered. PS：停止standby的redo应用，此时只是暂停redo 应用，并不是停止Standby 数据库，standby 仍然会保持接收只不过不会再应用接收到的归档，直到再次启动redo 应用为止。类似mysql里面的stop slave功能; 5.2 打开standby上的oracle库 SQL> alter database open; Database altered. 再应用redo日志 SQL> alter database recover managed standby database using current logfile disconnect ; 5.3 查看Data Guard数据库运行在哪种模式下： 在主库上： sql>select DATABASE_ROLE,PROTECTION_MODE,PROTECTION_LEVEL from v$database; DATABASE_ROLE PROTECTION_MODE PROTECTION_LEVEL ---------------- -------------------- -------------------- PRIMARY MAXIMUM PERFORMANCE MAXIMUM PERFORMANCE 在备库上： sql>select DATABASE_ROLE,PROTECTION_MODE,PROTECTION_LEVEL from v$database; DATABASE_ROLE PROTECTION_MODE PROTECTION_LEVEL ---------------- -------------------- -------------------- PHYSICAL STANDBY MAXIMUM PERFORMANCE MAXIMUM PERFORMANCE 5.4 在备机查看日志序列和被应用的状态 sql>select sequence#,applied from v$archived_log where applied=’YES’; 5.5 查看Data Guard Standby 后台恢复进程是否正常 在备机上： $ps -ef |grep mrp 输出结果应该有mrp的后台进程 5.6 查询主库日志与备库是否一致 SQL> select sequence# from v$archived_log where recid = (select max(recid) from v$archived_log) and applied = 'YES'; SQL> select sequence# from v$archived_log where recid = (select max(recid) from v$archived_log); 5.7 查看主库的归档日志的状态： SQL> select dest_name,status,error from v$archive_dest where rownum5.8 备库需要手工生成standby redo log吗？ 答案是不需要的，如果主库创建了standby redo log，那么在用rman进行备库生成的时候，备库自动会生成standby redo log 如下： SQL> select * from v$logfile; GROUP# STATUS TYPE MEMBER IS_REC ---------- -------------- -------------- -------------------------------------------------- ------ 1 ONLINE +ORADATA/lowa/onlinelog/group_1.265.975795255 NO 1 ONLINE +ARCHDATA/lowa/onlinelog/group_1.272.975795257 YES 2 ONLINE +ORADATA/lowa/onlinelog/group_2.266.975795257 NO 2 ONLINE +ARCHDATA/lowa/onlinelog/group_2.273.975795259 YES 3 ONLINE +ORADATA/lowa/onlinelog/group_3.267.975795259 NO 3 ONLINE +ARCHDATA/lowa/onlinelog/group_3.274.975795261 YES 7 STANDBY +ORADATA/lowa/onlinelog/group_7.257.975794407 NO 7 STANDBY +ARCHDATA/lowa/onlinelog/group_7.257.975794409 YES 4 STANDBY +ORADATA/lowa/onlinelog/group_4.258.975794407 NO 4 STANDBY +ARCHDATA/lowa/onlinelog/group_4.258.975794409 YES 5 STANDBY +ORADATA/lowa/onlinelog/group_5.259.975794411 NO 5 STANDBY +ARCHDATA/lowa/onlinelog/group_5.260.975794413 YES 6 STANDBY +ORADATA/lowa/onlinelog/group_6.260.975794411 NO 6 STANDBY +ARCHDATA/lowa/onlinelog/group_6.261.975794413 YES 14 rows selected. SQL> 5.9 检查Standby数据库上是否归档有被应用： 在备库上查看 是否有mrp进程 SQL> select process,status from v$managed_standby; PROCESS STATUS ------------------ ------------------------ ARCH CONNECTED ARCH CONNECTED ARCH CONNECTED ARCH CLOSING RFS IDLE RFS IDLE RFS IDLE MRP0 APPLYING_LOG 8 rows selected. 如果没有MRP进程，说明没有开启为 recover managed standby database状态 ; 可以使用 alter database recover managed standby database disconnect from session ; 开standby。 MRP就是备库的恢复进程 RFS进程接受从主库来的日志 没有MRP进程，说明备库没有处于恢复状态 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-27 13:33:28 "},"dataguard/3.11g-multinode-dg.html":{"url":"dataguard/3.11g-multinode-dg.html","title":"采用broker配置11g多节点dataguard(>=3节点)","keywords":"","body":"[grid@nazeebo admin]$ cat listener.ora # listener.ora Network Configuration File: /u01/app/11.2.0.4/grid/network/admin/listener.ora # Generated by Oracle configuration tools. LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) (ADDRESS = (PROTOCOL = TCP)(HOST = nazeebo)(PORT = 1521)) ) ) SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (GLOBAL_DBNAME = nazeebo) (ORACLE_HOME = /u01/app/oracle/product/11.2.0.4/db_1) (SID_NAME = nazeebo) ) (SID_DESC = (GLOBAL_DBNAME = nazeebo_DGMGRL) (ORACLE_HOME = /u01/app/oracle/product/11.2.0.4/db_1) (SID_NAME = nazeebo) ) ) ADR_BASE_LISTENER = /u01/app/grid ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER=ON # line added by Agent [grid@nazeebo admin]$ lsnrctl status LSNRCTL for Linux: Version 11.2.0.4.0 - Production on 10-MAY-2018 20:54:21 Copyright (c) 1991, 2013, Oracle. All rights reserved. Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521))) STATUS of the LISTENER ------------------------ Alias LISTENER Version TNSLSNR for Linux: Version 11.2.0.4.0 - Production Start Date 09-MAY-2018 16:15:18 Uptime 1 days 4 hr. 39 min. 2 sec Trace Level off Security ON: Local OS Authentication SNMP OFF Listener Parameter File /u01/app/11.2.0.4/grid/network/admin/listener.ora Listener Log File /u01/app/grid/diag/tnslsnr/nazeebo/listener/alert/log.xml Listening Endpoints Summary... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC1521))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=nazeebo)(PORT=1521))) Services Summary... Service \"+ASM\" has 1 instance(s). Instance \"+ASM\", status READY, has 1 handler(s) for this service... Service \"nazeebo\" has 1 instance(s). Instance \"nazeebo\", status READY, has 1 handler(s) for this service... Service \"nazeeboXDB\" has 1 instance(s). Instance \"nazeebo\", status READY, has 1 handler(s) for this service... The command completed successfully [grid@nazeebo admin]$ lsnrctl reload LSNRCTL for Linux: Version 11.2.0.4.0 - Production on 10-MAY-2018 20:54:27 Copyright (c) 1991, 2013, Oracle. All rights reserved. Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521))) The command completed successfully [grid@nazeebo admin]$ lsnrctl status LSNRCTL for Linux: Version 11.2.0.4.0 - Production on 10-MAY-2018 20:54:32 Copyright (c) 1991, 2013, Oracle. All rights reserved. Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521))) STATUS of the LISTENER ------------------------ Alias LISTENER Version TNSLSNR for Linux: Version 11.2.0.4.0 - Production Start Date 09-MAY-2018 16:15:18 Uptime 1 days 4 hr. 39 min. 14 sec Trace Level off Security ON: Local OS Authentication SNMP OFF Listener Parameter File /u01/app/11.2.0.4/grid/network/admin/listener.ora Listener Log File /u01/app/grid/diag/tnslsnr/nazeebo/listener/alert/log.xml Listening Endpoints Summary... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC1521))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=nazeebo)(PORT=1521))) Services Summary... Service \"+ASM\" has 1 instance(s). Instance \"+ASM\", status READY, has 1 handler(s) for this service... Service \"nazeebo\" has 2 instance(s). Instance \"nazeebo\", status UNKNOWN, has 1 handler(s) for this service... Instance \"nazeebo\", status READY, has 1 handler(s) for this service... Service \"nazeeboXDB\" has 1 instance(s). Instance \"nazeebo\", status READY, has 1 handler(s) for this service... Service \"nazeebo_DGMGRL\" has 1 instance(s). Instance \"nazeebo\", status UNKNOWN, has 1 handler(s) for this service... The command completed successfully [grid@nazeebo admin]$ Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-12-26 14:59:48 "},"dataguard/4.11g-doublerac-dg.html":{"url":"dataguard/4.11g-doublerac-dg.html","title":"采用备份复制的方式搭建11grac到rac的adg","keywords":"","body":" 一、环境说明 二、主备库网络相关过程 1.配置tnsnames 2.配置监听 3.测试 三、主库配置 1..确认主库为归档模式 2.将主库置为Force Logging 模式，在一个节点操作即可 3.打开最小补充日志 4.配置主库的初始化参数，在一个节点操作即可 5.创建standby redolog 6.传送密钥文件 四、备库配置过程 1.参数配置 2.备库删除文件 五、主库备份 1.主库备份数据和归档文件 2.主库备份成standby控制文件 六、备库还原 1.restore 数据库 2.关闭备库启动到mount standby 3.打开数据库 七、备库操作 1.设置为实时应用主库日志 2.启动另外一个节点 八、测试 九、部署过程中遇到的问题与解决办法 1.一个备库也是RAC环境的经验 2.在备库alter database open时，提示缺少某些日志 3.备库可以启动并打开，但无法接受主库的日志 4.第一次配置的时候，发现每次要在主库切一次日志，备库才能同步过去 5.当归档无法传递时，可在主库尝试执行（这样可达到重新连接的目的） 十、常用命令 一、环境说明 主备库均为11gRAC（11.2.0.4） 主库为生产环境，同一个数据库上部署了多套实例，故而不能启停监听 主备库创建时采用的是policy managed，三个实例其中两个被使用 备库因为是RAC环境，为了简化后期的操作步骤，已经在备库创建好了同主库数据库名一致的实例。创建实例时指定db_name、db_unique_name、service_name。在配置过程中只是删除物理文件，其他资源保留。 主库的数据文件磁盘组为ORADATA，备库的数据文件磁盘组为DATA 基于以上，用最传统是方式进行手工配置 主库 192.168.2.220 lowa1 192.168.2.222 lowa2 196.168.2.227 lowa3 196.168.2.229 pri-scan-ip 备库 192.168.66.30 nazeebo1 192.168.66.32 nazeebo2 192.168.66.34 nazeebo3 192.168.66.36 st-scan-ip vip 和 private ip习惯性忽略 数据库db_name：jwdlh，主库和备库的db_name一定要相同 db_unique_name：jwdlhdg，主库和备库的db_unique_name一定要设置成不一样 service_name：jwdlh，建议主库和备库设置成一样 数据文件路径：+DATA 归档路径：+ARCH 二、主备库网络相关过程 1.配置tnsnames 和所有的配置类似，主备库各自在tnsnames.ora中添加对应的tnsname 主库： jwdlh_pri = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.2.229)(PORT = 11521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = jwdlh) ) ) 备库： jwdlh_st = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.66.36)(PORT = 11521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = jwdlh) ) ) 2.配置监听 因为主库所在的主机上面有其他实例，所以监听不能重启，故而本文采用的方案为动态监听 3.测试 在主备库两端各节点执行如下命令： tnsping jwdlh_pri tnsping jwdlh_st 若以上均连接正常，则ok。否则进行troubleshooting，直至网络连接正常。 三、主库配置 1..确认主库为归档模式 archive log list; 如果不是归档模式，那么可以首先将数据库启动到MOUNT状态，然后执行： ALTER DATABASE ARCHIVELOG 2.将主库置为Force Logging 模式，在一个节点操作即可 SELECT FORCE_LOGGING FROM V$DATABASE ; ALTER DATABASE FORCE LOGGING; 3.打开最小补充日志 alter database add supplemental log data ; select supplemental_log_data_min min from v$database ; 4.配置主库的初始化参数，在一个节点操作即可 alter system set fal_client='jwdlh_pri' ; alter system set fal_server='jwdlh_st' ; alter system set log_archive_dest_2='service=jwdlh_st lgwr async valid_for=(online_logfiles,primary_role) db_unique_name=jwdlhdg' ; --这里的db_unique_name设置为备库的 alter system set log_archive_dest_state_1='ENABLE'; alter system set log_archive_dest_state_2='ENABLE'; alter system set standby_file_management='AUTO'; alter system set db_file_name_convert='+DATA/jwdlhdg','+ORADATA/jwdlh','+ARCH/jwdlhdg','+ARCH/jwdlh' scope=spfile; alter system set log_file_name_convert='+DATA/jwdlhdg','+ORADATA/jwdlh','+ARCH/jwdlhdg','+ARCH/jwdlh' scope=spfile; 5.创建standby redolog 推荐组数为(每线程的日志组数+1) X 最大线程数，大小和redo一致)： alter database add standby logfile thread 1 group 7 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 1 group 8 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 1 group 9 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 1 group 10 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 1 group 11 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 1 group 12 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 1 group 13 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 2 group 14 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 2 group 15 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 2 group 16 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 2 group 17 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 2 group 18 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 2 group 19 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 2 group 20 ('+ORADATA','+ARCH') size 512M; 6.传送密钥文件 用oracle用户传送密钥文件，在一个节点操作即可 scp $ORACLE_HOME/dbs/orapwjwdlh oracle@192.168.66.30:/u01/app/oracle/product/11.2.0/db/dbs/orapwjwdlhdg scp $ORACLE_HOME/dbs/orapwjwdlh oracle@192.168.66.32:/u01/app/oracle/product/11.2.0/db/dbs/orapwjwdlhdg scp $ORACLE_HOME/dbs/orapwjwdlh oracle@192.168.66.34:/u01/app/oracle/product/11.2.0/db/dbs/orapwjwdlhdg 四、备库配置过程 1.参数配置 alter system set fal_client='jwdlh_pri'; alter system set fal_server='jwdlh_st'; alter system set log_archive_dest_2='service=jwdlh_pri lgwr async valid_for=(online_logfiles,primary_role) db_unique_name=jwdlh' ; --这里的db_unique_name设置为主库的 alter system set log_archive_dest_state_1='ENABLE'; alter system set log_archive_dest_state_2='DEFER'; alter system set standby_file_management='AUTO'; alter system set db_file_name_convert='+ORADATA/jwdlh','+DATA/jwdlhdg','+ARCH/jwdlh','+ARCH/jwdlhdg' scope=spfile; alter system set log_file_name_convert='+ORADATA/jwdlh','+DATA/jwdlhdg','+ARCH/jwdlh','+ARCH/jwdlhdg' scope=spfile; 2.备库删除文件 由于备库当前已经创建了jwdlhdg的数据库，为了避免后期的各种服务注册，利用已经存在的jwdlhdg数据库，只是删除物理文件，其他资源保留。 srvctl stop database -d jwdlhdg asmcmd ASMCMD>cd +data/jwdlhdg ASMCMD>rm -rf datafile ASMCMD>rm -rf controlfile ASMCMD>rm -rf tempfile ASMCMD>rm -rf archivelog ASMCMD>rm -rf onlinelog 千万注意不要把里面的spfilexxx.ora给删除了！ 因为里面记录了之前备库所有的修改的初始化参数的信息。 五、主库备份 1.主库备份数据和归档文件 rman target / rman> sql' alter system archive log current'; RMAN> backup database format '/home/oracle/temp/full_%U'; RMAN> sql' alter system archive log current'; RMAN> backup archivelog all format '/home/oracle/temp/arch_%U'; 2.主库备份成standby控制文件 SQL>alter database create standby controlfile as '/home/oracle/temp/standby.ctl'; 传送文件至备库其中一个节点 scp * oracle@192.168.66.30:/home/oracle/temp/ 六、备库还原 在刚刚上传了文件的节点上操作即可 备库的操作顺序请注意！！！ 1.restore 数据库 export ORACLE_SID=jwdlhdg_1 rman target / RMAN>startup nomount RMAN>restore controlfile from '/home/oracle/temp/standby.ctl'; RMAN>alter database mount; RMAN>restore database; 2.关闭备库启动到mount standby SQL>shutdown immediate; SQL>startup nomount; SQL>alter database mount standby database; rman target / RMAN>recover database; 3.打开数据库 SQL>alter database open; 七、备库操作 1.设置为实时应用主库日志 SQL> alter database recover managed standby database using current logfile disconnect from session; 2.启动另外一个节点 grid$ srvctl start instance -d jwdlhdg -i jwdlhdg_2 在这个过程，会自动生成inst_2的redo和standby redo log 八、测试 在主库进行测试表的创建，看在备库上是否能实时看到。 九、部署过程中遇到的问题与解决办法 1.一个备库也是RAC环境的经验 备库如果也是RAC的话，为了简化后期的操作步骤，可以在备库创建好了同主库数据库名一致的实例。创建实例时指定db_name、db_unique_name、service_name。在配置过程中只是删除物理文件，其他资源保留。 备库的所有操作只需要启动一个实例进行操作即可，都执行完成且没有问题后，用grid用户去将第二个实例启动起来即可 2.在备库alter database open时，提示缺少某些日志 解决方法： 在主库执行： SELECT THREAD#, MAX (SEQUENCE#) AS \"LAST_APPLIED_LOG\" FROM GV$LOG_HISTORY GROUP BY THREAD#; 1 12 2 15 在备库执行： SELECT THREAD#, MAX (SEQUENCE#) AS \"LAST_APPLIED_LOG\" FROM GV$LOG_HISTORY GROUP BY THREAD#; 1 10 2 13 出现上述的情况时，需要手动将主库thread 1线程的10到12号和thread 2线程的13-15号日志复制到备库，可以参考以下方法，主库使用grid操作： grid$ asmcmd ASMCMD>cd +arch/jwdlh/archivelog ASMCMD>cp thread_1_12_376279112.log /home/oracle/temp ASMCMD>依次将所有缺少的日志复制出来 将复制出来的日志上传至备库 scp *.log oracle@192.168.66.30:/home/oracle/temp/ 备库上进行以下操作 SQL>ALTER DATABASE REGISTER LOGFILE '/home/oracle/temp/thread_1_12_376279112.log'; 依次将缺少的日志注册进来，在open备库 SQL>alter database open; 3.备库可以启动并打开，但无法接受主库的日志 select status,error from v$archive_dest where dest_name='LOG_ARCHIVE_DEST_2'; 查看报错信息，根据提示解决问题，直到status值为VALID 如：ORA-16047: 目标设置和备用之间的 DGID 不匹配； 看主库log_archive_dest_2参数设置，db_unique_name属性和standby的初始化参数db_unique_name是否一致 查看备库的log_archive_config有没有设置 如：ORA-16191: Primary log shipping client not logged on standby 查看这个参数remote_login_passwordfile是否为EXCLUSIVE； 确认备库的密码文件是否来自主库，可以尝试重新将主库的密码文件传送到备库 4.第一次配置的时候，发现每次要在主库切一次日志，备库才能同步过去 用以下命令查看 set lines 200 col ctime format a20 col value format a20 select inst_id,to_char(sysdate,'yyyymmdd hh24:mi:ss') ctime,name,value,datum_time from gv$dataguard_stats where name like '%lag'; 第一次发现没有lag 在主库重新执行一次alter system archive log current; 后，发现有了lag 接着查mrp进程，进程是有的： 接着去看standby redo log，发现了问题： 观察上图的结果，发现standby redo log全部都是线程1的，赶紧通过命令把thread 2的standby log补上，过了一会儿就同步了。 类似命令： alter database add standby logfile thread 2 group 14 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 2 group 15 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 2 group 16 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 2 group 17 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 2 group 18 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 2 group 19 ('+ORADATA','+ARCH') size 512M; alter database add standby logfile thread 2 group 20 ('+ORADATA','+ARCH') size 512M; 5.当归档无法传递时，可在主库尝试执行（这样可达到重新连接的目的） ALTER SYSTEM SET LOG_ARCHIVE_DEST_STATE_2=defer; ALTER SYSTEM SET LOG_ARCHIVE_DEST_STATE_2=ENABLE; 十、常用命令 ---查看备库缺少的归档日志，备库上查看 select thread#, low_sequence#, high_sequence# from gv$archive_gap; --手动切换日志 alter system switch logfile; --每个实例的日志都切换 alter system archive log current； --延迟10分钟应用归档 alter database recover managed standby database delay 10 disconnect from session; --取消延迟 alter database recover managed standby database nodelay disconnect from session; --使用standby redolog应用日志，这样可以实时接受主库日志 alter database recover managed standby database using current logfile disconnect from session; --取消日志应用 alter database recover managed standby database cancel; --使用归档日志应用日志，这种方式为10g的方式，只能等主库日志切换时才可以接受并应用主库的归档日志 alter database recover managed standby database disconnect from session; --查看主库归档传送和应用情况 select dest_name,archived_thread#,archived_seq#, applied_thread#,applied_seq#, db_unique_name from gv$archive_dest_status where status= 'valid'; --查看主备库的日志的应用情况是否一致 select thread#, max (sequence#) as \"last_applied_log\" from gv$log_history group by thread#; --查看dg各进程信息 select process,status,thread#,pid,sequence# from gv$managed_standby; --查看standby日志状态 select * from gv$standby_log; --在备库上查看日志传递和应用是否有lag set lines 200 col ctime format a20 col value format a20 select inst_id,to_char(sysdate,'yyyymmdd hh24:mi:ss') ctime,name,value,datum_time from gv$dataguard_stats where name like '%lag'; Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-24 10:25:23 "},"dataguard/rac2rac-dg-duplicate-spfile.html":{"url":"dataguard/rac2rac-dg-duplicate-spfile.html","title":"使用duplicate原生在线搭建11grac到rac的adg","keywords":"","body":" 一、概述 1.概述 2.环境介绍 二、配置过程： 1.配置监听与tnsnames 1.1 监听 1.2 配置tnsnames 2.主库配置第一次配置： 2.1 归档模式 2.2 主库本地的归档路径 2.3 force模式 2.4 检查 remote_login_passwordfile 2.5 修改主库参数 2.6 创建standby redo log 2.7 创建pfile传到备库 3.备库配置 3.1 两个节点都要创建adump的目录 3.2 从主库copy密码 3.3 使用一个临时的pfile文件将数据库启动到nomount状态即可 3.4 用nomount+pfile的方式启动备库实例1，并验证 3.5 在备库执行duplicate的脚本 4.duplicate完成后主库的操作 5.duplicate完成后备库的操作 5.1 修改参数 5.2 创建备库的spfile，并放入到asm磁盘组中 5.3 停临时监听,启动local listener 5.4 启动备库到mount,并开始追日志 5.5 查看主备库的alert日志以及相应视图 5.6 备库启动到active dataguard的模式 5.7 验证 5.8 启动备库的另外一个节点 5.9 将实例信息加入到grid中 一、概述 1.概述 本次配置是RAC to RAC的adg 采用的配置方式和以往不同的是，这次没有使用broker来辅助完成，而是采用rman+duplicate+spfile的方式进行配置。 特点是: 1.采用临时的pfile启动备库到nomount状态，真正的spfile内容写到rman脚本中 2.不需要提前创建备库的standby控制文件 3.使用nohup+网络传输的方式进行数据同步,不需要做备份 4.适合任何的通用环境 2.环境介绍 ############# standby ############## #Public 10.220.220.16 racdg1 10.220.220.17 racdg2 #Private 192.168.220.16 racdg1-priv 192.168.220.17 racdg2-priv #Virtual 10.220.220.18 racdg1-vip 10.220.220.19 racdg2-vip #SCAN 10.220.220.20 racdg-scan ############# primary ############## #Public 10.220.220.11 racnode1 10.220.220.12 racnode2 #Private 192.168.220.11 racnode1-priv 192.168.220.12 racnode2-priv #Virtual 10.220.220.13 racnode1-vip 10.220.220.14 racnode2-vip #SCAN 10.220.220.15 rac-scan 二、配置过程： 1.配置监听与tnsnames 1.1 监听 备库因为在安装cluster的过程中已经配置好监听local和scan的监听了，所以只需要配置一个临时的监听，用作主库连接备库用，即可。 临时监听： su - grid LISTENER_TMP = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = racdg1-vip)(PORT = 1521)) ) ) SID_LIST_LISTENER_TMP = (SID_LIST = (SID_DESC = (GLOBAL_DBNAME = racdg) (ORACLE_HOME = /u01/app/oracle/product/11.2.0/db_1) (SID_NAME = racdg1) ) ) 注意使用的时候，要把grid的local listener都关掉，只对其中一个节点使用临时监听 1.2 配置tnsnames 配置tnsname，需要用tnsping检查即可。 注意： 需要修改 2套环境的tnsnames，共计4个地方的tnsnames.ora 参考其中一个tnsnames.ora ORCL = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = rac-scan)(PORT = 11521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = orcl) ) ) RACDG = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = racdg-scan)(PORT = 11521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = racdg) ) ) RACDG1 = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = racdg1-vip)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = racdg) (INSTANCE_NAME = racdg1) ) ) 2.主库配置第一次配置： 2.1 归档模式 2.2 主库本地的归档路径 alter system set log_archive_dest_1='location=+ARCH' scope=both sid='*'; 2.3 force模式 $ sqlplus / as sysdba SQL> select FORCE_LOGGING from v$database; FOR --- NO 如果返回值为：NO，则需要执行以下操作；如果返回值为YES不需要执行以下操作 SQL> alter database force logging; Database altered. SQL> select FORCE_LOGGING from v$database; FOR --- YES 2.4 检查 remote_login_passwordfile remote_login_passwordfile 必须设置为EXCLUSIVE show parameter remote_login_passwordfile 2.5 修改主库参数 alter system set LOG_ARCHIVE_CONFIG='DG_CONFIG=(orcl,racdg)'; alter system set LOG_ARCHIVE_DEST_1='LOCATION=+ARCH VALID_FOR=(ALL_LOGFILES,ALL_ROLES) DB_UNIQUE_NAME=orcl' sid='*'; alter system set LOG_ARCHIVE_DEST_2='SERVICE=racdg LGWR ASYNC VALID_FOR=(ONLINE_LOGFILES,PRIMARY_ROLE) DB_UNIQUE_NAME=racdg compression=enable MAX_CONNECTIONS=4 reopen=60 ' sid='*'; alter system set FAL_SERVER='racdg'; alter system set STANDBY_FILE_MANAGEMENT=AUTO; alter system set LOG_ARCHIVE_DEST_STATE_2=defer sid='*'; 2.6 创建standby redo log ALTER DATABASE ADD STANDBY LOGFILE thread 1 group 9 '+ORADATA' SIZE 100M; ALTER DATABASE ADD STANDBY LOGFILE thread 1 group 10 '+ORADATA' SIZE 100M; ALTER DATABASE ADD STANDBY LOGFILE thread 1 group 11 '+ORADATA' SIZE 100M; ALTER DATABASE ADD STANDBY LOGFILE thread 1 group 12 '+ORADATA' SIZE 100M; ALTER DATABASE ADD STANDBY LOGFILE thread 2 group 13 '+ORADATA' SIZE 100M; ALTER DATABASE ADD STANDBY LOGFILE thread 2 group 14 '+ORADATA' SIZE 100M; ALTER DATABASE ADD STANDBY LOGFILE thread 2 group 15 '+ORADATA' SIZE 100M; ALTER DATABASE ADD STANDBY LOGFILE thread 2 group 16 '+ORADATA' SIZE 100M; ALTER DATABASE ADD STANDBY LOGFILE thread 1 group 17 '+ORADATA' SIZE 100M; ALTER DATABASE ADD STANDBY LOGFILE thread 2 group 18 '+ORADATA' SIZE 100M; 2.7 创建pfile传到备库 create pfile='/home/oracle/pfile.ora' from spfile; 这个仅用作参考 3.备库配置 3.1 两个节点都要创建adump的目录 mkdir -p /u01/app/oracle/admin/racdg/adump 3.2 从主库copy密码 3.3 使用一个临时的pfile文件将数据库启动到nomount状态即可 DB_NAME='orcl' DB_UNIQUE_NAME='racdg' DB_BLOCK_SIZE=8192 SGA_TARGET=8589934592 db_create_file_dest='' control_files='+ORADATA/racdg/controlfile/control01.ctl','+ORADATA/racdg/controlfile/control02.ctl' 3.4 用nomount+pfile的方式启动备库实例1，并验证 经过验证这个地方，其实是需要先建立一个临时监听的，不然连不上备库的实例1。 sqlplus sys/Oracle123@orcl as sysdba sqlplus sys/Oracle123@racdg1 as sysdba 3.5 在备库执行duplicate的脚本 vi create_sb.sh rman target sys/Oracle123@orcl auxiliary sys/Oracle123@racdg1 在后台执行，避免操作终端中断带来的影响 chmod +x create_sb.sh nohup sh create_sb.sh > c1.log & 执行完成后，顺便检查备库的standby redolog是否有了。 4.duplicate完成后主库的操作 修改主库参数，打开归档的开关 alter system set LOG_ARCHIVE_DEST_STATE_2=enable sid='*'; 5.duplicate完成后备库的操作 5.1 修改参数 alter system set LOG_ARCHIVE_CONFIG='DG_CONFIG=(orcl,racdg)'; alter system set LOG_ARCHIVE_DEST_1='LOCATION=+ORADATA VALID_FOR=(ALL_LOGFILES,ALL_ROLES) DB_UNIQUE_NAME=racdg'; alter system set LOG_ARCHIVE_DEST_2='SERVICE=orcl LGWR ASYNC VALID_FOR=(ONLINE_LOGFILE,PRIMARY_ROLE) DB_UNIQUE_NAME=orcl compression=enable MAX_CONNECTIONS=4 reopen=60 '; alter system set STANDBY_FILE_MANAGEMENT=AUTO; alter system set FAL_SERVER='orcl'; alter system set instance_number = 1 sid='racdg1' scope=spfile; alter system set instance_number = 2 sid='racdg2' scope=spfile; alter system set undo_tablespace='UNDOTBS1' sid='racdg1' scope=spfile; alter system set undo_tablespace='UNDOTBS2' sid='racdg2' scope=spfile; alter system set thread = 1 sid='racdg1' scope=spfile; alter system set thread = 2 sid='racdg2' scope=spfile; alter system set \"_trace_files_public\"=true scope=spfile; alter system set \"_optimizer_use_feedback\"=false scope=spfile; alter system set LOG_ARCHIVE_MAX_PROCESSES=4; 5.2 创建备库的spfile，并放入到asm磁盘组中 create pfile='/tmp/init.ora' from spfile; shutdown immediate; 对/tmp/init.ora里面的参数做修改,删除不必要的参数,再重新启动数据库并创建spfile到diskgroup中 startup pfile='/tmp/init.ora' nomount; create spfile='+ORADATA/racdg/spfile.ora' from pfile='/tmp/init.ora'; shutdown immediate; 修改pfile cd $ORACLE_HOME/dbs vi initracdg1.ora spfile='+ORADATA/RACDG/spfile.ora' 在另外一个节点也要做： vi initracdg2.ora 5.3 停临时监听,启动local listener 2个节点执行 su - grid lsnrctl stop listener_tmp lsnrctl start 5.4 启动备库到mount,并开始追日志 $ sqlplus / as sysdba SQL> STARTUP MOUNT SQL> ALTER DATABASE RECOVER MANAGED STANDBY DATABASE DISCONNECT FROM SESSION; 主库执行切换日志 $ sqlplus / as sysdba SQL> ALTER SYSTEM ARCHIVE LOG CURRENT; SQL> ALTER SYSTEM ARCHIVE LOG CURRENT; SQL> ALTER SYSTEM ARCHIVE LOG CURRENT; SQL> ALTER SYSTEM ARCHIVE LOG CURRENT; SQL> ALTER SYSTEM ARCHIVE LOG CURRENT; 5.5 查看主备库的alert日志以及相应视图 查看相应的视图 SQL> select * from v$archive_gap; SQL> select error from v$archive_dest; 这个地方出问题遇到的最多的就是当使用了非默认的1521端口后,local_listener没有配 5.6 备库启动到active dataguard的模式 在追了一段时间archivelog后，切换到实时应用redo SQL> alter database recover managed standby database cancel; SQL> alter database open; SQL> ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT FROM SESSION; 注意！如果打开报错如下: SQL> alter database recover managed standby database cancel; Database altered. SQL> alter database open; alter database open * ERROR at line 1: ORA-10458: standby database requires recovery ORA-01152: file 1 was not restored from a sufficiently old backup ORA-01110: data file 1: '+DATA/tyqxdg/datafile/system.260.1000300965' 那么就很明显需要看下是不是主库的日志没有传过来了，去看这个视图： select error from v$archive_dest; 5.7 验证 SQL> SELECT thread#,max(sequence#) from v$archived_log where applied='YES' GROUP BY THREAD#; SQL> select * from v$archive_gap; 5.8 启动备库的另外一个节点 $ sqlplus / as sysdba SQL> startup; 5.9 将实例信息加入到grid中 $ srvctl add database -d racdg -o $ORACLE_HOME -p +ORADATA/racdg/spfile.ora -r physical_standby $ srvctl add instance -d racdg -n racdg1 -i racdg1 $ srvctl add instance -d racdg -n racdg2 -i racdg2 注意：将备节点的数据库加入到CRS中进行管理，但CRS在启动后并不会自动对其追加归档，在CRS重启后需要手动执行追加日志的操作，命令如下： SQL> ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT FROM SESSION; 至此，搭建RAC到RAC的adg完成。 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-02-22 22:56:01 "},"rac/14.11gRAC-backend-process.html":{"url":"rac/14.11gRAC-backend-process.html","title":"11gRAC进程详解","keywords":"","body":" 一、RAC后台进程 1. LMON 2. LMSn:Lock Monitor Services 3. LCK:Lock Process 4. LMD:Lock Monitor Deamon Process 5. DIAG:Diagnostic Deamon 二、RAC服务进程 1. CRS-集群资源服务(cluster ready services) 2. CSS-集群同步服务(Cluster Synchronization Service) 3. EVMD事件管理服务(Event Management) 4. ONS-事件的发布及订阅服务(Oracle Notification Service) 5. OCR- Oracle Cluster Register 6. Voting Disk 表决磁盘 一、RAC后台进程 1. LMON LMON:LOCK Monitor Processes 也被称为Global enqueue service monitor 监控整个集群状况，维护GCS的内存结构 监控非正常终止的进程和实例 当实例离开和加入集群时，锁和资源的重新配置 管理全局的锁和资源 监控全局的锁资源、处理死锁和阻塞 2. LMSn:Lock Monitor Services 也称作GCS（Global Cache Services）processes LMS进程主要用来管理集群内数据库的访问，并在不同实例的buffer cache中传输块镜像，当在某个数据块上 发生一致性读时，LMS负责回滚该数据块，并将它copy到请求的实例上 每个RAC节点至少有2个LMS进程 3. LCK:Lock Process LCK进程主要用来管理实例间资源请求和跨实例调用操作，调用操作包括数据字典等对像访问，并处理非 CACEH FUSION的CHACE资源请求，（例如dictionary cache或row cache的请求） 由于LMS进程负责主要的锁管理功能，所以每个实例只有一个LCK进程 4. LMD:Lock Monitor Deamon Process LMD进程主要管理对全局队列和资源的访问，并更新相应队列状态，处理来自于其它实例的资源请，每一个全局队列的当前状态存储在相应的实例共享内存中，该状态表明该实例具有相应的权利使用该资源，一个实例master的共享内存中存在一个特殊的队列，该队列记录来自其它远程实例的资源请求，当远程实例的LMD进程发出一个资源请求时，该请求指向master实例的LMD，当master实例的LMD进程受到该请求后，在共享内存中的特殊队列中监测该资源是否有无效，如果有效LMD进程更新该资源对列的状态，并通知请求资源的LMD进程该资源队列可以使用了，如果资源队列正被其它实例使用或当前无效，则LMD进程通知正在使用中的实例的LMD进程应用释放该资源，等资源释放变得有效时，master实例的LMD进程更新该资源队列的状态，并通知请求资源实例的LMD进程，该资源队列可以使用了 5. DIAG:Diagnostic Deamon oracle10g新的后台进程 例行对实例的健康情况进行监控，同时也监控实例是否挂起或者出现死锁 收集实例和进程出错时的关键诊断信息 这个进程会更新alert日志文件，写入一些重要告警信息 二、RAC服务进程 1. CRS-集群资源服务(cluster ready services) 管理集群内高可用操作的基本程序 CRS管理的任何事务被称之为资源 数据库、实例、监听、虚拟IP、应用进程等等 CRS是跟据存储于OCR中的资源配置信息来管理这些资源 当一资源的状态改变时，CRS进程生成一个事件 2. CSS-集群同步服务(Cluster Synchronization Service) 管理集群节点的成员资格 控制哪 个结点为集群的成员、节点在加入或离开集群时通知集群成员来控制集群配置信息 此进程发生故障导致集群重启 3. EVMD事件管理服务(Event Management) 事件管理守护进程 发布CRS创建事件的后台进程 4. ONS-事件的发布及订阅服务(Oracle Notification Service) 通信的快速应用通知事件的发布及订阅服务 5. OCR- Oracle Cluster Register 集群注册文件，记录每个节点的相关信息 保存RAC集群的各种资源信息 类似于windows注册表 存储于共享磁盘上，所有实例共享 默认有2个互备磁盘 6. Voting Disk 表决磁盘 仲裁机制用于仲裁多个节点向共享节点财时写的行为，避免发生冲突 存储于共享磁盘上，所有实例共享 用于确定各个实例的关系 当有节点失效时，通过voting disk来决定驱逐哪个实例 默认有3个互备磁盘 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-24 10:27:35 "},"rac/8.11gR2RAC-option-intro.html":{"url":"rac/8.11gR2RAC-option-intro.html","title":"11gR2 RAC各组件","keywords":"","body":" Oracle集群件组件 集群就绪服务——CRSd 集群同步服务——OCSSd 事件管理记录器——EVMd 进程监控器——OPROCd Oracle通知服务——ONS 11gR2中的集群件启动进程——OHASd 集群注册表——OCR Oracle本地注册表——OLR 表决磁盘 虚拟IP：在公共IP子网中配置这个IP，监听器将会被配置为监听VIP，而不是公共IP。 单一客户端访问名称——SCAN Oracle内核组件 全局资源目录——GRD LMS——全局和缓存服务进程 LMON——全局队列服务监控器 LMD——全局队列服务守护进程 LCK0——实例队列进程 DIAG Oracle集群件组件 Oracle集群件的后台进程和服务是CRSd、OCSSd、OPROCd、EVMd和ONS 另外Oracle集群件还包括OCR及表决磁盘。 集群就绪服务——CRSd 它为Oracle集群件提供了高可用性的框架，并管理集群资源的状态：启动、停止、监视集群资源，并把发生故障的集群资源重定位到集群中的可用节点。 集群资源包括如： 虚拟IP 数据库实例 监听器 第三方应用程序等 CRSD管理需知： CRSd对资源进行管理，例如启动和停止应用程序资源的服务及故障转移。它生成独立的进程来管理应用程序资源 CRS管理Oracle集群注册表（OCR），并将当前已知状态存储在OCR中 CRS在UNIX中以root身份运行，在Windows上以LocalSystem身份运行，在发生故障时会自动重新启动 CRS需要公共IP、私有IP和虚拟IP才能运行。在开始安装CRS之前，公共和私有接口应当处于运行状态，而且能够相互执行ping操作 CRSd有两种运行模式: 在计划内的集群件启动期间，它以reboot模式启动,在reboot模式中，CRSd启动受其管理的所有资源。 在计划外关闭之后，它以restart模式启动。在restart模式中，它保持原来的状态，并使资源返回关闭前的状态。 集群同步服务——OCSSd OCSSD提供对节点成员关系的访问，并支持基本集群服务，包含集群组服务和集群锁定。 OCSSd的故障会导致计算机重新启动，以避免“脑裂”。 OCSSd以Oracle用户身份运行，并通过“节点集群”和“组”成员资格服务来管理Oracle集群件的配置。 OCSSd以两种心跳机制来提供这些服务： 网络心跳 磁盘心跳 网络心跳的目的是查看Oracle集群的有效性，而磁盘心跳则帮助确认脑裂的情况。因为OCSSd如此重要，所以它发生故障时，将重启计算机。单实例使用ASM的情况下，也需要这一服务。 CSS提供的服务： CSS提供基本的组服务支持。组服务是一种分布式组成员资格系统，它允许应用程序协调活动，以得出一个公共的结果。 锁服务提供了基本的集群范围内序列化锁定功能。它使用FIFO机制来管理锁定。 节点服务使用OCR来存储数据，并在重新配置期间更新信息。它还管理OCR数据，这些OCR数据在其他方面是静态的。 事件管理记录器——EVMd evmd进程以Oracle用户身份运行。假设Oracle集群由两个集群节点组成：节点A和节点B。当节点B离开集群时，节点A上的ocssd进程发出一个离开FAN事件，节点A上的evmd进程将它发布到节点A上的crsd进程，因为crsd进程是离开FAN时间的订阅者。Oracle提供了evmwatch和evmget实用工具，用于在标准输出上查看FAN事件。 进程监控器——OPROCd 11gR2中已废弃。 Oracle通知服务——ONS 该进程是在安装Oracle集群件期间配置的，在CRS启动时会在每个集群节点上启动该进程。只要集群资源的状态发生改变每个集群节点上的ONS进程就会相互通信，并交换高可用性事件信息。CRS触发这些HA事件，并将它们传送到ONS进程，然后ONS进程将这一高可用性事件信息发布到中间层。如果应用程序需要与FAN事件集成，则必须安装ONS服务。 11gR2中的集群件启动进程——OHASd OHASd又称为高可用性服务守护进程，它来启动所有其他Oracle集群件守护进程。 在安装OGI时，Oracle向/etc/inittab文件中添加一项： h1:35:respawn:/etc/init.d/init.ohasd run >/dev/null 2>&1 /etc/inittab文件执行带有run参数的/etc/init.d/init.ohasd控制脚本，它生成ohasd.bin可执行文件。/etc/init.d/init.ohasd控制脚本根据ohasdrun集群控制文件的值（restart、reboot、stop）启动OHASd。 OHASd使用集群资源启动其他集群件守护进程。OHASd对每个集群件守护进程都有一个资源，这些资源存储在Oracle本地注册表中。这些守护进程资源使用代理管理集群件守护进程，如启动、停止和监控集群件守护进程。 有四种主要代理： oraagent orarootagent cssdagent cssdmonitor 这些代理对各自的集群件守护进程执行启动、停止、检查和清理操作。 集群注册表——OCR 用来存储Orcle集群件中所定义的全部集群资源的元数据、配置和状态信息。这些注册表文件是二进制文件。 OCR用于引导CSS，提供端口信息、集群中的节点和类似信息。 CSSd在集群创建阶段更新OCR，集群建立之后，OCR就用于只读操作。 在资源状态变化、服务器启停、网络故障转移以及策略变化时会更新OCR。 可以在Oracle集群件的安装期间镜像OCR文件。尽管这一点非常重要，但它并非强制进行。Oracle在一个名为ocr.loc的文本文件中存储了OCR文件的位置。[root@node1 ~]# cat /etc/oracle/ocr.loc ocrconfig_loc=+ASM_DG local_only=FALSE Oracle在每个集群节点上使用OCR的一个内存中副本来优化各个客户端针对OCR的查询，但是一个集群中不允许有一个以上的CRSd进程向共享OCR文件中写入内容。 CRSd进程刷新所有集群节点上的OCR缓存，客户端与本地CRSd进程通信，以访问OCR的本地副本，并通过本地CRSd进程与主CRSd进程联系，以获得物理OCR二进制文件的任意更新。 OCR还保存着集群资源的依赖信息。 OCR文件每4小时自动备份一次，这些备份保存一周，被循环覆盖。OCR的最近3个成功备份可以在下列目录中找到：$GRID_HOME/cdata/clustername Oracle本地注册表——OLR OLR是11gR2引入的，它只存储与本地节点有关的信息，OLR存储OHASd通常需要的信息（集群的版本配置等）。 Oracle在一个名为/etc/oracle/olr.loc的文件中保存了OLR的位置：$GRID_HOME/cdata/hostname.olr 表决磁盘 必须为共享磁盘，它保存了节点之间的心跳信息。如果有任何节点不能ping表决磁盘，那么集群立即确认通信故障，将该节点从集群组中逐出。 虚拟IP：在公共IP子网中配置这个IP，监听器将会被配置为监听VIP，而不是公共IP。 当一个节点停机时，VIP会被自动故障转移到其他节点之一，这一过程不需要等待TCP超时。 单一客户端访问名称——SCAN 11gR2中引入，集群可以有1～3个SCAN监听器和SCAN VIP，客户端仅以SCAN VIP进行连接，因此集群节点发生变化时并不需要改变客户端的连接配置。 每个数据库实例都是用数据库初始化参数REMOTE_LISTENER将自己注册到本地监听器和SCAN监听器。 Oracle内核组件 由于缓冲区缓存和共享池在Oracle RAC环境中是全局的，因此管理这些内存结构需要附加的后台进程。 Oracle RAC环境中的Oracle内核组件是每个实例中的附加后台进程集合。 全局资源目录——GRD 集群中的所有资源构成一个集中资源仓库，称为全局资源目录GRD，它是集成的，分布式的。 每个实例掌握着某一组资源，所有实例加起来构成GRD。 当一个实例离开或者加入集群时，GRD将重新分配。 GRD管理所有资源的锁定或所有权。 GRD有两个服务管理： 全局缓存服务（GCS）：GCS处理数据块 全局队列服务（GES）：GES处理队列和其他全局资源 GCS和GES使用以下进程管理资源： LMS——全局和缓存服务进程 又名锁管理服务器，它可以从数据块所在的实例的缓冲区向请求实例的缓冲区缓存中传递数据块的一致性副本；它还可以从LMD建立的服务队列中获取请求，以执行所请求的锁操作；LMS进程管理对GCS资源的“锁管理器服务器”请求，并将它们发送到一个由LMS进程处理的服务队列；LMS还负责全局锁的死锁检测，并监控对话的超时。 每个实例最多可以拥有10个LMS进程，实际数量根据节点之间的消息通信流量发生变化，也可以使用隐藏参数手动调整，只有在非常特殊的情况下，才需要调整该参数。 LMON——全局队列服务监控器 又名锁监控器，它负责管理GES，它在进程死亡时维持GCS内存的一致性，LMON还负责在有实例加入或离开集群时进行集群重新配置和锁重新配置。 LMON进程监控整个集群，以管理全局资源，它管理实例死亡以及任意故障实例的相关恢复。总的来说，LMON处理与全局资源有关的恢复部分。 LMD——全局队列服务守护进程 LMD进程负责死锁检测和全局资源请求。 LCK0——实例队列进程 它管理实例资源请求和对共享资源的跨实例调用。 DIAG DIAG的工作与实例无关，通过DIAG框架和oradebug实用工具实现集群范围内的调试。 如果DIAG进程死亡，PMON进程会重新启动一个DIAG Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-10 16:35:42 "},"rac/crs-has-cluster.html":{"url":"rac/crs-has-cluster.html","title":"crs-has-cluster的关系","keywords":"","body":"crs/has/cluster的关系 The Oracle Clusterware Stack Oracle Clusterware consists of two separate stacks: an upper stack anchored by the Cluster Ready Services (CRS) daemon (crsd) and a lower stack anchored by the Oracle High Availability Services daemon (ohasd). These two stacks have several processes that facilitate cluster operations. The following sections describe these stacks in more detail: The Cluster Ready Services Stack The Oracle High Availability Services Stack The Cluster Ready Services Stack The list in this section describes the processes that comprise CRS. The list includes components that are processes on Linux and UNIX operating systems, or services on Windows. Cluster Ready Services (CRS): The primary program for managing high availability operations in a cluster. The CRS daemon (crsd) manages cluster resources based on the configuration information that is stored in OCR for each resource. This includes start, stop, monitor, and failover operations. The crsd process generates events when the status of a resource changes. When you have Oracle RAC installed, the crsd process monitors the Oracle database instance, listener, and so on, and automatically restarts these components when a failure occurs. Cluster Synchronization Services (CSS): Manages the cluster configuration by controlling which nodes are members of the cluster and by notifying members when a node joins or leaves the cluster. If you are using certified third-party clusterware, then CSS processes interfaces with your clusterware to manage node membership information. The cssdagent process monitors the cluster and provides I/O fencing. This service formerly was provided by Oracle Process Monitor Daemon (oprocd), also known as OraFenceService on Windows. A cssdagent failure results in Oracle Clusterware restarting the node. Oracle ASM: Provides disk management for Oracle Clusterware. Cluster Time Synchronization Service (CTSS): Provides time management in a cluster for Oracle Clusterware. Event Management (EVM): A background process that publishes events that Oracle Clusterware creates. Oracle Notification Service (ONS): A publish and subscribe service for communicating Fast Application Notification (FAN) events. Oracle Agent (oraagent): Extends clusterware to support Oracle-specific requirements and complex resources. Runs server callout scripts when FAN events occur. This process was known as RACG in Oracle Clusterware 11g release 1 (11.1). Oracle Root Agent (orarootagent): A specialized oraagent process that helps crsd manage resources owned by root, such as the network, and the Grid virtual IP address. The Cluster Synchronization Service (CSS), Event Management (EVM), and Oracle Notification Services (ONS) components communicate with other cluster component layers in the other instances in the same cluster database environment. These components are also the main communication links between Oracle Database, applications, and the Oracle Clusterware high availability components. In addition, these background processes monitor and manage database operations. The Oracle High Availability Services Stack The list in this section describes the processes that comprise the Oracle High Availability Services stack. The list includes components that are processes on Linux and UNIX operating systems, or services on Windows. Grid Plug and Play (gpnpd): GPNPD provides access to the Grid Plug and Play profile, and coordinates updates to the profile among the nodes of the cluster to ensure that all of the nodes node have the most recent profile. Grid Interprocess Communication (GIPC): A helper daemon for the communications infrastructure. Currently has no functionality; to be activated in a later release. Multicast Domain Name Service (mDNS): Allows DNS requests. The mDNS process is a background process on Linux and UNIX, and a service on Windows. Oracle Grid Naming Service (GNS): A gateway between the cluster mDNS and external DNS servers. The gnsd process performs name resolution within the cluster. Table 1-1 lists the processes and services associated with Oracle Clusterware components. In Table 1-1, if a UNIX or a Linux system process has an (r) beside it, then the process runs as the root user. Table 1-1 List of Processes and Services Associated with Oracle Clusterware Components Oracle Clusterware Component Linux/UNIX Process Windows Services Windows Processes CRS crsd.bin (r) OracleHAService crsd.exe CSS ocssd.bin, cssdmonitor, cssdagent OracleHAService cssdagent.exe, cssdmonitor.exeocssd.exe CTSS octssd.bin (r) EVM evmd.bin, evmlogger.bin OracleHAService evmd.exe GIPC gipcd.bin GNS gnsd (r) gnsd.exe Grid Plug and Play gpnpd.bin OracleHAService gpnpd.exe Master Diskmon diskmon.bin mDNS mdnsd.bin mDNSResponder mdns.exe Oracle agent oraagent.bin (11.2), or racgmain and racgimon(11.1) oraagent.exe Oracle High Availability Services ohasd.bin (r) OracleHAService ohasd.exe ONS ons ons.exe Oracle root agent orarootagent (r) 1 通过命令查看cluster/has/crs管理的内容 [root@11rac1 ~]# crsctl check crs CRS-4638: Oracle High Availability Services is online CRS-4537: Cluster Ready Services is online CRS-4529: Cluster Synchronization Services is online CRS-4533: Event Manager is online [root@11rac1 ~]# crsctl check has CRS-4638: Oracle High Availability Services is online [root@11rac1 ~]# crsctl check cluster CRS-4537: Cluster Ready Services is online CRS-4529: Cluster Synchronization Services is online CRS-4533: Event Manager is online 这里可以看到crs显示的内容=has+cluster显示的内容 2 分别执行3条命令查看结果显示 2.1 crsctl stop cluster root@11rac1 ~]# crsctl stop cluster CRS-2673: Attempting to stop ‘ora.crsd’ on ’11rac1′ CRS-2790: Starting shutdown of Cluster Ready Services-managed resources on ’11rac1′ CRS-2673: Attempting to stop ‘ora.LISTENER.lsnr’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.LISTENER_SCAN1.lsnr’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.CRS.dg’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.power.db’ on ’11rac1′ CRS-2677: Stop of ‘ora.LISTENER.lsnr’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.11rac1.vip’ on ’11rac1′ CRS-2677: Stop of ‘ora.LISTENER_SCAN1.lsnr’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.scan1.vip’ on ’11rac1′ CRS-2677: Stop of ‘ora.scan1.vip’ on ’11rac1′ succeeded CRS-2672: Attempting to start ‘ora.scan1.vip’ on ’11rac2′ CRS-2677: Stop of ‘ora.11rac1.vip’ on ’11rac1′ succeeded CRS-2672: Attempting to start ‘ora.11rac1.vip’ on ’11rac2′ CRS-2677: Stop of ‘ora.power.db’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.DATA.dg’ on ’11rac1′ CRS-2676: Start of ‘ora.11rac1.vip’ on ’11rac2′ succeeded CRS-2676: Start of ‘ora.scan1.vip’ on ’11rac2′ succeeded CRS-2672: Attempting to start ‘ora.LISTENER_SCAN1.lsnr’ on ’11rac2′ CRS-2677: Stop of ‘ora.DATA.dg’ on ’11rac1′ succeeded CRS-2676: Start of ‘ora.LISTENER_SCAN1.lsnr’ on ’11rac2′ succeeded CRS-2677: Stop of ‘ora.CRS.dg’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.asm’ on ’11rac1′ CRS-2677: Stop of ‘ora.asm’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.ons’ on ’11rac1′ CRS-2677: Stop of ‘ora.ons’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.net1.network’ on ’11rac1′ CRS-2677: Stop of ‘ora.net1.network’ on ’11rac1′ succeeded CRS-2792: Shutdown of Cluster Ready Services-managed resources on ’11rac1′ has completed CRS-2677: Stop of ‘ora.crsd’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.ctssd’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.evmd’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.asm’ on ’11rac1′ CRS-2677: Stop of ‘ora.evmd’ on ’11rac1′ succeeded CRS-2677: Stop of ‘ora.ctssd’ on ’11rac1′ succeeded CRS-2677: Stop of ‘ora.asm’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.cluster_interconnect.haip’ on ’11rac1′ CRS-2677: Stop of ‘ora.cluster_interconnect.haip’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.cssd’ on ’11rac1′ CRS-2677: Stop of ‘ora.cssd’ on ’11rac1′ succeeded [root@11rac1 ~]# crsctl check crs CRS-4638: Oracle High Availability Services is online CRS-4535: Cannot communicate with Cluster Ready Services CRS-4530: Communications failure contacting Cluster Synchronization Services daemon CRS-4534: Cannot communicate with Event Manager [root@11rac1 ~]# crsctl check has CRS-4638: Oracle High Availability Services is online [root@11rac1 ~]# crsctl check cluster CRS-4535: Cannot communicate with Cluster Ready Services CRS-4530: Communications failure contacting Cluster Synchronization Services daemon CRS-4534: Cannot communicate with Event Manager 这里可以看到stop cluster停了Clusterware stack，其实也就是官方文档中指的Cluster Ready Services Stack。 2.2 crsctl stop has 继续上面的操作 [root@11rac1 ~]# crsctl stop has CRS-2791: Starting shutdown of Oracle High Availability Services-managed resources on ’11rac1′ CRS-2673: Attempting to stop ‘ora.mdnsd’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.crf’ on ’11rac1′ CRS-2677: Stop of ‘ora.crf’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.gipcd’ on ’11rac1′ CRS-2677: Stop of ‘ora.mdnsd’ on ’11rac1′ succeeded CRS-2677: Stop of ‘ora.gipcd’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.gpnpd’ on ’11rac1′ CRS-2677: Stop of ‘ora.gpnpd’ on ’11rac1′ succeeded CRS-2793: Shutdown of Oracle High Availability Services-managed resources on ’11rac1′ has completed CRS-4133: Oracle High Availability Services has been stopped. stop has停的就是官方文档中的Oracle High Availability Services Stack，但是Oracle High Availability Services Stack属于Cluster Ready Services Stack依赖的底层，所以在停Oracle High Availability Services Stack会自动停Cluster Ready Services Stack，如下： [root@11rac1 ~]# crsctl stop has CRS-2791: Starting shutdown of Oracle High Availability Services-managed resources on ’11rac1′ CRS-2673: Attempting to stop ‘ora.crsd’ on ’11rac1′ CRS-2790: Starting shutdown of Cluster Ready Services-managed resources on ’11rac1′ CRS-2673: Attempting to stop ‘ora.CRS.dg’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.power.db’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.LISTENER.lsnr’ on ’11rac1′ CRS-2677: Stop of ‘ora.LISTENER.lsnr’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.11rac1.vip’ on ’11rac1′ CRS-2677: Stop of ‘ora.11rac1.vip’ on ’11rac1′ succeeded CRS-2672: Attempting to start ‘ora.11rac1.vip’ on ’11rac2′ CRS-2677: Stop of ‘ora.power.db’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.DATA.dg’ on ’11rac1′ CRS-2676: Start of ‘ora.11rac1.vip’ on ’11rac2′ succeeded CRS-2677: Stop of ‘ora.DATA.dg’ on ’11rac1′ succeeded CRS-2677: Stop of ‘ora.CRS.dg’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.asm’ on ’11rac1′ CRS-2677: Stop of ‘ora.asm’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.ons’ on ’11rac1′ CRS-2677: Stop of ‘ora.ons’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.net1.network’ on ’11rac1′ CRS-2677: Stop of ‘ora.net1.network’ on ’11rac1′ succeeded CRS-2792: Shutdown of Cluster Ready Services-managed resources on ’11rac1′ has completed CRS-2677: Stop of ‘ora.crsd’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.crf’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.ctssd’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.evmd’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.asm’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.mdnsd’ on ’11rac1′ CRS-2677: Stop of ‘ora.crf’ on ’11rac1′ succeeded CRS-2677: Stop of ‘ora.evmd’ on ’11rac1′ succeeded CRS-2677: Stop of ‘ora.mdnsd’ on ’11rac1′ succeeded CRS-2677: Stop of ‘ora.ctssd’ on ’11rac1′ succeeded CRS-2677: Stop of ‘ora.asm’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.cluster_interconnect.haip’ on ’11rac1′ CRS-2677: Stop of ‘ora.cluster_interconnect.haip’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.cssd’ on ’11rac1′ CRS-2677: Stop of ‘ora.cssd’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.gipcd’ on ’11rac1′ CRS-2677: Stop of ‘ora.gipcd’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.gpnpd’ on ’11rac1′ CRS-2677: Stop of ‘ora.gpnpd’ on ’11rac1′ succeeded CRS-2793: Shutdown of Oracle High Availability Services-managed resources on ’11rac1′ has completed CRS-4133: Oracle High Availability Services has been stopped. 这里可以看到在停has的时候，自动把上层服务也停了 2.3 crsctl stop crs 这里的CRS其实指的是整个ORACLE集群，也不是 Cluster Ready Services Stack的简写。 [root@11rac1 ~]# crsctl stop crs CRS-2791: Starting shutdown of Oracle High Availability Services-managed resources on ’11rac1′ CRS-2673: Attempting to stop ‘ora.crsd’ on ’11rac1′ CRS-2790: Starting shutdown of Cluster Ready Services-managed resources on ’11rac1′ CRS-2673: Attempting to stop ‘ora.CRS.dg’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.power.db’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.LISTENER.lsnr’ on ’11rac1′ CRS-2677: Stop of ‘ora.LISTENER.lsnr’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.11rac1.vip’ on ’11rac1′ CRS-2677: Stop of ‘ora.11rac1.vip’ on ’11rac1′ succeeded CRS-2672: Attempting to start ‘ora.11rac1.vip’ on ’11rac2′ CRS-2677: Stop of ‘ora.power.db’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.DATA.dg’ on ’11rac1′ CRS-2676: Start of ‘ora.11rac1.vip’ on ’11rac2′ succeeded CRS-2677: Stop of ‘ora.DATA.dg’ on ’11rac1′ succeeded CRS-2677: Stop of ‘ora.CRS.dg’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.asm’ on ’11rac1′ CRS-2677: Stop of ‘ora.asm’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.ons’ on ’11rac1′ CRS-2677: Stop of ‘ora.ons’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.net1.network’ on ’11rac1′ CRS-2677: Stop of ‘ora.net1.network’ on ’11rac1′ succeeded CRS-2792: Shutdown of Cluster Ready Services-managed resources on ’11rac1′ has completed CRS-2677: Stop of ‘ora.crsd’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.crf’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.ctssd’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.evmd’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.asm’ on ’11rac1′ CRS-2673: Attempting to stop ‘ora.mdnsd’ on ’11rac1′ CRS-2677: Stop of ‘ora.crf’ on ’11rac1′ succeeded CRS-2677: Stop of ‘ora.evmd’ on ’11rac1′ succeeded CRS-2677: Stop of ‘ora.mdnsd’ on ’11rac1′ succeeded CRS-2677: Stop of ‘ora.ctssd’ on ’11rac1′ succeeded CRS-2677: Stop of ‘ora.asm’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.cluster_interconnect.haip’ on ’11rac1′ CRS-2677: Stop of ‘ora.cluster_interconnect.haip’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.cssd’ on ’11rac1′ CRS-2677: Stop of ‘ora.cssd’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.gipcd’ on ’11rac1′ CRS-2677: Stop of ‘ora.gipcd’ on ’11rac1′ succeeded CRS-2673: Attempting to stop ‘ora.gpnpd’ on ’11rac1′ CRS-2677: Stop of ‘ora.gpnpd’ on ’11rac1′ succeeded CRS-2793: Shutdown of Oracle High Availability Services-managed resources on ’11rac1′ has completed CRS-4133: Oracle High Availability Services has been stopped. 通过上面的简单测试，可以得出两点： 1，crsctl stop crs=crsctl stop cluster+crsctl stop has，前提是先停cluster后，再停has 2，crsctl stop crs=crsctl stop has，如果之前没有Oracle о 手动停cluster，那么crsctl stop crs与crsctl stop has的效果一样 另外crsctl stop crs与crsctl stop has都只能操作当前节点，crsctl stop cluster可以一次操作集群中多个节点，前提是HAS服务正常运行。 下面来一张ORACLE RAC进程之前的依赖 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-25 23:29:40 "},"rac/35.HAIP介绍.html":{"url":"rac/35.HAIP介绍.html","title":"HAIP介绍","keywords":"","body":"HAIP简介 Oracle从11.2.0.2开始引入了一个新特性网络冗余技术HAIP。HAIP的目的用来代替操作系统级别的网卡绑定以实现Active-Active的模式进行数据传输。一来可以实现传统操作系统网卡绑定带来的故障转移的功能，另一方面则可以更加充分利用其负载均衡的特性最大程度的减少因为gc等待带来的性能问题。 如果更多的网络适配器被指定，clusterware可以一次激活最多4个专用网络适配器。ora.cluster_interconnect.haip 将为Oracle RAC、Oracle ASM、Oracle ACFS等启用一至四个连接本地HAIP的互联通信网络适配器，注意，如果存在sun cluster，HAIT特性将在11.2.0.2中禁用。 Grid将自动选择连接本地保留地址169.254..作为HAIP子网，并且不会尝试适用任何169.254..地址，如果它已经被在用于其它目的使用。由于HAIP，在默认情况下，网络流量将被所有活动的网络接口负载均衡。并且如果其中一个失败或者变成不可连接状态，相应的HAIP地址将透明的转移到相对的其它网络适配器。 当Grid中启动集群中的第一个节点，HAIP地址数量是由有多少个私有网络适配器是活动状态所决定的。如果只有一个活跃的私有网络，那么Grid将创建一个，如果有两个，Grid将创建两个,如果大于两个，Grid将创建4个HAIPs.即使更多的私有网络适配器随后被激活，HAIPs的数量是不会改变的，要使得新的网络适配器变成活动状态，则要重启集群所有的节点。 参考: MetaLink 1210883.1 https://blog.csdn.net/ora_unix/article/details/9420393 https://blog.csdn.net/orion61/article/details/42489009 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-14 15:25:46 "},"rac/12.RAC-log-infra.html":{"url":"rac/12.RAC-log-infra.html","title":"RAC环境的日志体系","keywords":"","body":" Oracle集群环境中日志体系结构，在遇到问题时，可以快速查找所需的日志文件，及时的定位问题~ 1.Oracle集群日志的文件路径 Oracle集群涉及的日志主要位于“$GRID_HOME/log”和“$ORACLE_HOME/log”目录中。 2.日志目录结构 clusterware 层的日志结构： grid@rac1:/home/grid>tree -d $ORACLE_HOME/log /opt/rac/11.2.0/grid/log |-- crs |-- diag | `-- clients | `-- user_root | `-- host_1874443374_76 | |-- alert | |-- cdump | |-- incident | |-- incpkg | |-- lck | |-- metadata | |-- stage | |-- sweep | `-- trace `-- rac1 |-- admin |-- agent | |-- crsd | | |-- oraagent_grid | | |-- oraagent_oracle | | `-- orarootagent_root | `-- ohasd | |-- oraagent_grid | |-- oracssdagent_root | |-- oracssdmonitor_root | `-- orarootagent_root |-- client |-- crsd |-- cssd |-- ctssd |-- diskmon |-- evmd |-- gipcd |-- gnsd |-- gpnpd |-- mdnsd |-- ohasd |-- racg | |-- racgeut | |-- racgevtf | `-- racgmain `-- srvm 42 directories RMDBS 层的日志结构： oracle@rac1:/opt/rac/oracle/diag/rdbms/rac>tree -d rac1 rac1 |-- alert |-- cdump |-- hm |-- incident |-- incpkg |-- ir |-- lck |-- metadata |-- stage |-- sweep `-- trace 11 directories 其中“rac1”是主机名。 3.日志目录功能说明 1）CRS日志存放在“$GRID_HOME/log//crsd”目录，系统会对该日志每10M进行归档一次； 2）CSS日志存放在“$GRID_HOME/log//cssd”目录，系统会对该日志每20M进行归档一次； 3）EVM日志存放在“$GRID_HOME/log//evmd”目录； 4）“$GRID_HOME/log/”和“$ORACLE_HOME/log/”目录中的racg目录中记录了RACG可执行文件对应的日志； 5）$GRID_HOME/log/client和$ORACLE_HOME/log/client目录记录了与srvctl、ocrdump、ocrconfig以及ocrcheck命令对应的日志信息。 4.Oracle集群的alert日志 Oracle RAC环境中的alert日志文件与Oracle单实例的alert日志一样。该文件位于“在 $ORACLEBASE/rdbms//trace”目录下，命名规则为“alert.log” 该警告日志记录了有关Oracle集群rdbms 层面的重要警告信息。 oracle@rac1:/opt/rac/oracle/diag/rdbms/rac/rac1/trace>more alert_rac1.log Starting up: Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit Production With the Partitioning, Real Application Clusters, OLAP, Data Mining and Real Application Testing options. Using parameter settings in client-side pfile /opt/rac/oracle/admin/rac/pfile/init.ora on machine rac1 System parameters with non-default values: processes = 150 nls_language = \"SIMPLIFIED CHINESE\" nls_territory = \"CHINA\" memory_target = 1584M control_files = \"+DATA2/rac/controlfile/current.260.781821965\" db_block_size = 8192 compatible = \"11.2.0.0.0\" log_archive_dest_1 = \"LOCATION=+DATA2\" log_archive_format = \"yangdb_%t_%s_%r.dbf\" db_create_file_dest = \"+DATA2\" undo_tablespace = \"UNDOTBS1\" instance_number = 1 remote_login_passwordfile= \"EXCLUSIVE\" db_domain = \"\" dispatchers = \"(PROTOCOL=TCP) (SERVICE=racXDB)\" remote_listener = \"scan:1521\" audit_file_dest = \"/opt/rac/oracle/admin/rac/adump\" audit_trail = \"DB\" db_name = \"rac\" open_cursors = 300 diagnostic_dest = \"/opt/rac/oracle\" Cluster communication is configured to use the following interface(s) for this instance 10.10.10.10 cluster interconnect IPC version:Oracle UDP/IP (generic) IPC Vendor 1 proto 2 Sat Apr 28 20:50:38 2012 PMON started with pid=2, OS id=16042 Sat Apr 28 20:50:38 2012 VKTM started with pid=3, OS id=16044 at elevated priority VKTM running at (10)millisec precision with DBRM quantum (100)ms Sat Apr 28 20:50:39 2012 GEN0 started with pid=4, OS id=16048 Sat Apr 28 20:50:39 2012 DIAG started with pid=5, OS id=16050 Sat Apr 28 20:50:39 2012 DBRM started with pid=6, OS id=16052 5.小结 熟悉Oracle集群环境下日志文件的位置和功能有助于快速定位故障的位置，善用之。 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-24 10:27:31 "},"rac/10g-rac-command.html":{"url":"rac/10g-rac-command.html","title":"10gRAC命令","keywords":"","body":" 10gRAC 常用命令 Oracle Clusterware的命令集可以分为4种 节点层： 网络层 集群层 配置CRS 栈是否自启动 启动CRS 查看CRS资源状态 关闭特定集群资源 所有集群资源 当前节点所有CRS资源 srvctl停止和启动节点应用 对CRS后台进程做健康检查 检查OCR 检查表决磁盘 应用层 配置数据库随CRS的启动而自动启动 关闭某个实例的自动启动 启动，停止对象与查看对象 10gRAC 常用命令 Oracle Clusterware的命令集可以分为4种 节点层：osnodes 网络层：oifcfg 集群层：crsctl, ocrcheck,ocrdump,ocrconfig 应用层：srvctl,onsctl,crs_stat 下面分别来介绍这些命令。 节点层： 只有一个命令：　osnodes，这个命令用来显示集群点列表 ./olsnodes -n -p -i 网络层 只有一个命令：oifcfg oifcfg 命令用来定义和修改Oracle集群需要的网卡属性，这些属性包括网卡的网段地址，子网掩码，接口类型等。要想正确的使用这个命令，必须先知道Oracle 是如何定义网络接口的，Oracle的每个网络接口包括名称，网段地址，接口类型3个属性。 oifcfg 命令的格式如下：interface_name/subnet:interface_type 这些属性中没有IP地址，但接口类型有两种，public和private，前者说明接口用于外部通信，用于Oracle Net和VIP 地址，而后者说明接口用于Interconnect。 接口的配置方式分为两类：global 和node-specific。 前者说明集群所有节点的配置信息相同，也就是说所有节点的配置是对称的，而后者意味着这个节点的配置和其他节点配置不同，是非对称的。 Iflist：显示网口列表 Getif: 获得单个网口信息 Setif：配置单个网口 Delif：删除网口 集群层 集群层是指由Clusterware组成的核心集群，这一层负责维护集群内的共享设备，并为应用集群提供完整的集群状态视图，应用集群依据这个视图进行调整。 这一层共有4个命令：crsctl, ocrcheck,ocrdump,ocrconfig. 后三个是针对OCR 磁盘的。 配置CRS 栈是否自启动 crsctl disable crs crsctl enable crs 启动CRS CRS没有启动在使用crs_stat命令查看状态的时候 会收到如下的报错信息 CRS-0184:Cannot communicate with the CRSdaemon 启动命令为: crsctl start crs 停止CRS命令为: crsctl stop crs 查看CRS资源状态 10g: crs_stat –t 11g: crsctl res status -t 关闭特定集群资源 查找资源名字crs_stat | grep -i name= | cut -d '=' -f2 找到资源名字后关闭 crs_stop ora.RACDB.RACDB1.inst 确定资源开启 crs_start ora.RACDB.RACDB1.inst 所有集群资源 关闭所有集群资源 crs_stop -all 启动所有集群资源 crs_start -all 当前节点所有CRS资源 crsctl start resources srvctl停止和启动节点应用 关闭节点应用 srvctl stop nodeapps -n rac1 srvctl start nodeapps -n rac1 对CRS后台进程做健康检查 crsctl check crs 检查OCR ocrcheck 检查表决磁盘 crsctl query css votedisk 应用层 应用层就是指RAC数据库了，这一层有若干资源组成，每个资源都是一个进程或者一组进程组成的完整服务，这一层的管理和维护都是围绕这些资源进行的。有: srvctl,onsctl, crs_stat 三个命令。 crs_stat 这个命令用于查看CRS维护的所有资源的运行状态 onsctl命令用于管理配置ONS(Oracle Notification Service). ONS 是Oracle Clusterware 实现FAN EventPush模型的基础。 srvctl是RAC维护中最常用，也是最复杂的。可以操作下面的几种资源：Database，Instance，ASM，Service，Listener 和Node Application，其中Node application又包括GSD，ONS，VIP。资源除了使用srvctl工具统一管理外，某些资源还有自己独立的管理工具，比如ONS可以使用onsctl命令进行管理；Listener 可以通过lsnrctl 管理。 配置数据库随CRS的启动而自动启动 srvctl enable database -d raw srvctl disable database -d raw 关闭某个实例的自动启动 srvctl disable instance -d raw -i raw1 启动，停止对象与查看对象 在RAC 环境下启动，关闭数据库虽然仍然可以使用SQL/PLUS方法，但是更推荐使用srvctl命令来做这些工作，这可以保证即使更新CRS中运行信息，可以使用start/stop 命令启动，停止对象，然后使用status 命令查看对象状态。 指定启动状态 srvctl start database -d raw -i raw1 -o mount 关闭对象，并指定关闭方式 srvctl stop instance -d raw -i raw1 -o immediate 停止 Oracle RAC 10g 环境 $ srvctl stop instance -d orcl -i orcl1 $ srvctl stop asm -n rac1 $ srvctl stop nodeapps –n rac1 启动 Oracle RAC 10g 环境 $ srvctl start nodeapps -n rac1 $ srvctl start asm -n rac1 $ srvctl start instance -d orcl -i orcl1 启动/停止所有实例及其启用的服务。 $ srvctl start database -d orcl $ srvctl stop database -d orcl Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-24 09:13:07 "},"rac/9.rac-commnd-intro.html":{"url":"rac/9.rac-commnd-intro.html","title":"11gRAC常用命令","keywords":"","body":" 11gRAC 常用命令 一、在Oracle 11g环境中，Oracle的关闭和启动顺序 1.关闭顺序 2.启动顺序 3.启动和停止CRS 二、检查集群状态 1.检查 CRS 状态 2.检查集群的运行状况 3.查看各资源状态 4.查看各资源状态(nodeapps节点应用程序，ASM实例，数据库实例等) 5.查看数据库状态 6.检查单个实例状态 7.节点应用程序状态 8.列出所有的配置数据库 9.数据库配置 10.ASM状态以及ASM配置 11.检查 Oracle 集群注册表 (OCR) 12.查看表决磁盘 13.TNS监听器状态以及配置 14.SCAN状态以及配置 15.VIP各个节点的状态以及配置 16.验证所有集群节点间的时钟同步 三、用SQL查看状态 1.集群中所有正在运行的实例 2.所有数据库文件及它们所在的 ASM 磁盘组 3.ASM 磁盘卷 查看11g 数据库实例的alert log及trace 查看RAC 11g 集群log及trace 四、RAC上的数据库运维 1.创建表空间及增加数据文件 11gRAC 常用命令 11gRAC对比10GRAC的命令有了许多变化，下面一一叙述 一、在Oracle 11g环境中，Oracle的关闭和启动顺序 1.关闭顺序 1、关闭数据库,oracl用户执行srvctl命令： [oracle@rac1 ~]$ srvctl stop database -d ORCL ---停止所有节点上的实例 或者每个节点登录数据库后执行 SQL>shutdown immediate 2、停止集群服务，必须以root用户： [root@rac1 oracle]# cd /u01/grid/11.2.0/grid/bin [root@rac1 bin]# ./crsctl stop cluster -all ----停止所有节点服务 [root@rac1 bin]# ./crsctl stop cluster ----停止本节点集群服务，每个节点分别执行 PS: 也可以如下控制所停节点： [root@rac1 bin]# ./crsctl stop cluster -n rac1 3、停止HAS(High Availability Services)，必须以root用户 [root@rac1 oracle]# cd /u01/grid/11.2.0/grid/bin [root@rac1 bin]# ./crsctl stop has –f 注：在运行crsctl stop cluster命令之后，如果 Oracle Clusterware 管理的资源中有任何一个还在运行，则整个命令失败。使用 -f 选项无条件地停止所有资源并停止 Oracle Clusterware 系统。 另请注意，可通过指定 -all 选项在集群中所有服务器上停止 Oracle Clusterware 系统。 2.启动顺序 11g R2的RAC默认开机会自启动，当然如果需要手工启动。手工启动按照HAS,cluster, database的顺序启动即可，具体命令如下： 1、启动HAS(High Availability Services)，必须以root用户 [root@rac1 bin]# ./crsctl start has 以上has启动命令需要在每个节点分别执行 2、启动集群（cluster） [root@rac1 ~]# ./crsctl start cluster -all --所有节点同时启动 或者只启动指定节点的 [root@rac1 ~]# ./crsctl start cluster -n rac1 rac2 --两个节点同时启动 3、启动数据库,oracl用户执行srvctl命令（假设数据库名为ORCL）： [oracle@rac1 ~]$ srvctl start database -d ORCL ---停止所有节点上的实例 或者每个节点登录数据库后执行SQL>startup 4、使用crs_stat命令来进程验证 [grid@oracle1 ~]$ crs_stat -t -v 3.启动和停止CRS 以下操作需用root用户执行 [root@racnode2 bin]# /u01/app/11.2.0/grid/bin/crsctl stop crs CRS-2791: 正在启动用于关闭 'racnode2' 上 Oracle High Availability Services 管理的资源的操作 CRS-2673: 尝试停止 'ora.crsd' (在 'racnode2' 上) CRS-2790: 正在启动关闭 'racnode2' 上集群就绪服务管理的资源的操作 CRS-2673: 尝试停止 'ora.CRS.dg' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.racdb.db' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.LISTENER.lsnr' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.LISTENER_SCAN1.lsnr' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.LISTENER.lsnr' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.racnode2.vip' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.LISTENER_SCAN1.lsnr' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.scan1.vip' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.racnode2.vip' (在 'racnode2' 上) CRS-2672: 尝试启动 'ora.racnode2.vip' (在 'racnode1' 上) CRS-2677: 成功停止 'ora.scan1.vip' (在 'racnode2' 上) CRS-2672: 尝试启动 'ora.scan1.vip' (在 'racnode1' 上) CRS-2676: 成功启动 'ora.scan1.vip' (在 'racnode1' 上) CRS-2676: 成功启动 'ora.racnode2.vip' (在 'racnode1' 上) CRS-2672: 尝试启动 'ora.LISTENER_SCAN1.lsnr' (在 'racnode1' 上) CRS-2676: 成功启动 'ora.LISTENER_SCAN1.lsnr' (在 'racnode1' 上) CRS-2677: 成功停止 'ora.CRS.dg' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.racdb.db' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.FRA.dg' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.RACDB_DATA.dg' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.FRA.dg' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.RACDB_DATA.dg' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.asm' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.asm' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.eons' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.ons' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.ons' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.net1.network' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.net1.network' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.eons' (在 'racnode2' 上) CRS-2792: 关闭 'racnode2' 上集群就绪服务管理的资源的操作已完成 CRS-2677: 成功停止 'ora.crsd' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.mdnsd' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.cssdmonitor' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.ctssd' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.evmd' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.asm' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.cssdmonitor' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.evmd' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.mdnsd' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.ctssd' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.asm' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.cssd' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.cssd' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.gpnpd' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.diskmon' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.gpnpd' (在 'racnode2' 上) CRS-2673: 尝试停止 'ora.gipcd' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.gipcd' (在 'racnode2' 上) CRS-2677: 成功停止 'ora.diskmon' (在 'racnode2' 上) CRS-2793: 关闭 'racnode2' 上 Oracle High Availability Services 管理的资源的操作已完成 CRS-4133: Oracle High Availability Services has been stopped. [root@racnode2 bin]# /u01/app/11.2.0/grid/bin/crsctl start crs CRS-4123: Oracle High Availability Services has been started. 二、检查集群状态 1.检查 CRS 状态 [grid@racnode1 ~]$ crsctl check crs CRS-4638: Oracle High Availability Services is online CRS-4537: Cluster Ready Services is online CRS-4529: Cluster Synchronization Services is online CRS-4533: Event Manager is online 2.检查集群的运行状况 [grid@racnode1 ~]$ crsctl check cluster CRS-4537: Cluster Ready Services is online CRS-4529: Cluster Synchronization Services is online CRS-4533: Event Manager is online 3.查看各资源状态 包括:nodeapps节点应用程序，ASM实例，数据库实例等 [root@racnode1 ~]# su - grid [grid@racnode1 ~]$ crs_stat -t -v Name Type R/RA F/FT Target State Host ---------------------------------------------------------------------- ora.CRS.dg ora....up.type 0/5 0/ ONLINE ONLINE racnode1 ora.FRA.dg ora....up.type 0/5 0/ ONLINE ONLINE racnode1 ora....ER.lsnr ora....er.type 0/5 0/ ONLINE ONLINE racnode1 ora....N1.lsnr ora....er.type 0/5 0/0 ONLINE ONLINE racnode2 ora....DATA.dg ora....up.type 0/5 0/ ONLINE ONLINE racnode1 ora.asm ora.asm.type 0/5 0/ ONLINE ONLINE racnode1 ora.eons ora.eons.type 0/3 0/ ONLINE ONLINE racnode1 ora.gsd ora.gsd.type 0/5 0/ OFFLINE OFFLINE ora....network ora....rk.type 0/5 0/ ONLINE ONLINE racnode1 ora.oc4j ora.oc4j.type 0/5 0/0 OFFLINE OFFLINE ora.ons ora.ons.type 0/3 0/ ONLINE ONLINE racnode1 ora.racdb.db ora....se.type 0/2 0/1 ONLINE ONLINE racnode1 ora....SM1.asm application 0/5 0/0 ONLINE ONLINE racnode1 ora....E1.lsnr application 0/5 0/0 ONLINE ONLINE racnode1 ora....de1.gsd application 0/5 0/0 OFFLINE OFFLINE ora....de1.ons application 0/3 0/0 ONLINE ONLINE racnode1 ora....de1.vip ora....t1.type 0/0 0/0 ONLINE ONLINE racnode1 ora....SM2.asm application 0/5 0/0 ONLINE ONLINE racnode2 ora....E2.lsnr application 0/5 0/0 ONLINE ONLINE racnode2 ora....de2.gsd application 0/5 0/0 OFFLINE OFFLINE ora....de2.ons application 0/3 0/0 ONLINE ONLINE racnode2 ora....de2.vip ora....t1.type 0/0 0/0 ONLINE ONLINE racnode2 ora.scan1.vip ora....ip.type 0/0 0/0 ONLINE ONLINE racnode2 4.查看各资源状态(nodeapps节点应用程序，ASM实例，数据库实例等) [grid@racnode1 ~]$ crsctl status res -t -------------------------------------------------------------------------------- NAME TARGET STATE SERVER STATE_DETAILS -------------------------------------------------------------------------------- Local Resources -------------------------------------------------------------------------------- ora.CRS.dg ONLINE ONLINE racnode1 ONLINE ONLINE racnode2 ora.FRA.dg ONLINE ONLINE racnode1 ONLINE ONLINE racnode2 ora.LISTENER.lsnr ONLINE ONLINE racnode1 ONLINE ONLINE racnode2 ora.RACDB_DATA.dg ONLINE ONLINE racnode1 ONLINE ONLINE racnode2 ora.asm ONLINE ONLINE racnode1 Started ONLINE ONLINE racnode2 ora.eons ONLINE ONLINE racnode1 ONLINE ONLINE racnode2 ora.gsd OFFLINE OFFLINE racnode1 OFFLINE OFFLINE racnode2 ora.net1.network ONLINE ONLINE racnode1 ONLINE ONLINE racnode2 ora.ons ONLINE ONLINE racnode1 ONLINE ONLINE racnode2 -------------------------------------------------------------------------------- Cluster Resources -------------------------------------------------------------------------------- ora.LISTENER_SCAN1.lsnr 1 ONLINE ONLINE racnode2 ora.oc4j 1 OFFLINE OFFLINE ora.racdb.db 1 ONLINE ONLINE racnode1 Open 2 ONLINE ONLINE racnode2 Instance Shutdown ora.racnode1.vip 1 ONLINE ONLINE racnode1 ora.racnode2.vip 1 ONLINE ONLINE racnode2 ora.scan1.vip 1 ONLINE ONLINE racnode2 5.查看数据库状态 [grid@racnode1 ~]$ srvctl status database -d racdb 实例 racdb1 正在节点 racnode1 上运行 实例 racdb2 正在节点 racnode2 上运行 6.检查单个实例状态 [grid@racnode1 ~]$ srvctl status instance -d racdb -i racdb1 实例 racdb1 正在节点 racnode1 上运行 7.节点应用程序状态 [grid@racnode1 ~]$ srvctl status instance -d racdb -i racdb1 实例 racdb1 正在节点 racnode1 上运行 [grid@racnode1 ~]$ srvctl status nodeapps VIP racnode1-vip 已启用 VIP racnode1-vip 正在节点上运行: racnode1 VIP racnode2-vip 已启用 VIP racnode2-vip 正在节点上运行: racnode2 网络已启用 网络正在节点上运行: racnode1 网络正在节点上运行: racnode2 GSD 已禁用 GSD 没有运行的节点: racnode1 GSD 没有运行的节点: racnode2 ONS 已启用 ONS 守护程序正在节点上运行:racnode1 ONS 守护程序正在节点上运行:racnode2 eONS 已启用 eONS 守护程序正在节点上运行:racnode1 eONS 守护程序正在节点上运行:racnode2 8.列出所有的配置数据库 [grid@racnode1 ~]$ srvctl config database racdb 9.数据库配置 [grid@racnode1 ~]$ srvctl config database -d racdb -a 数据库唯一名称: racdb 数据库名: racdb Oracle 主目录: /u01/app/oracle/product/11.2.0/dbhome_1 Oracle 用户: oracle Spfile: +RACDB_DATA/racdb/spfileracdb.ora 域: path_finder.info 启动选项: open 停止选项: immediate 数据库角色: PRIMARY 管理策略: AUTOMATIC 服务器池: racdb 数据库实例: racdb1,racdb2 磁盘组: RACDB_DATA,FRA 服务: 数据库已启用 数据库是管理员管理的 10.ASM状态以及ASM配置 [grid@racnode1 ~]$ srvctl status asm ASM 正在 racnode1,racnode2 上运行 [grid@racnode1 ~]$ srvctl status asm -a ASM 正在 racnode1,racnode2 上运行 ASM 已启用。 [grid@racnode1 ~]$ srvctl config asm -a ASM 主目录: /u01/app/11.2.0/grid ASM 监听程序: LISTENER ASM 已启用。 11.检查 Oracle 集群注册表 (OCR) [grid@racnode1 ~]$ ocrcheck Status of Oracle Cluster Registry is as follows : Version : 3 Total space (kbytes) : 262120 Used space (kbytes) : 2568 Available space (kbytes) : 259552 ID : 1884152943 Device/File Name : +CRS Device/File integrity check succeeded Device/File not configured Device/File not configured Device/File not configured Device/File not configured Cluster registry integrity check succeeded Logical corruption check bypassed due to non-privileged user 12.查看表决磁盘 [grid@racnode1 ~]$ crsctl query css votedisk ## STATE File Universal Id File Name Disk group -- ----- ----------------- --------- --------- 1. ONLINE 2aae1495c66a4f50bf63a503076ef792 (ORCL:CRSVOL1) [CRS] Located 1 voting disk(s). 13.TNS监听器状态以及配置 [grid@racnode1 ~]$ srvctl status listener 监听程序 LISTENER 已启用 监听程序 LISTENER 正在节点上运行: racnode1,racnode2 [grid@racnode1 ~]$ srvctl config listener -a 名称: LISTENER 网络: 1, 所有者: grid 主目录: 节点 racnode2,racnode1 上的 /u01/app/11.2.0/grid 端点: TCP:1521 14.SCAN状态以及配置 [grid@racnode1 ~]$ srvctl status scan SCAN VIP scan1 已启用 SCAN VIP scan1 正在节点 racnode2 上运行 [grid@racnode1 ~]$ srvctl config scan SCAN 名称: racnode-cluster-scan, 网络: 1/10.236.101.0/255.255.255.0/eth0 SCAN VIP 名称: scan1, IP: /racnode-cluster-scan/10.236.101.234 15.VIP各个节点的状态以及配置 [grid@racnode1 ~]$ srvctl status vip -n racnode1 VIP racnode1-vip 已启用 VIP racnode1-vip 正在节点上运行: racnode1 [grid@racnode1 ~]$ srvctl status vip -n racnode2 VIP racnode2-vip 已启用 VIP racnode2-vip 正在节点上运行: racnode2 [grid@racnode1 ~]$ srvctl config vip -n racnode1 VIP 已存在。:racnode1 VIP 已存在。: /racnode1-vip/10.236.101.232/255.255.255.0/eth0 [grid@racnode1 ~]$ srvctl config vip -n racnode2 VIP 已存在。:racnode2 VIP 已存在。: /racnode2-vip/10.236.101.233/255.255.255.0/eth0 16.验证所有集群节点间的时钟同步 [grid@racnode1 ~]$ cluvfy comp clocksync -verbose 验证 各集群节点上的时钟同步 正在检查是否在所有节点上安装了集群件... 集群件的安装检查通过 正在检查 CTSS 资源是否在所有节点上运行... 检查: CTSS 资源是否正在所有节点上运行 节点名 状态 ------------------------------------ ------------------------ racnode1 通过 结果:CTSS 资源检查通过 正在查询所有节点上时间偏移量的 CTSS... 结果:时间偏移量的 CTSS 查询通过 检查 CTSS 状态已启动... 检查: CTSS 状态 节点名 状态 ------------------------------------ ------------------------ racnode1 活动 CTSS 处于活动状态。正在继续检查所有节点上的时钟时间偏移量... 引用时间偏移量限制: 1000.0 毫秒 检查: 引用时间偏移量 节点名 时间偏移量 状态 ------------ ------------------------ ------------------------ racnode1 0.0 通过 以下节点集的时间偏移量在指定的限制之内: \"[racnode1]\" 结果:时钟时间偏移量检查通过 Oracle 集群时间同步服务检查已通过 各集群节点上的时钟同步 的验证成功。 三、用SQL查看状态 1.集群中所有正在运行的实例 SELECT inst_id , instance_number inst_no , instance_name inst_name , parallel , status ,database_status db_status , active_state state , host_name host FROM gv$instance ORDER BY inst_id; 2.所有数据库文件及它们所在的 ASM 磁盘组 SQL> select name from v$datafile union select member from v$logfile union select name from v$controlfile union select name from v$tempfile; NAME -------------------------------------------------------- +FRA/racdb/controlfile/current.256.949053765 +FRA/racdb/onlinelog/group_1.257.949053775 +FRA/racdb/onlinelog/group_2.258.949053785 +FRA/racdb/onlinelog/group_3.259.949064369 +FRA/racdb/onlinelog/group_4.260.949064379 +RACDB_DATA/racdb/controlfile/current.256.949053757 +RACDB_DATA/racdb/datafile/rac_data1.dbf +RACDB_DATA/racdb/datafile/rac_data2.dbf +RACDB_DATA/racdb/datafile/sysaux.260.949053881 +RACDB_DATA/racdb/datafile/system.259.949053795 +RACDB_DATA/racdb/datafile/undotbs1.261.949053941 +RACDB_DATA/racdb/datafile/undotbs2.263.949054029 +RACDB_DATA/racdb/datafile/users.264.949054051 +RACDB_DATA/racdb/onlinelog/group_1.257.949053771 +RACDB_DATA/racdb/onlinelog/group_2.258.949053781 +RACDB_DATA/racdb/onlinelog/group_3.265.949064363 +RACDB_DATA/racdb/onlinelog/group_4.266.949064373 +RACDB_DATA/racdb/tempfile/rac_temp1.dbf +RACDB_DATA/racdb/tempfile/temp.262.949053963 19 rows selected. 3.ASM 磁盘卷 SQL> SELECT path FROM v$asm_disk; PATH -------------------------------------------------------------------------------- ORCL:CRSVOL1 ORCL:DATAVOL1 ORCL:FRAVOL1 查看11g 数据库实例的alert log及trace 数据库alert日志的路径在： [oracle@racnode1 ~]$ more /u01/app/oracle/diag/rdbms/racdb/racdb1/trace/alert_racdb1.log 查看RAC 11g 集群log及trace grid的日志在： [grid@racnode1 ~]$ cd /u01/app/11.2.0/grid/log/racnode1 [grid@racnode1 racnode1]$ ls admin/ agent/ alertracnode1.log client/ crsd/ cssd/ ctssd/ diskmon/ evmd/ gipcd/ gnsd/ gpnpd/ mdnsd/ ohasd/ racg/ srvm/ [grid@racnode1 racnode1]$ cd crsd [grid@racnode1 crsd]$ ls crsd.l01 crsd.l02 crsd.l03 crsd.l04 crsd.log crsdOUT.log crsd.trc [grid@racnode1 crsd]$ cat crsd.log |more Oracle Database 11g Clusterware Release 11.2.0.1.0 - Production Copyright 1996, 2009 Oracle. All rights reserved. 2017-08-07 10:10:08.735: [UiServer][1516341568] Sending message to PE. ctx= 0x2aaaac09be60 2017-08-07 10:10:08.736: [ CRSCCL][1484839232]clscsend completed:msgTag= 0xcccccccc version= 0 msgType= 0 msgId= 595 msglen = 1160 clschdr.size_clscmsgh= 1248 src= (1, 805586624) dest= (2, 4294883590) 2017-08-07 10:10:08.742: [ CRSCCL][1474349376]clscreceive:msgTag= 0xcccccccc version= 0 msgType= 0 msgId= 603 msglen = 828 clschdr.size_clscmsgh= 916 src= (2, 4294883590) dest= (1, 805586624) 2017-08-07 10:10:08.743: [UiServer][1516341568] Done for ctx=0x2aaaac09be60 2017-08-07 10:10:08.982: [ OCRUTL][1285531968]u_freem: mem passed is null 2017-08-07 10:10:51.772: [UiServer][1518442816] S(0x2aaaac057740): set Properties ( grid,0x3f2dc40) 2017-08-07 10:10:51.783: [UiServer][1516341568] processMessage called 2017-08-07 10:10:51.783: [UiServer][1516341568] Sending message to PE. ctx= 0x2aaaac06bf20 2017-08-07 10:10:51.786: [ CRSCCL][1484839232]clscsend completed:msgTag= 0xcccccccc version= 0 msgType= 0 msgId= 596 msglen = 1116 clschdr.size_clscmsgh= 1204 src= (1, 805586624) dest= (2, 4294883590) 2017-08-07 10:10:51.791: [ CRSCCL][1474349376]clscreceive:msgTag= 0xcccccccc version= 0 msgType= 0 msgId= 604 msglen = 825 clschdr.size_clscmsgh= 913 src= (2, 4294883590) dest= (1, 805586624) 2017-08-07 10:10:51.793: [UiServer][1516341568] Done for ctx=0x2aaaac06bf20 2017-08-07 10:10:51.809: [UiServer][1518442816] S(0x2aaaac050f30): set Properties ( grid,0x3f2dc40) 2017-08-07 10:10:51.820: [UiServer][1516341568] processMessage called 2017-08-07 10:10:51.820: [UiServer][1516341568] Sending message to PE. ctx= 0x2aaaac06cce0 2017-08-07 10:10:51.831: [ CRSCCL][1484839232]clscsend completed:msgTag= 0xcccccccc version= 0 msgType= 0 msgId= 597 msglen = 1127 clschdr.size_clscmsgh= 1215 src= (1, 805586624) dest= (2, 4294883590) 2017-08-07 10:10:51.836: [ CRSCCL][1474349376]clscreceive:msgTag= 0xcccccccc version= 0 msgType= 0 msgId= 605 msglen = 828 clschdr.size_clscmsgh= 916 src= (2, 4294883590) dest= (1, 805586624) 2017-08-07 10:10:51.837: [UiServer][1516341568] Done for ctx=0x2aaaac06cce0 2017-08-07 10:10:51.853: [UiServer][1518442816] S(0x2aaaac0572e0): set Properties ( grid,0x3f1ff20) 2017-08-07 10:10:51.881: [UiServer][1516341568] processMessage called 2017-08-07 10:10:51.881: [UiServer][1516341568] Sending message to PE. ctx= 0x2aaaac086eb0 2017-08-07 10:10:51.885: [ CRSCCL][1484839232]clscsend completed:msgTag= 0xcccccccc version= 0 msgType= 0 msgId= 598 msglen = 1116 clschdr.size_clscmsgh= 1204 src= (1, 805586624) dest= (2, 4294883590) 2017-08-07 10:10:51.890: [ CRSCCL][1474349376]clscreceive:msgTag= 0xcccccccc version= 0 msgType= 0 msgId= 606 msglen = 825 clschdr.size_clscmsgh= 913 src= (2, 4294883590) dest= (1, 805586624) 2017-08-07 10:10:51.891: [UiServer][1516341568] Done for ctx=0x2aaaac086eb0 2017-08-07 10:10:51.906: [UiServer][1518442816] S(0x2aaaac050ad0): set Properties ( grid,0x3f2dc40) 2017-08-07 10:10:51.918: [UiServer][1516341568] processMessage called 2017-08-07 10:10:51.919: [UiServer][1516341568] Sending message to PE. ctx= 0x2aaaac09be30 2017-08-07 10:10:51.971: [ CRSCCL][1484839232]clscsend completed:msgTag= 0xcccccccc version= 0 msgType= 0 msgId= 599 msglen = 1118 clschdr.size_clscmsgh= 1206 src= (1, 805586624) dest= (2, 4294883590) 2017-08-07 10:10:51.976: [ CRSCCL][1474349376]clscreceive:msgTag= 0xcccccccc version= 0 msgType= 0 msgId= 607 msglen = 848 clschdr.size_clscmsgh= 936 src= (2, 4294883590) dest= (1, 805586624) 2017-08-07 10:10:51.977: [UiServer][1516341568] Done for ctx=0x2aaaac09be30 2017-08-07 10:10:52.012: [UiServer][1518442816] S(0x2aaaac064030): set Properties ( grid,0x3f2dc40) 2017-08-07 10:10:52.024: [UiServer][1516341568] processMessage called 2017-08-07 10:10:52.024: [UiServer][1516341568] Sending message to PE. ctx= 0x2aaaac06bf40 2017-08-07 10:10:52.031: [ CRSCCL][1484839232]clscsend completed:msgTag= 0xcccccccc version= 0 msgType= 0 msgId= 600 msglen = 1125 clschdr.size_clscmsgh= 1213 src= (1, 805586624) dest= (2, 4294883590) 2017-08-07 10:10:52.091: [ CRSCCL][1474349376]clscreceive:msgTag= 0xcccccccc version= 0 msgType= 0 msgId= 608 msglen = 830 clschdr.size_clscmsgh= 918 src= (2, 4294883590) dest= (1, 805586624) 2017-08-07 10:10:52.092: [UiServer][1516341568] Done for ctx=0x2aaaac06bf40 2017-08-07 10:10:52.254: [UiServer][1518442816] S(0x2aaaac068cf0): set Properties ( grid,0x3f2dc40) [grid@racnode1 ~]$ cd /u01/app/11.2.0/grid/log/diag/tnslsnr/racnode1/listener_scan1/trace [grid@racnode1 trace]$ ls listener_scan1.log [grid@racnode1 trace]$ cat listener_scan1.log|more Tue Jul 11 08:56:49 2017 Create Relation ADR_CONTROL Create Relation ADR_INVALIDATION Create Relation INC_METER_IMPT_DEF Create Relation INC_METER_PK_IMPTS 系统参数文件为/u01/app/11.2.0/grid/network/admin/listener.ora 写入/u01/app/11.2.0/grid/log/diag/tnslsnr/racnode1/listener_scan1/alert/log.xml的日志信息 写入/u01/app/11.2.0/grid/log/diag/tnslsnr/racnode1/listener_scan1/trace/ora_5279_47079032759072.trc的跟踪信息 跟踪级别当前为0 以 pid=5279 开始 监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=LISTENER_SCAN1))) Listener completed notification to CRS on start TIMESTAMP * CONNECT DATA [* PROTOCOL INFO] * EVENT [* SID] * RETURN CODE 11-7月 -2017 08:56:53 * (CONNECT_DATA=(CID=(PROGRAM=)(HOST=racnode1)(USER=grid))(COMMAND=status)(ARGUMENTS=64)(SERVICE=LISTENER_SCAN1)(VERSION=186646784)) * status * 0 11-7月 -2017 08:56:54 * version * 0 监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=10.236.101.234)(PORT=1521))) 11-7月 -2017 08:56:54 * service_register * LsnrAgt * 0 11-7月 -2017 08:56:54 * (CONNECT_DATA=(CID=(PROGRAM=)(HOST=racnode1)(USER=grid))(COMMAND=status)(ARGUMENTS=64)(SERVICE=LISTENER_SCAN1)(VERSION=186646784)) * status * 0 Tue Jul 11 08:57:54 2017 11-7月 -2017 08:57:54 * (CONNECT_DATA=(CID=(PROGRAM=)(HOST=racnode1)(USER=grid))(COMMAND=status)(ARGUMENTS=64)(SERVICE=LISTENER_SCAN1)(VERSION=186646784)) * status * 0 Tue Jul 11 08:58:54 2017 11-7月 -2017 08:58:54 * (CONNECT_DATA=(CID=(PROGRAM=)(HOST=racnode1)(USER=grid))(COMMAND=status)(ARGUMENTS=64)(SERVICE=LISTENER_SCAN1)(VERSION=186646784)) * status * 0 Tue Jul 11 08:59:54 2017 11-7月 -2017 08:59:54 * (CONNECT_DATA=(CID=(PROGRAM=)(HOST=racnode1)(USER=grid))(COMMAND=status)(ARGUMENTS=64)(SERVICE=LISTENER_SCAN1)(VERSION=186646784)) * status * 0 Tue Jul 11 09:00:54 2017 11-7月 -2017 09:00:54 * (CONNECT_DATA=(CID=(PROGRAM=)(HOST=racnode1)(USER=grid))(COMMAND=status)(ARGUMENTS=64)(SERVICE=LISTENER_SCAN1)(VERSION=186646784)) * status * 0 Tue Jul 11 09:01:54 2017 11-7月 -2017 09:01:54 * (CONNECT_DATA=(CID=(PROGRAM=)(HOST=racnode1)(USER=grid))(COMMAND=status)(ARGUMENTS=64)(SERVICE=LISTENER_SCAN1)(VERSION=186646784)) * status * 0 Tue Jul 11 09:02:54 2017 11-7月 -2017 09:02:54 * (CONNECT_DATA=(CID=(PROGRAM=)(HOST=racnode1)(USER=grid))(COMMAND=status)(ARGUMENTS=64)(SERVICE=LISTENER_SCAN1)(VERSION=186646784)) * status * 0 Tue Jul 11 09:03:54 2017 11-7月 -2017 09:03:54 * (CONNECT_DATA=(CID=(PROGRAM=)(HOST=racnode1)(USER=grid))(COMMAND=status)(ARGUMENTS=64)(SERVICE=LISTENER_SCAN1)(VERSION=186646784)) * status * 0 Tue Jul 11 09:04:54 2017 11-7月 -2017 09:04:54 * (CONNECT_DATA=(CID=(PROGRAM=)(HOST=racnode1)(USER=grid))(COMMAND=status)(ARGUMENTS=64)(SERVICE=LISTENER_SCAN1)(VERSION=186646784)) * status * 0 Tue Jul 11 09:05:54 2017 11-7月 -2017 09:05:54 * (CONNECT_DATA=(CID=(PROGRAM=)(HOST=racnode1)(USER=grid))(COMMAND=status)(ARGUMENTS=64)(SERVICE=LISTENER_SCAN1)(VERSION=186646784)) * status * 0 Tue Jul 11 09:06:54 2017 11-7月 -2017 09:06:54 * (CONNECT_DATA=(CID=(PROGRAM=)(HOST=racnode1)(USER=grid))(COMMAND=status)(ARGUMENTS=64)(SERVICE=LISTENER_SCAN1)(VERSION=186646784)) * status * 0 Tue Jul 11 09:07:54 2017 11-7月 -2017 09:07:54 * (CONNECT_DATA=(CID=(PROGRAM=)(HOST=racnode1)(USER=grid))(COMMAND=status)(ARGUMENTS=64)(SERVICE=LISTENER_SCAN1)(VERSION=186646784)) * status * 0 四、RAC上的数据库运维 1.创建表空间及增加数据文件 SQL> select tablespace_name from dba_tablespaces; TABLESPACE_NAME ------------------------------ SYSTEM SYSAUX UNDOTBS1 TEMP UNDOTBS2 USERS RAC_DATA RAC_TEMP 8 rows selected. SQL> select name from v$datafile union select member from v$logfile union select name from v$controlfile union select name from v$tempfile; NAME -------------------------------------------------------------------------------- +FRA/racdb/controlfile/current.256.949053765 +FRA/racdb/onlinelog/group_1.257.949053775 +FRA/racdb/onlinelog/group_2.258.949053785 +FRA/racdb/onlinelog/group_3.259.949064369 +FRA/racdb/onlinelog/group_4.260.949064379 +RACDB_DATA/racdb/controlfile/current.256.949053757 +RACDB_DATA/racdb/datafile/rac_data1.dbf +RACDB_DATA/racdb/datafile/rac_data2.dbf +RACDB_DATA/racdb/datafile/sysaux.260.949053881 +RACDB_DATA/racdb/datafile/system.259.949053795 +RACDB_DATA/racdb/datafile/undotbs1.261.949053941 +RACDB_DATA/racdb/datafile/undotbs2.263.949054029 +RACDB_DATA/racdb/datafile/users.264.949054051 +RACDB_DATA/racdb/onlinelog/group_1.257.949053771 +RACDB_DATA/racdb/onlinelog/group_2.258.949053781 +RACDB_DATA/racdb/onlinelog/group_3.265.949064363 +RACDB_DATA/racdb/onlinelog/group_4.266.949064373 +RACDB_DATA/racdb/tempfile/rac_temp1.dbf +RACDB_DATA/racdb/tempfile/temp.262.949053963 19 rows selected. [grid@racnode1 ]$ asmcmd ASMCMD> pwd + ASMCMD> ls CRS/ FRA/ RACDB_DATA/ ASMCMD> cd +RACDB_DATA/racdb/datafile/ ASMCMD> pwd +RACDB_DATA/racdb/datafile ASMCMD> ls RAC_DATA.268.950270625 RAC_DATA.269.950274149 SYSAUX.260.949053881 SYSTEM.259.949053795 UNDOTBS1.261.949053941 UNDOTBS2.263.949054029 USERS.264.949054051 rac_data1.dbf rac_data2.dbf ASMCMD> ASMCMD> ls -ls Type Redund Striped Time Sys Block_Size Blocks Bytes Space Name DATAFILE UNPROT COARSE AUG 07 11:00:00 Y 8192 2621441 21474844672 21476933632 RAC_DATA.268.950270625 DATAFILE UNPROT COARSE AUG 07 11:00:00 Y 8192 2621441 21474844672 21476933632 RAC_DATA.269.950274149 DATAFILE UNPROT COARSE AUG 07 11:00:00 Y 8192 147201 1205870592 1207959552 SYSAUX.260.949053881 DATAFILE UNPROT COARSE AUG 07 11:00:00 Y 8192 90881 744497152 746586112 SYSTEM.259.949053795 DATAFILE UNPROT COARSE AUG 07 11:00:00 Y 8192 41601 340795392 342884352 UNDOTBS1.261.949053941 DATAFILE UNPROT COARSE AUG 07 11:00:00 Y 8192 25601 209723392 211812352 UNDOTBS2.263.949054029 DATAFILE UNPROT COARSE AUG 07 11:00:00 Y 8192 641 5251072 6291456 USERS.264.949054051 N rac_data1.dbf => +RACDB_DATA/RACDB/DATAFILE/RAC_DATA.268.950270625 N rac_data2.dbf => +RACDB_DATA/RACDB/DATAFILE/RAC_DATA.269.950274149 ASMCMD> exit [oracle@racnode1 ~]$ sqlplus / as sysdba SQL*Plus: Release 11.2.0.1.0 Production on Mon Aug 7 17:27:46 2017 Copyright (c) 1982, 2009, Oracle. All rights reserved. Connected to: Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit Production With the Partitioning, Real Application Clusters, Automatic Storage Management, OLAP, Data Mining and Real Application Testing options SQL> alter tablespace RAC_DATA add datafile '+RACDB_DATA/racdb/datafile/rac_data3.dbf' size 20G ; Tablespace altered. [grid@racnode1 trace]$ asmcmd ASMCMD> pwd + ASMCMD> cd +RACDB_DATA/racdb/datafile/ ASMCMD> ls -ls Type Redund Striped Time Sys Block_Size Blocks Bytes Space Name DATAFILE UNPROT COARSE AUG 07 11:00:00 Y 8192 2621441 21474844672 21476933632 RAC_DATA.268.950270625 DATAFILE UNPROT COARSE AUG 07 11:00:00 Y 8192 2621441 21474844672 21476933632 RAC_DATA.269.950274149 DATAFILE UNPROT COARSE AUG 07 17:00:00 Y 8192 2621441 21474844672 21476933632 RAC_DATA.271.951411029 DATAFILE UNPROT COARSE AUG 07 11:00:00 Y 8192 147201 1205870592 1207959552 SYSAUX.260.949053881 DATAFILE UNPROT COARSE AUG 07 11:00:00 Y 8192 90881 744497152 746586112 SYSTEM.259.949053795 DATAFILE UNPROT COARSE AUG 07 11:00:00 Y 8192 41601 340795392 342884352 UNDOTBS1.261.949053941 DATAFILE UNPROT COARSE AUG 07 11:00:00 Y 8192 25601 209723392 211812352 UNDOTBS2.263.949054029 DATAFILE UNPROT COARSE AUG 07 11:00:00 Y 8192 641 5251072 6291456 USERS.264.949054051 N rac_data1.dbf => +RACDB_DATA/RACDB/DATAFILE/RAC_DATA.268.950270625 N rac_data2.dbf => +RACDB_DATA/RACDB/DATAFILE/RAC_DATA.269.950274149 N rac_data3.dbf => +RACDB_DATA/RACDB/DATAFILE/RAC_DATA.271.951411029 ASMCMD> ls RAC_DATA.268.950270625 RAC_DATA.269.950274149 RAC_DATA.271.951411029 SYSAUX.260.949053881 SYSTEM.259.949053795 UNDOTBS1.261.949053941 UNDOTBS2.263.949054029 USERS.264.949054051 rac_data1.dbf rac_data2.dbf rac_data3.dbf ASMCMD> SQL> create tablespace RAC_DATA datafile '+RACDB_DATA/racdb/datafile/rac_data1.dbf' size 20G ; Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-24 10:49:08 "},"rac/10.11gRAC-10gRAC.html":{"url":"rac/10.11gRAC-10gRAC.html","title":"11gRAC对比10gRAC","keywords":"","body":" 11g服务的改进 和 11g常用命令 10gRAC的三大服务：CSS, CRS, EVM CSS CRS EVM 11gRAC的服务改进 crsd ohasd clusteware 利用 os 的init 脚本启动的 11g常用命令 检查整个集群状态 在root下关闭整个集群(包括资源) 关闭cluster 后查看状态 启动集群并查看状态 查看数据库的信息 关闭数据库 关闭实例 关闭监听 查看db的状态(10g也用这个) 查看scan的相关信息 查看vip的信息 查看监听信息 查看asm状态 查看磁盘组信息 查看重要的后台进程 crs_stat 查询软件的版本 11g服务的改进 和 11g常用命令 10gRAC的三大服务：CSS, CRS, EVM CSS CSS (clustersynchronization service）自动节点重启 CSS 服务的进程：ocssd、oprocd, oclsomon 这三个进程都具有重启系统的功能 若ocssd 被kill 系统就会重启 oclsomon 负责监控ocssd 的状态 CRS CRS的主进程是crsd 负责启动、关闭、监控资源状态 EVM EVM 进程evmd 11gRAC的服务改进 grid 11.2 把原来的CRS拆分成两份 分别叫CRSD栈和OHASD栈 CRSD负责高级别的资源，如数据库实例 OHASD负责下层级别进程，因此有upper stack 和 lower PS: CRS的配置信息OCR被分成OLR和OCR 其中 OHASD 管理OLR，CRSD管理OCR crsd CRSD专注于 上层（应用层）资源的管理维护 先与CRSD关闭的那些资源是上层资源，CRSD之后关闭的资源就是OHASD的资源了 ohasd OHASD是整个 oracle 进程堆栈的基础据/etc/oracle/scls_scr/目录的控制文件内容决定其他堆栈成员的状态 OHASD栈的启动顺序记录在GPnp profile ,也依赖于OLR中的信息 clusteware 利用 os 的init 脚本启动的 # Run xdm in runlevel 5 x:5:respawn:/etc/X11/prefdm -nodaemon htfa:35:respawn:/etc/init.d/init.tfa run >/dev/null 2>&1 /dev/null 2>&1 11g常用命令 检查整个集群状态 [grid@rac1 ~]$ olsnodes -n rac1 1 rac2 2 [grid@rac1 ~]$ crsctl check crs CRS-4638: Oracle High Availability Services is online CRS-4537: Cluster Ready Services is online CRS-4529: Cluster Synchronization Services is online CRS-4533: Event Manager is online [grid@rac2 ~]$ crsctl check cluster -all ************************************************************** rac1: CRS-4537: Cluster Ready Services is online CRS-4529: Cluster Synchronization Services is online CRS-4533: Event Manager is online ************************************************************** rac2: CRS-4537: Cluster Ready Services is online CRS-4529: Cluster Synchronization Services is online CRS-4533: Event Manager is online ************************************************************** [grid@rac1 ~]$ crsctl status res -t -------------------------------------------------------------------------------- NAME TARGET STATE SERVER STATE_DETAILS 目标状态 当前状态 跑在哪个机器 -------------------------------------------------------------------------------- Local Resources -------------------------------------------------------------------------------- ora.DATA.dg ONLINE ONLINE rac1 ONLINE ONLINE rac2 ora.LISTENER.lsnr ONLINE ONLINE rac1 ONLINE ONLINE rac2 ora.OCRVT.dg ONLINE ONLINE rac1 ONLINE ONLINE rac2 ora.asm ONLINE ONLINE rac1 Started ONLINE ONLINE rac2 Started ora.gsd 这是一个向前兼容（9i rac ）相互兼容的一个服务，管理9i的接口而已，没有9i环境等于无，是正确的 OFFLINE OFFLINE rac1 OFFLINE OFFLINE rac2 ora.net1.network ONLINE ONLINE rac1 ONLINE ONLINE rac2 ora.ons ONLINE ONLINE rac1 ONLINE ONLINE rac2 ora.registry.acfs ONLINE ONLINE rac1 ONLINE ONLINE rac2 -------------------------------------------------------------------------------- Cluster Resources -------------------------------------------------------------------------------- ora.LISTENER_SCAN1.lsnr 1 ONLINE ONLINE rac1 ora.cvu 1 ONLINE ONLINE rac1 ora.oc4j 1 ONLINE ONLINE rac1 ora.rac1.vip 1 ONLINE ONLINE rac1 ora.rac2.vip 1 ONLINE ONLINE rac2 ora.racjiqun.db 1 ONLINE OFFLINE Instance Shutdown,S TARTING 2 ONLINE OFFLINE Instance Shutdown,S TARTING ora.scan1.vip 1 ONLINE ONLINE rac1 [grid@rac1 ~]$ srvctl status nodeapps VIP rac1-vip is enabled VIP rac1-vip is running on node: rac1 VIP rac2-vip is enabled VIP rac2-vip is running on node: rac2 Network is enabled Network is running on node: rac1 Network is running on node: rac2 GSD is disabled GSD is not running on node: rac1 GSD is not running on node: rac2 ONS is enabled ONS daemon is running on node: rac1 ONS daemon is running on node: rac2 在root下关闭整个集群(包括资源) [root@rac1 ~]# cd /home/grid/ [root@rac1 grid]# ls Desktop oradiag_grid [root@rac1 grid]# source .bash_profile [root@rac1 grid]# crsctl stop cluster 关闭1节点的cluster CRS-2673: Attempting to stop 'ora.crsd' on 'rac1' CRS-2790: Starting shutdown of Cluster Ready Services-managed resources on 'rac1' CRS-2673: Attempting to stop 'ora.rac1.vip' on 'rac1' CRS-2673: Attempting to stop 'ora.OCRVT.dg' on 'rac1' CRS-2673: Attempting to stop 'ora.racjiqun.db' on 'rac1' CRS-2673: Attempting to stop 'ora.registry.acfs' on 'rac1' CRS-2677: Stop of 'ora.racjiqun.db' on 'rac1' succeeded CRS-2673: Attempting to stop 'ora.DATA.dg' on 'rac1' CRS-2677: Stop of 'ora.rac1.vip' on 'rac1' succeeded CRS-2672: Attempting to start 'ora.rac1.vip' on 'rac2' CRS-2677: Stop of 'ora.DATA.dg' on 'rac1' succeeded CRS-2677: Stop of 'ora.registry.acfs' on 'rac1' succeeded CRS-2676: Start of 'ora.rac1.vip' on 'rac2' succeeded CRS-2677: Stop of 'ora.OCRVT.dg' on 'rac1' succeeded CRS-2673: Attempting to stop 'ora.asm' on 'rac1' CRS-2677: Stop of 'ora.asm' on 'rac1' succeeded CRS-2673: Attempting to stop 'ora.ons' on 'rac1' CRS-2677: Stop of 'ora.ons' on 'rac1' succeeded CRS-2673: Attempting to stop 'ora.net1.network' on 'rac1' CRS-2677: Stop of 'ora.net1.network' on 'rac1' succeeded CRS-2792: Shutdown of Cluster Ready Services-managed resources on 'rac1' has completed CRS-2677: Stop of 'ora.crsd' on 'rac1' succeeded CRS-2673: Attempting to stop 'ora.ctssd' on 'rac1' CRS-2673: Attempting to stop 'ora.evmd' on 'rac1' CRS-2673: Attempting to stop 'ora.asm' on 'rac1' CRS-2677: Stop of 'ora.evmd' on 'rac1' succeeded CRS-2677: Stop of 'ora.asm' on 'rac1' succeeded CRS-2673: Attempting to stop 'ora.cluster_interconnect.haip' on 'rac1' CRS-2677: Stop of 'ora.cluster_interconnect.haip' on 'rac1' succeeded CRS-2677: Stop of 'ora.ctssd' on 'rac1' succeeded CRS-2673: Attempting to stop 'ora.cssd' on 'rac1' CRS-2677: Stop of 'ora.cssd' on 'rac1' succeeded 关闭cluster 后查看状态 [grid@rac1 ~]$ crsctl check cluster -all ************************************************************** rac1: CRS-4535: Cannot communicate with Cluster Ready Services CRS-4530: Communications failure contacting Cluster Synchronization Services daemon CRS-4534: Cannot communicate with Event Manager ************************************************************** rac2: CRS-4537: Cluster Ready Services is online CRS-4529: Cluster Synchronization Services is online CRS-4533: Event Manager is online ************************************************************** [root@rac2 ~]# cd /home/grid/ [root@rac2 grid]# source .bash_profile [root@rac2 grid]# crsctl stop cluster 关闭2节点的cluster CRS-2673: Attempting to stop 'ora.crsd' on 'rac2' CRS-2790: Starting shutdown of Cluster Ready Services-managed resources on 'rac2' CRS-2673: Attempting to stop 'ora.rac1.vip' on 'rac2' CRS-2673: Attempting to stop 'ora.OCRVT.dg' on 'rac2' CRS-2673: Attempting to stop 'ora.racjiqun.db' on 'rac2' CRS-2673: Attempting to stop 'ora.registry.acfs' on 'rac2' CRS-2673: Attempting to stop 'ora.cvu' on 'rac2' CRS-2673: Attempting to stop 'ora.oc4j' on 'rac2' CRS-2673: Attempting to stop 'ora.LISTENER_SCAN1.lsnr' on 'rac2' CRS-2677: Stop of 'ora.LISTENER_SCAN1.lsnr' on 'rac2' succeeded CRS-2673: Attempting to stop 'ora.scan1.vip' on 'rac2' CRS-2677: Stop of 'ora.cvu' on 'rac2' succeeded CRS-2677: Stop of 'ora.rac1.vip' on 'rac2' succeeded CRS-2673: Attempting to stop 'ora.rac2.vip' on 'rac2' CRS-2677: Stop of 'ora.scan1.vip' on 'rac2' succeeded CRS-2677: Stop of 'ora.racjiqun.db' on 'rac2' succeeded CRS-2673: Attempting to stop 'ora.DATA.dg' on 'rac2' CRS-2677: Stop of 'ora.rac2.vip' on 'rac2' succeeded CRS-2677: Stop of 'ora.DATA.dg' on 'rac2' succeeded CRS-2677: Stop of 'ora.registry.acfs' on 'rac2' succeeded CRS-2677: Stop of 'ora.OCRVT.dg' on 'rac2' succeeded CRS-2673: Attempting to stop 'ora.asm' on 'rac2' CRS-2677: Stop of 'ora.asm' on 'rac2' succeeded CRS-2677: Stop of 'ora.oc4j' on 'rac2' succeeded CRS-2673: Attempting to stop 'ora.ons' on 'rac2' CRS-2677: Stop of 'ora.ons' on 'rac2' succeeded CRS-2673: Attempting to stop 'ora.net1.network' on 'rac2' CRS-2677: Stop of 'ora.net1.network' on 'rac2' succeeded CRS-2792: Shutdown of Cluster Ready Services-managed resources on 'rac2' has completed CRS-2677: Stop of 'ora.crsd' on 'rac2' succeeded CRS-2673: Attempting to stop 'ora.ctssd' on 'rac2' CRS-2673: Attempting to stop 'ora.evmd' on 'rac2' CRS-2673: Attempting to stop 'ora.asm' on 'rac2' CRS-2677: Stop of 'ora.evmd' on 'rac2' succeeded CRS-2677: Stop of 'ora.asm' on 'rac2' succeeded CRS-2673: Attempting to stop 'ora.cluster_interconnect.haip' on 'rac2' CRS-2677: Stop of 'ora.ctssd' on 'rac2' succeeded CRS-2677: Stop of 'ora.cluster_interconnect.haip' on 'rac2' succeeded CRS-2673: Attempting to stop 'ora.cssd' on 'rac2' CRS-2677: Stop of 'ora.cssd' on 'rac2' succeeded [grid@rac1 ~]$ crsctl check cluster -all ************************************************************** rac1: CRS-4535: Cannot communicate with Cluster Ready Services CRS-4530: Communications failure contacting Cluster Synchronization Services daemon CRS-4534: Cannot communicate with Event Manager ************************************************************** rac2: CRS-4535: Cannot communicate with Cluster Ready Services CRS-4530: Communications failure contacting Cluster Synchronization Services daemon CRS-4534: Cannot communicate with Event Manager ************************************************************** 启动集群并查看状态 [root@rac1 grid]# crsctl start cluster -all CRS-2672: Attempting to start 'ora.cssdmonitor' on 'rac1' CRS-2672: Attempting to start 'ora.cssdmonitor' on 'rac2' CRS-2676: Start of 'ora.cssdmonitor' on 'rac1' succeeded CRS-2672: Attempting to start 'ora.cssd' on 'rac1' CRS-2672: Attempting to start 'ora.diskmon' on 'rac1' CRS-2676: Start of 'ora.cssdmonitor' on 'rac2' succeeded CRS-2672: Attempting to start 'ora.cssd' on 'rac2' CRS-2672: Attempting to start 'ora.diskmon' on 'rac2' CRS-2676: Start of 'ora.diskmon' on 'rac2' succeeded CRS-2676: Start of 'ora.diskmon' on 'rac1' succeeded CRS-2676: Start of 'ora.cssd' on 'rac2' succeeded CRS-2676: Start of 'ora.cssd' on 'rac1' succeeded CRS-2672: Attempting to start 'ora.ctssd' on 'rac2' CRS-2672: Attempting to start 'ora.ctssd' on 'rac1' CRS-2676: Start of 'ora.ctssd' on 'rac2' succeeded CRS-2672: Attempting to start 'ora.evmd' on 'rac2' CRS-2672: Attempting to start 'ora.cluster_interconnect.haip' on 'rac2' CRS-2676: Start of 'ora.ctssd' on 'rac1' succeeded CRS-2672: Attempting to start 'ora.evmd' on 'rac1' CRS-2672: Attempting to start 'ora.cluster_interconnect.haip' on 'rac1' CRS-2676: Start of 'ora.evmd' on 'rac2' succeeded CRS-2676: Start of 'ora.evmd' on 'rac1' succeeded CRS-2676: Start of 'ora.cluster_interconnect.haip' on 'rac1' succeeded CRS-2672: Attempting to start 'ora.asm' on 'rac1' CRS-2676: Start of 'ora.cluster_interconnect.haip' on 'rac2' succeeded CRS-2672: Attempting to start 'ora.asm' on 'rac2' CRS-2676: Start of 'ora.asm' on 'rac2' succeeded CRS-2672: Attempting to start 'ora.crsd' on 'rac2' CRS-2676: Start of 'ora.asm' on 'rac1' succeeded CRS-2672: Attempting to start 'ora.crsd' on 'rac1' CRS-2676: Start of 'ora.crsd' on 'rac2' succeeded CRS-2676: Start of 'ora.crsd' on 'rac1' succeeded [root@rac1 ~]# ps -ef|grep smon root 3151 1 0 16:32 ? 00:00:08 /oracle/gridjia/grid/bin/osysmond.bin grid 3950 1 0 16:34 ? 00:00:00 asm_smon_+ASM1 oracle 8080 1 0 16:59 ? 00:00:00 ora_smon_racjiqun1 root 9816 9561 0 17:13 pts/3 00:00:00 grep smon [root@rac2 ~]# ps -ef|grep smon root 3097 1 0 16:32 ? 00:00:05 /oracle/gridjia/grid/bin/osysmond.bin grid 3875 1 0 16:34 ? 00:00:00 asm_smon_+ASM2 oracle 7301 1 0 16:55 ? 00:00:00 ora_smon_racjiqun2 root 9976 9923 0 17:14 pts/2 00:00:00 grep smon 查看数据库的信息 [grid@rac1 ~]$ srvctl config database -d racjiqun Database unique name: racjiqun Database name: racjiqun Oracle home: /oracle/app/oracle/11.2.4/db_1 Oracle user: oracle Spfile: +DATA/racjiqun/spfileracjiqun.ora Domain: Start options: open Stop options: immediate Database role: PRIMARY Management policy: AUTOMATIC Server pools: racjiqun Database instances: racjiqun1,racjiqun2 Disk Groups: DATA Mount point paths: Services: Type: RAC Database is administrator managed [grid@rac1 ~]$ srvctl status database -d racjiqun Instance racjiqun1 is running on node rac1 Instance racjiqun2 is running on node rac2 关闭数据库 [grid@rac1 ~]$ srvctl stop database -d racjiqun [grid@rac1 ~]$ srvctl status database -d racjiqun Instance racjiqun1 is not running on node rac1 Instance racjiqun2 is not running on node rac2 关闭实例 [grid@rac2 ~]$ srvctl stop instance -d racjiqun -i racjiqun1 -o immediate [grid@rac2 ~]$ srvctl status database -d racjiqun Instance racjiqun1 is not running on node rac1 Instance racjiqun2 is running on node rac2 关闭监听 [grid@rac2 ~]$ srvctl stop listener [grid@rac2 ~]$ srvctl status listener Listener LISTENER is enabled Listener LISTENER is not running 查看db的状态(10g也用这个) [grid@rac1 ~]$ crs_stat ora.racjiqun.db NAME=ora.racjiqun.db TYPE=ora.database.type TARGET=ONLINE STATE=ONLINE on rac1 查看scan的相关信息 [grid@rac1 ~]$ srvctl config scan SCAN name: rac-scan, Network: 1/192.168.10.0/255.255.255.0/eth0 SCAN VIP name: scan1, IP: /rac-scan/192.168.10.200 [grid@rac1 ~]$ srvctl status scan SCAN VIP scan1 is enabled SCAN VIP scan1 is running on node rac1 [grid@rac1 ~]$ srvctl status scan_listener SCAN Listener LISTENER_SCAN1 is enabled SCAN listener LISTENER_SCAN1 is running on node rac1 查看vip的信息 [grid@rac1 ~]$ srvctl config vip -n rac1 VIP exists: /rac1-vip/192.168.10.110/192.168.10.0/255.255.255.0/eth0, hosting node rac1 查看监听信息 [grid@rac1 ~]$ srvctl config listener -a 本地监听 Name: LISTENER Network: 1, Owner: grid Home: /oracle/gridhome/grid on node(s) rac1,rac2 End points: TCP:1521 [grid@rac1 ~]$ srvctl status listener Listener LISTENER is enabled Listener LISTENER is running on node(s): rac2,rac1 查看asm状态 [grid@rac1 ~]$ srvctl status asm -a ASM is running on rac2,rac1 ASM is enabled. 查看磁盘组信息 [grid@rac1 ~]$ srvctl status diskgroup -g DATA Disk Group DATA is running on rac2,rac1 查看重要的后台进程 [grid@rac1 ~]$ crsctl status res -t -init -------------------------------------------------------------------------------- NAME TARGET STATE SERVER STATE_DETAILS -------------------------------------------------------------------------------- Cluster Resources -------------------------------------------------------------------------------- ora.asm 1 ONLINE ONLINE rac1 Started ora.cluster_interconnect.haip 1 ONLINE ONLINE rac1 ora.crf 1 ONLINE ONLINE rac1 ora.crsd 1 ONLINE ONLINE rac1 ora.cssd 1 ONLINE ONLINE rac1 ora.cssdmonitor 1 ONLINE ONLINE rac1 ora.ctssd 1 ONLINE ONLINE rac1 ACTIVE:0 ora.diskmon 1 OFFLINE OFFLINE ora.drivers.acfs 1 ONLINE ONLINE rac1 ora.evmd 1 ONLINE ONLINE rac1 ora.gipcd 1 ONLINE ONLINE rac1 ora.gpnpd 1 ONLINE ONLINE rac1 ora.mdnsd 1 ONLINE ONLINE rac1 [grid@rac1 ~]$ crs_stat -t -v Name Type R/RA F/FT Target State Host ---------------------------------------------------------------------- ora.DATA.dg ora....up.type 0/5 0/ ONLINE ONLINE rac1 ora....ER.lsnr ora....er.type 0/5 0/ ONLINE ONLINE rac1 ora....N1.lsnr ora....er.type 0/5 0/0 ONLINE ONLINE rac2 ora.OCRVT.dg ora....up.type 0/5 0/ ONLINE ONLINE rac1 ora.asm ora.asm.type 0/5 0/ ONLINE ONLINE rac1 ora.cvu ora.cvu.type 0/5 0/0 ONLINE ONLINE rac2 ora.gsd ora.gsd.type 0/5 0/ OFFLINE OFFLINE ora....network ora....rk.type 0/5 0/ ONLINE ONLINE rac1 ora.oc4j ora.oc4j.type 0/1 0/2 ONLINE ONLINE rac2 ora.ons ora.ons.type 0/3 0/ ONLINE ONLINE rac1 ora....SM1.asm application 0/5 0/0 ONLINE ONLINE rac1 ora....C1.lsnr application 0/5 0/0 ONLINE ONLINE rac1 ora.rac1.gsd application 0/5 0/0 OFFLINE OFFLINE ora.rac1.ons application 0/3 0/0 ONLINE ONLINE rac1 ora.rac1.vip ora....t1.type 0/0 0/0 ONLINE ONLINE rac1 ora....SM2.asm application 0/5 0/0 ONLINE ONLINE rac2 ora....C2.lsnr application 0/5 0/0 ONLINE ONLINE rac2 ora.rac2.gsd application 0/5 0/0 OFFLINE OFFLINE ora.rac2.ons application 0/3 0/0 ONLINE ONLINE rac2 ora.rac2.vip ora....t1.type 0/0 0/0 ONLINE ONLINE rac2 ora....iqun.db ora....se.type 0/2 0/1 ONLINE ONLINE rac1 ora....ry.acfs ora....fs.type 0/5 0/ ONLINE ONLINE rac1 ora.scan1.vip ora....ip.type 0/0 0/0 ONLINE ONLINE rac2 crs_stat crs_stat这个命令用于查看CRS维护的所有资源的运行状态，如果不带任何参数时，显示所有资源的概要信息。每个资源显示是各个属性：资源名称，类型，目录，资源运行状态等。 也可以指定资源名，查看指定资源的状态，并可以使用-V和-P选项，以查看详细信息，其中-p参数显示的内容比-V更详细。 [grid@rac1 ~]$ crs_stat -v ora.racjiqun.db NAME=ora.racjiqun.db TYPE=ora.database.type GEN_START_OPTIONS@SERVERNAME(rac1)=open GEN_START_OPTIONS@SERVERNAME(rac2)=open GEN_USR_ORA_INST_NAME@SERVERNAME(rac1)=racjiqun1 GEN_USR_ORA_INST_NAME@SERVERNAME(rac2)=racjiqun2 RESTART_ATTEMPTS=2 RESTART_COUNT=0 USR_ORA_INST_NAME@SERVERNAME(rac1)=racjiqun1 USR_ORA_INST_NAME@SERVERNAME(rac2)=racjiqun2 FAILURE_THRESHOLD=1 FAILURE_COUNT=0 TARGET=ONLINE STATE=ONLINE on rac1 [grid@rac1 ~]$ crs_stat -p ora.racjiqun.db NAME=ora.racjiqun.db TYPE=ora.database.type ACTION_SCRIPT= ACTIVE_PLACEMENT=1 AUTO_START=restore CHECK_INTERVAL=1 DESCRIPTION=Oracle Database resource FAILOVER_DELAY=0 FAILURE_INTERVAL=60 FAILURE_THRESHOLD=1 GEN_START_OPTIONS@SERVERNAME(rac1)=open GEN_START_OPTIONS@SERVERNAME(rac2)=open GEN_USR_ORA_INST_NAME@SERVERNAME(rac1)=racjiqun1 GEN_USR_ORA_INST_NAME@SERVERNAME(rac2)=racjiqun2 HOSTING_MEMBERS= PLACEMENT=restricted RESTART_ATTEMPTS=2 SCRIPT_TIMEOUT=60 START_TIMEOUT=600 STOP_TIMEOUT=600 UPTIME_THRESHOLD=1h USR_ORA_INST_NAME@SERVERNAME(rac1)=racjiqun1 USR_ORA_INST_NAME@SERVERNAME(rac2)=racjiqun2 查询软件的版本 [grid@rac1 ~]$ crsctl query crs activeversion Oracle Clusterware active version on the cluster is [11.2.0.4.0] [grid@rac1 ~]$ crsctl query crs releaseversion Oracle High Availability Services release version on the local node is [11.2.0.4.0] Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-10 14:53:35 "},"rac/34.11gRAC的监听介绍.html":{"url":"rac/34.11gRAC的监听介绍.html","title":"11gRAC的监听介绍","keywords":"","body":" 11gRAC的监听 一、IP的概念 1.Public IP 2.Private IP 3.Virtual IP 二、监听的基本概念 1. 11gRAC的监听又分为本地监听和scan监听 2. 10g监听与11g监听的对比 三、监听器管理 1.基本配置信息 2.查看scan vip配置 3.查看scan vip状态 4.查看scan listener配置 5.查看scan listener状态 6.查看本地监听器配置 7.查看本地监听器状态 8.查看本地运行的监听器 9.资源查看 四、使用srvctl 添加静态监听 1.添加监听 2.执行添加监听操作 查询监听状态 3.启动监听 4.查看新建的监听状态 5.查看监听配置文件 6.加入静态注册信息 7.启动监听不加参数默认是在两个节点同时启动 8.查询监听LISTENER_TEST状态 五、11gRAC的监听排错步骤 1.在任意节点上使用tnsnames.ORA通过scan-ip登陆数据库 2.检查RAC上的scan-ip配置 3.DNS测试 4.ping三个scan-ip 5.在任意客户端测试可否登陆 6.检查监听器配置 7.检查数据库两个与监听相关的参数 11gRAC的监听 一、IP的概念 1.Public IP 这是网卡上配置的真实IP地址，我们称为公共IP，这个IP的存在关系到 VIP 能不能正确漂在其所在网卡上 注意，PUBLIC IP是不提供给客户端去连接配置的，这并不是说通过 PUBLIC IP 无法连接实例，而是当节点服务器宕机时，所有向它请求连接的客户端都会有等待现象并且最后得到超时信息 2.Private IP 称为私网 IP（私有IP），它是用于心跳同步的，也就是保证两台服务器数据同步 Oracle另一个高可用性连接特性（HAIP） 其实 Cache Fusion 会消耗节点服务器很大的私网资源，另外，私网间无法通信还会引起 brain split(脑裂)，以前为解决这种问题，我们可以采用网卡 bonding 技术，而 Oracle 在 11g R2 的时候通过 HAIP 技术来实现 HAIP(Highly Available Virtual IP)用于节点间的私网通信，支持同时使用多个网络连接来满足网卡间的负载均衡，并且还提高了Cache Fusion 资源通信能力 3.Virtual IP RAC 的每个节点都需要有一个虚拟IP，这就是VIP VIP 会绑定到节点的 public 网卡上，需要和 PUBLIC IP同一个子网，它们是由 GI 的 Clusterware 来管理的 VIP 在其节点服务器发生故障的时候会自动漂移到另外正常的节点服务器上，如果 RAC 是多节点运行的，那具体漂移到哪个活动的节点将由Clusterware 决定 等故障节点恢复正常，漂移的 VIP 也回到此节点上，继续提供服务 二、监听的基本概念 Oracle11gR2 RAC开始引入scan概念，一般通过dns服务器或gns服务器解析scan，也可以使用/etc/hosts文件解析scan，只不过oracle官方不建议这样做，hosts文件只能解析一个scan ip 监听器前移到$GRID_HOME/network/admin/listener.ora文件，即11g rac监听器由grid用户管理，oracle用户保留文件，但已经不起作用。客户端文件tnsnames.ora依然在$ORACLE_HOME/network/admin/tnsnames.ora文件。 scan的提出彻底做到了rac数据库对用户的透明管理，客户端通过scan域名直接连接数据库即可（首先客户端可以解析scan域名），具体由DNS服务器解析域名，这里如果用dns解析scan，最多可以解析3个scan vip，通过scan域名访问数据库可以实现scan vip的failover和负载均衡，即只要3个scan vip中存活一个，客户端应用既可以访问数据库。 如果采用hosts文件解析scan，只能解析一个scan vip。 1. 11gRAC的监听又分为本地监听和scan监听 1.1 LOCAL LISTENER 本地监听，RAC 的每个节点上都会有独立的本地监听，它会监听该节点的 PUBLIC IP 和 VIP。 每个节点的实例在启动的时候向本地监听进行注册，当 VIP 或者PUBLIC IP (这种情况比较少见)有连接请求的时候，本地监听就接受处理并和本地实例建立连接。如果某个节点故障，其上面的VIP会进行漂移，但本地监听并不会产生漂移。 1.2 SCAN LISTENER： SCAN 监听，它是实现 SCAN 负载均衡的原理。 SCAN 监听跟着 SCAN VIP 随机分配到节点服务器上，如果某个节点发生故障，运行在此节点上的 SCAN VIP 会进行漂移，这时候 SCAN 监听也跟着漂移到正常的节点上，继续为 SCAN VIP 监听连接请求，当 PMON 进程下次动态更新实例信息到该 SCAN 监听后，它又重新接受客户端的连接。 2. 10g监听与11g监听的对比 Oracle 10g rac中监听器由oracle用户管理，每个节点上，只有一个监听器，但是这个监听器同时监听public ip和vip，即oracle 10g rac中的监听器同时承担着路由选择和建立连接的功能。10g rac客户端通过vip连接数据库。 Oracle 11g rac中使用GRID_HOME下的监听器而不采用ORACLE_HOME 下的监听器，同时在Oracle 11g rac中出现了多个监听器，使用名称区分。所以11g rac的监听器使用grid用户管理，而不通过oracle用户进行管理。11g rac监听器分本地监听器（建立连接）和scan监听器（路由转发）2种，另外，每一个scan vip都会有一个scan监听器，并且运行在同一个节点上。即： 每个节点上都运行一个本地监听器，这个监听器负责监听本地的vip。 凡是scan ip漂移到的节点,都会运行scan监听器。 scanvip和scan监听器成对出现。 三、监听器管理 1.基本配置信息 [grid@node1 admin]$ pwd /u01/app/11.2.0/grid/network/admin [grid@node1 admin]$ cat listener.ora # listener.ora.node1 Network Configuration File: /u01/app/11.2.0/grid/network/admin/listener.ora.node1 # Generated by Oracle configuration tools. ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER_SCAN3 = ON ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER_SCAN2 = ON ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER_SCAN1 = ON ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER1 = ON LISTENER = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = IPC)(KEY = LISTENER)) ) ) ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER = ON LISTENER_SCAN3 = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = IPC)(KEY = LISTENER_SCAN3)) ) ) LISTENER_SCAN2 = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = IPC)(KEY = LISTENER_SCAN2)) ) ) LISTENER_SCAN1 = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = IPC)(KEY = LISTENER_SCAN1)) ) ) 节点2 listener.ora配置： [grid@node2 admin]$ pwd /u01/app/11.2.0/grid/network/admin [grid@node2 admin]$ cat listener.ora # listener.ora.node2 Network Configuration File: /u01/app/11.2.0/grid/network/admin/listener.ora.node2 # Generated by Oracle configuration tools. ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER_SCAN3 = ON ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER_SCAN2 = ON ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER_SCAN1 = ON ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER1 = ON SID_LIST_LISTENER1 = (SID_LIST = (SID_DESC = (GLOBAL_DBNAME = orcl) (ORACLE_HOME = /u01/app/11.2.0/grid) (SID_NAME = orcl2) ) ) LISTENER = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = LISTENER)) ) ADR_BASE_LISTENER = /u01/app/grid ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER = ON LISTENER_SCAN3 = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = LISTENER_SCAN3)) ) LISTENER_SCAN2 = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = LISTENER_SCAN2)) ) LISTENER_SCAN1 = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = LISTENER_SCAN1)) ) ADR_BASE_LISTENER_SCAN3 = /u01/app/grid ADR_BASE_LISTENER_SCAN2 = /u01/app/grid ADR_BASE_LISTENER_SCAN1 = /u01/app/grid 说明： local_listener 默认不需要配置，默认配置指向1521端口，对于单实例改变端口需要指向tns里的连接字符串，而在rac配置中默认指向本节点的vip。 remote_listener指向的是scan监听名，需要远程监的配置。 Oracle 11.2版本后，有一个新的监听文件endpoints_listener.ora被引进，里面的内容是节点的IP和VIP信息 。 Endpoints_listener.ora 文件的作用是向后兼容11.2版本以前的数据库，DBCA建库时，需要通过获取endpoints的位置信息来配置数据库参数和tnsnames，其中最下面两行参数涉及ENABLE_GLOBAL_DYNAMIC_ENDPOINT参数，该参数的作用是允许监听程序接受针对oracle 11.2版本之前未进行动态注册的连接。 2.查看scan vip配置 [grid@node1 admin]$ srvctl config scan SCAN name: scan-cluster, Network: 1/192.168.100.0/255.255.255.0/eth0 SCAN VIP name: scan1, IP: /scan-cluster/192.168.100.45 SCAN VIP name: scan2, IP: /scan-cluster/192.168.100.46 SCAN VIP name: scan3, IP: /scan-cluster/192.168.100.47 3.查看scan vip状态 [grid@node1 admin]$ srvctl status scan SCAN VIP scan1 is enabled SCAN VIP scan1 is running on node node2 SCAN VIP scan2 is enabled SCAN VIP scan2 is running on node node2 SCAN VIP scan3 is enabled SCAN VIP scan3 is running on node node1 4.查看scan listener配置 [grid@node1 admin]$ srvctl config scan_listener SCAN Listener LISTENER_SCAN1 exists. Port: TCP:1521 SCAN Listener LISTENER_SCAN2 exists. Port: TCP:1521 SCAN Listener LISTENER_SCAN3 exists. Port: TCP:1521 5.查看scan listener状态 [grid@node1 admin]$ srvctl status scan_listener SCAN Listener LISTENER_SCAN1 is enabled SCAN listener LISTENER_SCAN1 is running on node node2 SCAN Listener LISTENER_SCAN2 is enabled SCAN listener LISTENER_SCAN2 is running on node node2 SCAN Listener LISTENER_SCAN3 is enabled SCAN listener LISTENER_SCAN3 is running on node node1 6.查看本地监听器配置 节点1： [grid@node1 admin]$ srvctl config listener Name: LISTENER Network: 1, Owner: grid Home: End points: TCP:1521 节点2： [grid@node2 admin]$ srvctl config listener Name: LISTENER Network: 1, Owner: grid Home: End points: TCP:1521 7.查看本地监听器状态 节点1： [grid@node1 admin]$ srvctl status listener Listener LISTENER is enabled Listener LISTENER is running on node(s): node2,node1 节点2： [grid@node2 admin]$ srvctl status listener Listener LISTENER is enabled Listener LISTENER is running on node(s): node2,node1 8.查看本地运行的监听器 节点1： [grid@node1 admin]$ ps -ef|grep lsnr grid 6290 8174 0 16:12 pts/1 00:00:00 grep lsnr grid 23796 1 0 11:24 ? 00:00:00 /u01/app/11.2.0/grid/bin/tnslsnr LISTENER_SCAN3 -inherit grid 23859 1 0 11:24 ? 00:00:00 /u01/app/11.2.0/grid/bin/tnslsnr LISTENER -inherit 节点2： [grid@node2 admin]$ ps -ef|grep lsnr grid 8649 1 0 11:44 ? 00:00:00 /u01/app/11.2.0/grid/bin/tnslsnr LISTENER_SCAN2 -inherit grid 10591 1 0 Mar24 ? 00:00:01 /u01/app/11.2.0/grid/bin/tnslsnr LISTENER -inherit grid 18776 6639 0 16:13 pts/1 00:00:00 grep lsnr grid 24334 1 0 Mar24 ? 00:00:02 /u01/app/11.2.0/grid/bin/tnslsnr LISTENER_SCAN1 -inherit 9.资源查看 [grid@node2 admin]$ crsctl stat res -t -------------------------------------------------------------------------------- NAME TARGET STATE SERVER STATE_DETAILS -------------------------------------------------------------------------------- Local Resources -------------------------------------------------------------------------------- ora.DATA.dg ONLINE ONLINE node1 ONLINE ONLINE node2 ora.FRA.dg ONLINE ONLINE node1 ONLINE ONLINE node2 ora.LISTENER.lsnr ONLINE ONLINE node1 ONLINE ONLINE node2 ora.OCRVOTE.dg ONLINE ONLINE node1 ONLINE ONLINE node2 ora.asm ONLINE ONLINE node1 Started ONLINE ONLINE node2 Started ora.gsd OFFLINE OFFLINE node1 OFFLINE OFFLINE node2 ora.net1.network ONLINE ONLINE node1 ONLINE ONLINE node2 ora.ons ONLINE ONLINE node1 ONLINE ONLINE node2 ora.registry.acfs ONLINE ONLINE node1 ONLINE ONLINE node2 -------------------------------------------------------------------------------- Cluster Resources -------------------------------------------------------------------------------- ora.LISTENER_SCAN1.lsnr 1 ONLINE ONLINE node2 ora.cvu 1 ONLINE ONLINE node2 ora.node.db 1 ONLINE ONLINE node1 Open 2 ONLINE ONLINE node2 Open ora.node1.vip 1 ONLINE ONLINE node1 ora.node2.vip 1 ONLINE ONLINE node2 ora.oc4j 1 ONLINE ONLINE node2 ora.scan1.vip 1 ONLINE ONLINE node2 [grid@node2 admin]$ 发现本地监听在ora.LISTENER.lsnr各自online,而scan监听ora.LISTENER_SCAN1.lsnr在节点2上online； 四、使用srvctl 添加静态监听 参考: http://www.askmaclean.com/archives/11gr2-rac-add-listener-static-register.html 1.添加监听 在grid用户下执行 [grid@node2 admin]$ srvctl config network Network exists: 1/192.168.56.0/255.255.255.0/eth0, type static [grid@node2 admin]$ [grid@node2 admin]$ srvctl add listener -h Adds a listener configuration to the Oracle Clusterware. Usage: srvctl add listener [-l ] [-s] [-p \"[TCP:][, ...][/IPC:][/NMP:][/TCPS:] [/SDP:]\"] [-o ] [-k ] -l Listener name (default name is LISTENER) -o ORACLE_HOME path (default value is CRS_HOME) -k network number (default number is 1) -s Skip the checking of ports -p \"[TCP:][, ...][/IPC:][/NMP:][/TCPS:] [/SDP:]\" Comma separated tcp ports or listener endpoints -h Print usage -k 填入方才获得的network number，-p填入端口号，-l填入监听名，-o 填入GI HOME路径 2.执行添加监听操作 [grid@node2 admin]$ srvctl add listener -l LISTENER_TEST -o $ORACLE_HOME -p 1522 -k 1 [grid@node2 admin]$ 查询监听状态 [grid@node2 admin]$ srvctl status listener -h Displays the current state of the listener. Usage: srvctl status listener [-l ] [-n ] [-v] -l Listener name -n Node name -v Verbose output -h Print usage [grid@node2 admin]$ srvctl status listener -l LISTENER_TEST Listener LISTENER_TEST is enabled Listener LISTENER_TEST is not running [grid@node2 admin]$ 3.启动监听 [grid@node2 admin]$ srvctl start listener -l LISTENER_TEST 4.查看新建的监听状态 [grid@node2 admin]$ lsnrctl status LISTENER_TEST LSNRCTL for Linux: Version 11.2.0.4.0 - Production on 19-OCT-2017 15:29:46 Copyright (c) 1991, 2013, Oracle. All rights reserved. Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER_TEST))) STATUS of the LISTENER ------------------------ Alias LISTENER_TEST Version TNSLSNR for Linux: Version 11.2.0.4.0 - Production Start Date 19-OCT-2017 15:29:12 Uptime 0 days 0 hr. 0 min. 35 sec Trace Level off Security ON: Local OS Authentication SNMP OFF Listener Parameter File /oracle/app/11.2.0/grid/network/admin/listener.ora Listener Log File /oracle/app/11.2.0/grid/log/diag/tnslsnr/node2/LISTENER_TEST/alert/log.xml Listening Endpoints Summary... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=LISTENER_TEST))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=192.168.56.4)(PORT=1522))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=192.168.56.5)(PORT=1522))) The listener supports no services The command completed successfully [grid@node2 admin]$ 5.查看监听配置文件 srvctl start listener启动新添加的监听后listener.ora和endpoints_listener.ora会出现新的记录 [grid@node2 admin]$ cat listener.ora LISTENER_TEST=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER_TEST)))) # line added by Agent LISTENER_SCAN1=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER_SCAN1)))) # line added by Agent LISTENER=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER)))) # line added by Agent ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER=ON # line added by Agent ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER_SCAN1=ON # line added by Agent #----ADDED BY TNSLSNR 19-OCT-2017 10:31:25--- PASSWORDS_LISTENER = 1DF5C2FD0FE9CFA2 #-------------------------------------------- ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER_TEST=ON # line added by Agent [grid@node2 admin]$ [grid@node2 admin]$ cat endpoints_listener.ora LISTENER_TEST_node2=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=TCP)(HOST=node2-vip)(PORT=1522))(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.56.4)(PORT=1522)(IP=FIRST))))# line added by Agent LISTENER_node2=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=TCP)(HOST=node2-vip)(PORT=1521))(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.56.4)(PORT=1521)(IP=FIRST)))) # line added by Agent [grid@node2 admin]$ 6.加入静态注册信息 SID_LIST_LISTENER_TEST = (SID_LIST = (SID_DESC = (GLOBAL_DBNAME = node) (ORACLE_HOME = /oracle/app/11.2.0/grid) (SID_NAME=node2) ) ) 加入如上信息到listener.ora配置文件中(SIDLIST($LISTENER_NAME)，并重启监听即完成静态注册： [grid@node2 admin]$ srvctl status listener -l LISTENER_TEST Listener LISTENER_TEST is enabled Listener LISTENER_TEST is running on node(s): node1,node2 [grid@node2 admin]$ [grid@node2 admin]$ srvctl stop listener -l LISTENER_TEST [grid@node2 admin]$ [grid@node2 admin]$ srvctl status listener -l LISTENER_TEST Listener LISTENER_TEST is enabled Listener LISTENER_TEST is not running [grid@node2 admin]$ [grid@node2 admin]$ srvctl start listener -l LISTENER_TEST -n node2 [grid@node2 admin]$ [grid@node2 admin]$ srvctl status listener -l LISTENER_TEST Listener LISTENER_TEST is enabled Listener LISTENER_TEST is running on node(s): node2 命令srvctl start listener -l LISTENER_TEST -n node2只在一个节点启动监听 7.启动监听不加参数默认是在两个节点同时启动 [grid@node2 admin]$ srvctl stop listener -l LISTENER_TEST [grid@node2 admin]$ [grid@node2 admin]$ srvctl status listener -l LISTENER_TEST Listener LISTENER_TEST is enabled Listener LISTENER_TEST is not running [grid@node2 admin]$ [grid@node2 admin]$ srvctl start listener -l LISTENER_TEST -n node1,node2 PRKO-2003 : Invalid command line option value: node1,node2 [grid@node2 admin]$ [grid@node2 admin]$ srvctl start listener -l LISTENER_TEST [grid@node2 admin]$ [grid@node2 admin]$ srvctl status listener -l LISTENER_TEST Listener LISTENER_TEST is enabled Listener LISTENER_TEST is running on node(s): node1,node2 8.查询监听LISTENER_TEST状态 [grid@node2 admin]$ lsnrctl status LISTENER_TEST LSNRCTL for Linux: Version 11.2.0.4.0 - Production on 19-OCT-2017 16:08:14 Copyright (c) 1991, 2013, Oracle. All rights reserved. Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER_TEST))) STATUS of the LISTENER ------------------------ Alias LISTENER_TEST Version TNSLSNR for Linux: Version 11.2.0.4.0 - Production Start Date 19-OCT-2017 16:05:30 Uptime 0 days 0 hr. 2 min. 43 sec Trace Level off Security ON: Local OS Authentication SNMP OFF Listener Parameter File /oracle/app/11.2.0/grid/network/admin/listener.ora Listener Log File /oracle/app/11.2.0/grid/log/diag/tnslsnr/node2/LISTENER_TEST/alert/log.xml Listening Endpoints Summary... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=LISTENER_TEST))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=192.168.56.4)(PORT=1522))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=192.168.56.5)(PORT=1522))) Services Summary... Service \"node\" has 1 instance(s). Instance \"node2\", status UNKNOWN, has 1 handler(s) for this service... The command completed successfully [grid@node2 admin]$ 附上节点一的监听配置信息： [grid@node1 admin]$ cat listener.ora LISTENER_TEST=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER_TEST)))) # line added by Agent LISTENER=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER)))) # line added by Agent LISTENER_SCAN1=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER_SCAN1)))) # line added by Agent ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER_SCAN1=ON # line added by Agent ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER=ON # line added by Agent ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER_TEST=ON # line added by Agent [grid@node1 admin]$ [grid@node1 admin]$ cat endpoints_listener.ora LISTENER_TEST_node1=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=TCP)(HOST=node1-vip)(PORT=1522))(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.56.2)(PORT=1522)(IP=FIRST))))# line added by Agent LISTENER_node1=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=TCP)(HOST=node1-vip)(PORT=1521))(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.56.2)(PORT=1521)(IP=FIRST)))) # line added by Agent 五、11gRAC的监听排错步骤 1.在任意节点上使用tnsnames.ORA通过scan-ip登陆数据库 [grid@node1 admin]$ tnsping RACDB TNS Ping Utility for Linux: Version 11.2.0.1.0 - Production on 02-JAN-2014 18:41:16 Copyright (c) 1997, 2009, Oracle. All rights reserved. Used parameter files: /u/app/11.2.0/grid/network/admin/sqlnet.ora Used TNSNAMES adapter to resolve the alias Attempting to contact (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 10.134.30.50)(PORT = 1521))) (CONNECT_DATA = (SERVICE_NAME = RACDB))) OK (0 msec) [grid@node1 admin]$ sqlplus scott/testpassword@RACDB SQL*Plus: Release 11.2.0.1.0 Production on Thu Jan 2 18:41:27 2014 Copyright (c) 1982, 2009, Oracle. All rights reserved. Connected to: Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit Production With the Partitioning, Real Application Clusters, Automatic Storage Management, OLAP, Data Mining and Real Application Testing options SQL> 2.检查RAC上的scan-ip配置 [grid@node1 ~]$ srvctl config scan SCAN name: RACSCAN.localdomain., Network: 1/10.134.30.0/255.255.255.0/eth0 SCAN VIP name: scan1, IP: /RACSCAN.localdomain/10.134.30.50 SCAN VIP name: scan2, IP: /RACSCAN.localdomain/10.134.30.51 SCAN VIP name: scan3, IP: /RACSCAN.localdomain/10.134.30.52 [grid@node1 ~]$ srvctl config scan_listener SCAN Listener LISTENER_SCAN1 exists. Port: TCP:1521 SCAN Listener LISTENER_SCAN2 exists. Port: TCP:1521 SCAN Listener LISTENER_SCAN3 exists. Port: TCP:1521 3.DNS测试 [root@node1 ~]# nslookup RACSCAN.localdomain. Server: 10.134.30.27 Address: 10.134.30.27#53 Name: RACSCAN.localdomain Address: 10.134.30.52 Name: RACSCAN.localdomain Address: 10.134.30.50 Name: RACSCAN.localdomain Address: 10.134.30.51 [grid@node1 ~]$ nslookup 10.134.30.50 Server: 10.134.30.27 Address: 10.134.30.27#53 50.30.134.10.in-addr.arpa name = RACSCAN.localdomain. [grid@node1 ~]$ nslookup 10.134.30.51 Server: 10.134.30.27 Address: 10.134.30.27#53 51.30.134.10.in-addr.arpa name = RACSCAN.localdomain. [grid@node1 ~]$ nslookup 10.134.30.52 Server: 10.134.30.27 Address: 10.134.30.27#53 52.30.134.10.in-addr.arpa name = RACSCAN.localdomain. 多次运行nslookup RACSCAN.localdomain.可观察到scan-ip轮询没有任何问题，反向解析亦没有任何问题。 4.ping三个scan-ip primary$ping 10.134.30.47 PING 10.134.30.47 (10.134.30.47) 56(84) bytes of data. 64 bytes from 10.134.30.47: icmp_seq=1 ttl=63 time=0.508 ms primary$ping 10.134.30.48 PING 10.134.30.48 (10.134.30.48) 56(84) bytes of data. 64 bytes from 10.134.30.48: icmp_seq=1 ttl=63 time=0.522 ms primary$ping 10.134.30.50 PING 10.134.30.50 (10.134.30.50) 56(84) bytes of data. 64 bytes from 10.134.30.50: icmp_seq=1 ttl=63 time=0.514 ms 5.在任意客户端测试可否登陆 primary$tnsping guijian TNS Ping Utility for Linux: Version 11.2.0.1.0 - Production on 02-JAN-2014 19:12:15 Copyright (c) 1997, 2009, Oracle. All rights reserved. Used parameter files: /u/app/oracle/product/11g/db/network/admin/sqlnet.ora Used TNSNAMES adapter to resolve the alias Attempting to contact (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = RACSCAN.localdomain.)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = RACDB))) OK (0 msec)-------------------------à此处透过scan-ip的tnsping正常 primary$ primary$sqlplus scott/Testpassword@guijian SQL*Plus: Release 11.2.0.1.0 Production on Thu Jan 2 19:08:06 2014 Copyright (c) 1982, 2009, Oracle. All rights reserved. ERROR: ORA-12170: TNS:Connect timeout occurred primary$ 等待N久之后提示超时，但此时的tnsping正常，起初测试也曾提示提示 no listener。 6.检查监听器配置 [grid@node1 admin]$ cat listener.ora LISTENER_SCAN3=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER_SCAN3)))) # line added by Agent LISTENER_SCAN2=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER_SCAN2)))) # line added by Agent LISTENER=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER)))) # line added by Agent LISTENER_SCAN1=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER_SCAN1)))) # line added by Agent LISTENER_SCAN1=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER_SCAN2)))) # line added by Agent LISTENER_SCAN1=(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER_SCAN3)))) # line added by Agent ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER_SCAN1=ON # line added by Agent ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER_SCAN2=ON # line added by Agent ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER_SCAN3=ON # line added by Agent ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER=ON # line added by Agent 经过初步的检测问题可能不是出在服务器监听这一块,而是可能出在与监听相关的初始化参数上。 7.检查数据库两个与监听相关的参数 SQL> show parameter local_listener SQL> show parameter remote_listener Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-15 11:38:33 "},"rac/36.11gR2RAC修改监听默认端口.html":{"url":"rac/36.11gR2RAC修改监听默认端口.html","title":"11gR2RAC修改监听默认端口","keywords":"","body":" 对11gR2 rac修改默认的监听端口 一、修改SCAN listener port 1.修改SCAN listener port 2.重启SCAN listener生效新端口 3.确认更改 二、修改Listener Ports 1.修改端口 2.手工修改LOCAL_LISTENER 3.重新启动监听程序 4.检查监听配置 参考 对11gR2 rac修改默认的监听端口 对11gR2 rac修改默认的监听端口分为两步： 修改scan listener的端口 修改本地listener的端口 一、修改SCAN listener port 1.修改SCAN listener port [grid@tyqxdb1 ~]$ $GRID_HOME/bin/srvctl modify scan_listener -p 11521 [oracle@tyqxdb1 ~]$ sqlplus / as sysdba SQL*Plus: Release 11.2.0.4.0 Production on Mon Nov 22 09:30:46 2018 Copyright (c) 1982, 2013, Oracle. All rights reserved. Connected to: Oracle Database 1g Enterprise Edition Release 11.2.0.4.0 - 4bit Production With the Partitioning, Real Application Clusters, Automatic Storage Management, OLAP, Data Mining and Real Application Testing options SQL> show parameter listener NAME TYPE VALUE listener_networks string local_listener string (ADDRESS=(PROTOCOL=TCP)(HOST= 10.238.205.192)(PORT=1521)) remote_listener string tyqxdb-scan:1521 SQL> alter system set remote_listener='tyqxdb-scan:11521' scope=both; System altered. SQL> show parameter listener NAME TYPE VALUE listener_networks string local_listener string (ADDRESS=(PROTOCOL=TCP)(HOST= 10.238.205.192)(PORT=1521)) remote_listener string tyqxdb-scan:11521 SQL> 2.重启SCAN listener生效新端口 [grid@tyqxdb1 ~]$ $GRID_HOME/bin/srvctl stop scan_listener [grid@tyqxdb1 ~]$ $GRID_HOME/bin/srvctl start scan_listener 3.确认更改 [grid@tyqxdb1 ~]$ $GRID_HOME/bin/srvctl config scan_listener SCAN Listener LISTENER_SCAN1 exists. Port: TCP:11521 二、修改Listener Ports 1.修改端口 获取监听信息 [grid@tyqxdb1 ~]$ srvctl config listener Name: LISTENER Network: 1, Owner: grid Home: End points: TCP:1521 修改端口 [grid@tyqxdb1 ~]$ srvctl modify listener -l LISTENER -p \"TCP:11521\" 2.手工修改LOCAL_LISTENER [oracle@tyqxdb1 ~]$ sqlplus / as sysdba SQL*Plus: Release 11.2.0.4.0 Production on Mon Nov 22 14:11:00 2018 Copyright (c) 1982, 2013, Oracle. All rights reserved. Connected to: Oracle Database 11g Enterprise Edition Release 11.2.0.4.0 - 64bit Production With the Partitioning, Real Application Clusters, Automatic Storage Management, OLAP, Data Mining and Real Application Testing options SQL> alter system set local_listener='(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=TCP)(HOST=10.238.205.192)(PORT=11521))))' scope=both sid='tyqxdb1'; System altered. SQL> alter system set local_listener='(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=TCP)(HOST=10.238.205.194)(PORT=11521))))' scope=both sid='tyqxdb2'; System altered. SQL> show parameter listener NAME TYPE VALUE ------------------------------------ ----------- ------------------------------ listener_networks string local_listener string (DESCRIPTION=(ADDRESS_LIST=(AD DRESS=(PROTOCOL=TCP)(HOST=10.238.205.192)(PORT=11521)))) remote_listener string tyqxdb-scan:11521 在节点2上做同样的操作，需要注意的是节点2的local_listene要配置节点的VIP 3.重新启动监听程序 节点1: [grid@tyqxdb1 admin]$ srvctl stop listener [grid@tyqxdb1 admin]$ srvctl start listener 节点2: [grid@tyqxdb1 admin]$ srvctl stop listener [grid@tyqxdb1 admin]$ srvctl start listener 4.检查监听配置 节点1: [oracle@tyqxdb1 ~]$ srvctl config Listener Name: LISTENER Network: 1, Owner: grid Home: End points: TCP:11521 节点2: [oracle@tyqxdb2 ~]$ srvctl config Listener Name: LISTENER Network: 2, Owner: grid Home: End points: TCP:11521 参考 How to Modify SCAN Setting or SCAN Listener Port after Installation (文档 ID 972500.1) Changing Listener Ports On RAC/EXADATA (文档 ID 1473035.1) Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-03-22 21:12:53 "},"rac/11.asm-commnd-intro.html":{"url":"rac/11.asm-commnd-intro.html","title":"asm常用命令","keywords":"","body":" 一、查看ASM空间使用情况 1.1 查看磁盘组的信息，和磁盘空间大小 1.2 查看磁盘组 1.3 查看及修改asm重新平衡粒度 1.4 查看asm实例操作变化（只记录结构变化操作） 二、ASM磁盘组的创建删除挂载 2.1 asm磁盘组创建 2.2 asm 磁盘组删除 2.3 asm磁盘组添加磁盘 2.4 asm磁盘组删除磁盘 2.5 挂载磁盘组 2.6 卸载磁盘组 2.7 删除磁盘组 三、ASM磁盘组目录管理 3.1 asm磁盘组增加目录 3.2 asm磁盘组重命名目录 3.3 asm磁盘组增加多层目录，必须一层一层添加(用asmcmd也可以实现) 3.4 asm磁盘组目录删除 四.、ASM磁盘组文件管理 4.1 数据文件添加别名 4.2 重新命名别名 4.3 查询别名 4.4 删除别名 五、ASM几个重要参数 六、ASM相关视图 七、添加数据文件 八、 ASMCMD的使用 8.1 显示指定的ASM目录下ASM文件占用的所有磁盘空间 8.2 列出ASM目录下的内容及其属性、磁盘空间占用 8.3 列出当前ASM客户端的信息 8.4 列出所有磁盘组及其属性 8.5 列出数据文件信息 8.6 列出盘的信息 8.7 查看磁盘I/O信息 一、查看ASM空间使用情况 1.1 查看磁盘组的信息，和磁盘空间大小 [grid@nazeebo ~]$ asmcmd ASMCMD> lsdg State Type Rebal Sector Block AU Total_MB Free_MB Req_mir_free_MB Usable_file_MB Offline_disks Voting_files Name MOUNTED EXTERN N 512 4096 1048576 25600 24386 0 24386 0 N ARCH/ MOUNTED EXTERN N 512 4096 1048576 25600 22974 0 22974 0 N DATA/ MOUNTED EXTERN N 512 4096 1048576 20480 20421 0 20421 0 N OCR/ 1.2 查看磁盘组 [grid@nazeebo ~]$ sqlplus / as sysasm SQL> col name2 format a10 SQL> col state format a10 SQL> select name name2,state,type,free_mb,total_mb,usable_file_mb from v$asm_diskgroup; NAME2 STATE TYPE FREE_MB TOTAL_MB USABLE_FILE_MB ---------- ---------- ------------ ---------- ---------- -------------- OCR MOUNTED EXTERN 20421 20480 20421 DATA MOUNTED EXTERN 22974 25600 22974 ARCH MOUNTED EXTERN 24386 25600 24386 1.3 查看及修改asm重新平衡粒度 SQL> col name format a30 SQL> col value format a20 SQL> set lines 100 SQL> show parameter power NAME TYPE VALUE ------------------------------------ ---------------------- ------------------------------ asm_power_limit integer 1 SQL> show parameter asm NAME TYPE VALUE ------------------------------------ ---------------------- ------------------------------ asm_diskgroups string DATA, ARCH asm_diskstring string asm_power_limit integer 1 asm_preferred_read_failure_groups string SQL> 1.4 查看asm实例操作变化（只记录结构变化操作） select * from v$asm_operation; 二、ASM磁盘组的创建删除挂载 以下的操作可以使用asmca(11g),10g(dbca) 图形界面来创建，也可以使用命令行进行操作 2.1 asm磁盘组创建 sql> create diskgroup datadg01 external redundancy disk '/dev/raw/raw4'; 2.2 asm 磁盘组删除 sql>drop diskgroup datadg01; 2.3 asm磁盘组添加磁盘 sql>alter diskgroup datadg01 add disk '/dev/raw/raw5; 2.4 asm磁盘组删除磁盘 查询物理盘映射到asm中的磁盘名称 sql>select name,path from v$asm_disk ; NAME PATH ----------------------------- DATA_0000 /dev/raw/raw1 DATA_0001 /dev/raw/raw2 DATA_0002 /dev/raw/raw3 DATADG01_0000 /dev/raw/raw5 DATADG01_0001 /dev/raw/raw6 DATADG01_0002 /dev/raw/raw7 sql> alter diskgroup datadg drop disk 'DATADG01_0001'; --这里是磁盘名称，而不是'/dev/raw/raw1' 2.5 挂载磁盘组 sql> alter diskgroup datadg01 mount; or sql> alter diskgroup all mount; 2.6 卸载磁盘组 sql> alter diskgroup datadg01 dismount; or sql> alter diskgroup all dismount; 2.7 删除磁盘组 sql>drop diskgroup datadg01; 说明：删除磁盘组时，磁盘组必须被挂载(mount) 三、ASM磁盘组目录管理 3.1 asm磁盘组增加目录 sql> alter diskgroup datadg01 add directory '+datadg01/datafile'; 3.2 asm磁盘组重命名目录 sql> alter diskgroup datadg01 rename directory '+datadg01/datafile' to '+datadg01/datafile01'; 3.3 asm磁盘组增加多层目录，必须一层一层添加(用asmcmd也可以实现) --首先添加nazeebo SQL> alter diskgroup datadg01 add directory '+datadg01/nazeebo/'; 然后添加datafile SQL> alter diskgroup datadg01 add directory '+datadg01/nazeebo/datafile'; 3.4 asm磁盘组目录删除 SQL> alter diskgroup datadg01 drop directory '+datadg01/datafile'; 四.、ASM磁盘组文件管理 4.1 数据文件添加别名 sql>alter diskgroup datadg01 add alias '+datadg01/node/datafile/users.dbf' for '+datadg01/node/datafile/users.266.987885487'; 4.2 重新命名别名 SQL> alter diskgroup datadg01 rename alias '+datadg01/node/datafile/users.dbf' to '+datadg01/node/datafile/users01.dbf'; 4.3 查询别名 SQL> select name,group_number,file_number,alias_index,alias_directory,system_created from v$asm_alias where rownum4.4 删除别名 SQL> alter diskgroup datadg01 drop alias '+datadg01/node/datafile/users01.dbf'; 五、ASM几个重要参数 asm_power_limit当加入磁盘后磁盘组的各个磁盘之间做均衡进程 asm_disktring 指定asm启动时候查找磁盘路径 Linux 自动搜索：/dev/raw/ 和/dev下的设备文件 aix 自动搜索：/dev/下设备文件 hp-ux：由于hp-ux下的磁盘路径在/dev/rdsk/下边，需要设置 磁盘组的重新平衡:当磁盘组中的磁盘发生变化时，磁盘组将自动进行重新平衡 平衡级别为0-11，当手工进行重新平衡时，可以指定平衡级别 可用的最高级别通过初始化参数asm_power_limit 指定 SQL>alter diskgroup datadg01 rebalance power 3; SQL>alter diskgroup datadg01 rebalance power 3 wait ; 六、ASM相关视图 v$asm_disk(_stat) --查看磁盘及其状态信息 v$asm_diskgroup(_stat) --查看磁盘组及其状态信息 v$asm_operation --查看当前磁盘的操作信息 v$asm_client --返回当前连接的客户端实例信息 v$asm_file --返回asm文件的相关信息 v$asm_template --返回asm文件样本的相关信息 v$asm_alias --返回asm文件的别名信息 七、添加数据文件 如果是数据库文件 sql>create tablespace test datafile'+datadg01' size 100M; 如果归档日志： sql>alter system set log_archive_dest_1='location=+datadg01' scope=both; 八、 ASMCMD的使用 8.1 显示指定的ASM目录下ASM文件占用的所有磁盘空间 ASMCMD> du Used_MB Mirror_used_MB 3723 3723 8.2 列出ASM目录下的内容及其属性、磁盘空间占用 ASMCMD> ls -ls State Type Rebal Sector Block AU Total_MB Free_MB Req_mir_free_MB Usable_file_MB Offline_disks Voting_files Name MOUNTED EXTERN N 512 4096 1048576 25600 24386 0 24386 0 N ARCH/ MOUNTED EXTERN N 512 4096 1048576 25600 22974 0 22974 0 N DATA/ MOUNTED EXTERN N 512 4096 1048576 20480 20421 0 20421 0 N OCR/ 8.3 列出当前ASM客户端的信息 ASMCMD> lsct DB_Name Status Software_Version Compatible_version Instance_Name Disk_Group +ASM CONNECTED 11.2.0.4.0 11.2.0.4.0 +ASM DATA +ASM CONNECTED 11.2.0.4.0 11.2.0.4.0 +ASM ARCH nazeebo CONNECTED 11.2.0.4.0 11.2.0.4.0 nazeebo DATA nazeebo CONNECTED 11.2.0.4.0 11.2.0.4.0 nazeebo ARCH 8.4 列出所有磁盘组及其属性 ASMCMD> lsdg State Type Rebal Sector Block AU Total_MB Free_MB Req_mir_free_MB Usable_file_MB Offline_disks Voting_files Name MOUNTED EXTERN N 512 4096 1048576 25600 24386 0 24386 0 N ARCH/ MOUNTED EXTERN N 512 4096 1048576 25600 22974 0 22974 0 N DATA/ MOUNTED EXTERN N 512 4096 1048576 20480 20421 0 20421 0 N OCR/ 8.5 列出数据文件信息 ASMCMD> lsof DB_Name Instance_Name Path nazeebo nazeebo +arch/nazeebo/controlfile/current.256.975754453 nazeebo nazeebo +arch/nazeebo/flashback/log_4.307.975880811 nazeebo nazeebo +arch/nazeebo/onlinelog/group_1.257.975754455 nazeebo nazeebo +arch/nazeebo/onlinelog/group_1.257.975754455 nazeebo nazeebo +arch/nazeebo/onlinelog/group_2.258.975754457 nazeebo nazeebo +arch/nazeebo/onlinelog/group_3.297.975801663 nazeebo nazeebo +data/nazeebo/controlfile/current.259.975754453 nazeebo nazeebo +data/nazeebo/datafile/sysaux.261.975754473 nazeebo nazeebo +data/nazeebo/datafile/system.260.975754459 nazeebo nazeebo +data/nazeebo/datafile/undotbs1.262.975754485 nazeebo nazeebo +data/nazeebo/datafile/users.264.975754495 nazeebo nazeebo +data/nazeebo/onlinelog/group_1.258.975754453 nazeebo nazeebo +data/nazeebo/onlinelog/group_1.258.975754453 nazeebo nazeebo +data/nazeebo/onlinelog/group_2.257.975754455 nazeebo nazeebo +data/nazeebo/onlinelog/group_3.270.975801663 nazeebo nazeebo +data/nazeebo/tempfile/temp.263.975754489 8.6 列出盘的信息 ASMCMD> lsdsk Path /dev/raw/raw1 /dev/raw/raw2 /dev/raw/raw3 8.7 查看磁盘I/O信息 ASMCMD> lsdsk --statistics -G arch Reads Write Read_Errs Write_Errs Read_time Write_Time Bytes_Read Bytes_Written Voting_File Path 17300 1049436 0 0 103.154258 426236.546655 699333120 10588122624 N /dev/raw/raw3 ASMCMD> iostat Group_Name Dsk_Name Reads Writes OCR OCR_0000 688128 579183616 DATA DATA_0000 21627850752 14756515328 ARCH ARCH_0000 699349504 10588560896 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-27 13:35:00 "},"dataguard/17.case-dg-nosync-troubleshooting.html":{"url":"dataguard/17.case-dg-nosync-troubleshooting.html","title":"解决一起较复杂dg不同步的问题","keywords":"","body":" 一、照往常一样查看dataguard的日志同步三板斧 第一板斧：查看主从库的日志的最大号以及是否存在lag 第二板斧：查看查询主库日志与备库是否一致 第三板斧：查看有没有MRP进程 二、启动了mrp进程后发现有ora-600的错误 重新同步的步骤： 三、备库报错ORA-00313、ORA-00312、ORA-27037 只有用clear的方式把redo清除了的步骤： 接到同事电话，说公司的mis系统好像从库查询和主库的数据有点不一致。Ok，很明显应该是主从不同步的问题，在处理过程中以为和往常一样很简单，哪儿晓得遇到了好几个坑，特此记录一下。 数据库版本：11.2.0.4 单实例 一、照往常一样查看dataguard的日志同步三板斧 第一板斧：查看主从库的日志的最大号以及是否存在lag 1.Primary/stndby：查询主库的最大日志 SQL> select max(sequence#) from v$archived_log; SQL> select max(sequence#) from v$archived_log where applied='YES'; 2.查看是够有lag 用以下命令查看 set lines 200 col ctime format a20 col value format a20 select inst_id,to_char(sysdate,'yyyymmdd hh24:mi:ss') ctime,name,value,datum_time from gv$dataguard_stats where name like '%lag'; 第二板斧：查看查询主库日志与备库是否一致 1.查看查询主库日志与备库是否一致 SQL> select sequence# from v$archived_log where recid = (select max(recid) from v$archived_log) and applied = 'YES'; SQL> select sequence# from v$archived_log where recid = (select max(recid) from v$archived_log); 2.备库接收到的日志和应用的日志是否一致 select max(lh.SEQUENCE#) ,max(al.SEQUENCE#) fromv$log_history lh,v$archived_log al; 第三板斧：查看有没有MRP进程 SQL> select process,status from v$managed_standby; PROCESS STATUS ------- ------------ ARCH CONNECTED ARCH CONNECTED MRP0 WAIT_FOR_LOG RFS RECEIVING 没有MRP进程，说明备库没有处于恢复状态。可以使用 alter database recover managed standby database disconnect from session ； 打开standby的同步。 二、启动了mrp进程后发现有ora-600的错误 原本以为就搞定了，结果查看了一下alert日志，发现报错： ORA-00600: internal error code, arguments: [2619], [81304], [], [], [], [], [], [], [], [], [], [] MRP0: Background Media Recovery process shutdown (amldb) 查了下metalink，发现这个600错误是备库在执行恢复的过程中，发现81304这个归档日志有问题或者找不到。 根据提示查了下主库，这个81304号的归档日志已经早删除了。。（如果没有删的话，可以直接传一份到备库重新应用即可） 为了让主备库的数据一致，在不重建备库的情况下，可以采用通过主库增量备份的方式来完成重新同步了。 重新同步的步骤： 1.在备库上取消日志应用 alter database recover managedstandby database cancel; 2.查看备库scn select current_scn from v$database; 3.根据scn，在主库上进行rman增量备份 获取增量数据 backup incremental from scn xxxx database format '/u01/archivelog/temp/20180705_%U.bak' tag 'forstandby'; 备份控制文件 backup current controlfile forstandby format '/u01/archivelog/temp/controlfile.bak'; 4.将增量备份传到备库 5.将备库启动到mount状态 shutdown immediate startup nomount alter database mount standby database; 6.用rman进行恢复增量备份 rman target / nocatalog RMAN> catalog start with '/u01/archivelog/temp/'; RMAN> recover database noredo; 7.用rman恢复控制文件 RMAN> shutdown; RMAN> startup nomount; RMAN> restore standby controlfile from '/u01/archivelog/temp/controlfile.bak'; 8.启动备库到mount状态 RMAN> shutdown SQL> startup nomount; SQL> alter database mount standby database; 9.因为恢复了控制文件，所以需要重新添加新的standby redo log file alter database add standby logfile group 11('/u01/app/oracle/sid/oradata/stdbyredo01.log') size 100m; ... alter database add standby logfile group 17('/u01/app/oracle/sid/oradata/stdbyredo07.log') size 100m; 10.启动备库同步 SQL> alter database open read only; SQL> alter database recover managed standby database disconnect from session using current logfile; 11.查看归档日志应用 select max(lh.SEQUENCE#) ,max(al.SEQUENCE#) fromv$log_history lh,v$archived_log al; 三、备库报错ORA-00313、ORA-00312、ORA-27037 原本以为搞定了，然后查看alert日志，发现又报错了。。日了狗了！ 这次报的错是DG备库报错ORA-00313、ORA-00312、ORA-27037 意思说redo日志不存在。去相对应的目录看，果然备库的redo不存在。 肿么办呢？只有用clear的方式把redo清除了 只有用clear的方式把redo清除了的步骤： 1.在备库上取消日志应用 alter database recover managed standby database cancel; 2.执行如下命令重建备库上所有的日志组 SQL> select group#,sequence#,archived,status from v$log; GROUP# SEQUENCE# ARCHIVED STATUS ---------- ---------- -------- ---------------- 1 1 YES INACTIVE 2 2 YES INACTIVE 3 3 NO CURRENT 对于已经归档和状态为inactive的组可以用下面的命令来重建 对于状态为active的日志组则需要先做一下日志的切换才行，而做日志的切换又需要先把数据库open，切完后再startup到mount状态 ``` alter database clear logfile group X; redo: alter database drop logfile group X; alter database add logfile group X ('路径') size 100m; standby redo: alter database drop standby logfile group X; alter database add standby logfile group X ('路径') size 100m; #### 3.在clear的过程又遇到一个报错：ORA-19527和ORA-00312 这个和备库的LOG_FILE_NAME_CONVERT有关，需要设置这个spfile的参数才行，修改完后重启数据库，执行clear成功。 #### 4.启动备库并检查 做完以上后: shutdown immediate startup mount #查看alert日志没有错误后再执行下面的 alter database open read only alter database recover managedstandby database disconnect from session using current logfile; select max(lh.SEQUENCE#) ,max(al.SEQUENCE#) fromv$log_history lh,v$archived_log al; ``` 参考： (1) 官方文档：Database Backup and Recovery Advanced User's Guide (2) 1138913.1： ORA-600[2619] During Physical Standby Recovery Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-27 13:35:51 "},"dataguard/16.dg-nosync-troubleshooting.html":{"url":"dataguard/16.dg-nosync-troubleshooting.html","title":"DG不同步诊断方法","keywords":"","body":"用以下命令查看 set lines 200 col ctime format a20 col value format a20 select inst_id,to_char(sysdate,'yyyymmdd hh24:mi:ss') ctime,name,value,datum_time from gv$dataguard_stats where name like '%lag'; 第一次发现没有lag 在主库重新执行一次alter system archive log current; 后，发现有了lag 接着查mrp进程，进程是有的： 接着去看standby redo log，发现了问题： 观察上图的结果，发现standby redo log全部都是线程1的，赶紧通过命令把thread 2的standby log补上，过了一会儿就同步了。 类似命令： alter database add standby logfile thread 2 group 14 ('+DATA/','+ARCH') size 512M; alter database add standby logfile thread 2 group 15 ('+DATA/','+ARCH') size 512M; alter database add standby logfile thread 2 group 16 ('+DATA/','+ARCH') size 512M; alter database add standby logfile thread 2 group 17 ('+DATA/','+ARCH') size 512M; alter database add standby logfile thread 2 group 18 ('+DATA/','+ARCH') size 512M; alter database add standby logfile thread 2 group 19 ('+DATA/','+ARCH') size 512M; alter database add standby logfile thread 2 group 20 ('+DATA/','+ARCH') size 512M; ARC3: Archivelog destination LOG_ARCHIVE_DEST_2 disabled: Data Guard configuration identifier mismatch 在主库上查询v$ARCHIVE_DEST视图： SQL> select dest_name, status, error from v$archive_dest WHERE DEST_ID = 2; DEST_NAME -------------------------------------------------------------------------------- STATUS ERROR --------- ----------------------------------------------------------------- LOG_ARCHIVE_DEST_2 DISABLED ORA-16047: DGID mismatch between destination setting and target database 需要重点检查如下参数： log_archive_config fal_client fal_server log_archive_dest_2 log_archive_dest_state_2 ===================================== DG传输过程监控 1、查看备库工作模式及状态 select inst_id,db_unique_name,database_role,open_mode,protection_mode,protection_level,switchover_status,force_logging from gv$database; select db_unique_name,protection_mode,synchronization_status,SYNCHRONIZED from v$archive_dest_status; 2、日志恢复进程 archive log list; select thread#,max(sequence#) from v$archived_log group by thread#; select pid,process,client_process,client_pid,thread#,sequence#,status,DELAY_MINS from v$managed_standby; --RFS进程从主数据库接收重做数据，并将其写入备用重做日志。 3、查看standbylog状态 如果是RAC两节点，那么每个节点至少有一个是ACTIVE的状态，否则不对 set lines 200 select group#,thread#,sequence#,bytes/1024/1024,archived,used,status,first_change#,last_change# from v$standby_log; 检查备库已恢复的最大归档日志序号 select thread#,max(sequence#),registrar,applied,status from v$archived_log where applied='YES' and registrar='RFS' and name is not null group by thread#,registrar,applied,status; 4、检查应用率和活动率（PS） --Redo Applied 值以MB衡量。剩余两个以KB/s计算。 select to_char(start_time,'DD-MON-RR HH24:MI:SS') start_time,ITEM,sofar from v$recovery_progress where item in ('Active Apply Rate','Average Apply Rate','Redo Applied'); 5、审阅传输和应用滞后（PS+LS） transport lag 表明从主数据库到物理备用数据库的重做数据传输时间。 apply lag 表明应用滞后时间，它反映了archive_log_dest_n参数中 DELAY 特性。 COL NAME FOR A13 COL VALUE FOR A20 COL UNIT FOR A30 SET LINES 200 select name,value,unit,time_computed from v$dataguard_stats where name like '%lag%'; 6、查看Data Guard状态视图中的错误 set lines 132 col message for a80 col timestamp for a20 select error_code,severity,message, to_char(timestamp,'DD-MON-RR HH24:MI:SS') timestamp from v$dataguard_status where callout='YES' and timestamp > sysdate -1; 7、检查日志文件是否传输到备用数据库 select dest_name,status,error from v$archive_dest where dest_id=2; DEST_NAME STATUS ERROR -------------------- ---------- -------------------- LOG_ARCHIVE_DEST_2 VALID status列如果为valid，说明归档成功，可以查看error列得到不能归档的原因 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-02-19 16:47:53 "},"manage/解决ORA-01152_ORA-10458_ORA-01110.html":{"url":"manage/解决ORA-01152_ORA-10458_ORA-01110.html","title":"解决ORA-01152(ORA-10458、ORA-01110)","keywords":"","body":" 问题及现象 解决方法 1.从库启动到mount状态 2.主库上操作 3.备库操作 问题及现象 11g搭建完备库后，打开备库时报错，如下： SQL> alter database recover managed standby database cancel; Database altered. SQL> alter database open; alter database open * ERROR at line 1: ORA-10458: standby database requires recovery ORA-01152: file 1 was not restored from a sufficiently old backup ORA-01110: data file 1: '+ORADATA/racdg/datafile/system.260.1000300965' 解决方法 1.从库启动到mount状态 SQL>SHUTDOWN IMMEDIATE SQL>STARTUP MOUNT; SQL>ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USEING CURRENT LOGFILE DISCONNECT FROM SESSION; 2.主库上操作 SQL>ALTER SYSTEM SWITCH LOGFILE; 多操作几次，操作之后，稍等一段时间，时间视网速而定，过一段时间后，在主库上查询一下规定情况： SQL>SELECT NAME,SEQUENCE#,ARCHIVED,APPLIED FROMV$ARCHIVED_LOG ORDER BY SEQUENCE#; 如果返回结果\"APPLIED\"都是“YES”或者只有最后一个是“NO”的话，说明全部归档日志全部已经归档完了，此时到备库上上操作 3.备库操作 SQL>ALTER DATABASE RECOVER MANAGED STANDBY DATABASE CANCEL; SQL>ALTER DATABASE OPEN; SQL>ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT FROM SESSION; Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-02-26 17:00:16 "},"dataguard/39.dg-switchov-failover.html":{"url":"dataguard/39.dg-switchov-failover.html","title":"ADG切换过程","keywords":"","body":" ADG的手工切换 一、switchover 1.主库操作 2.备库操作 3.在新的备库上（原主库）执行启用日志实时应用模式 4.主库（新的主库，原备库）查看状态 二、FAILOVER 1.备库操作 2.利用flashback重建DG ADG的手工切换 一、switchover 是用户有计划的进行停机切换，能够保证不丢失数据 切换步骤: 1.主库操作 1.0 关闭其他实例 如果RAC环境,先关闭其他实例,只留一个实例1进行操作 1.1 查看主库的状态 SQL> select open_mode,database_role,protection_mode,protection_level,switchover_status from v$database; 只有当switchover_status这一列状态为 TO STANDBY 或 SESSIONS ACTIVE才可以进行切换 1.2 主库状态切换 alter system switch logfile; alter system archive log current; alter database commit to switchover to physical standby with session shutdown; 如果swtichover_status状态为session active，就需要在命令中加入with session shutdown子句。 执行后，会发现主库其实已经关闭。 加入with session shutdown相当于杀掉连接进程了，此时库已经关闭了，保险起见，再执行下 shutdown abort 1.3 重启主库到mount阶段 重启主库到mount阶段，确保主库不会在有连接导致数据变动 startup mount 1.4 查看主库切换后的状态 select switchover_status from v$database; SWITCHOVER_STATUS -------------------- TO PRIMARY 另外，在实际生产环境，遇到过启动到mount状态后，SWITCHOVER_STATUS的值有可能为recovery needed或switchover latent或not allowed 这个时候主库就需要apply完所有归档日志才能切换，命令如下： alter database recover managed standby database disconnect from session; 这一步过后,也可以执行alter database open; 此时主库虽然这样打开，但是还是read only的状态。因为上面执行了alter database commit to switchover to physical standby with session shutdown;这条语句。 2.备库操作 2.0 关闭其他实例 如果是RAC集群环境,先关闭其他实例,保证只在节点1进行操作 2.1 查看备库状态 select open_mode,database_role,protection_mode,protection_level,switchover_status from v$database; OPEN_MODE DATABASE_ROLE PROTECTION_MODE PROTECTION_LEVEL -------------------- ---------------- -------------------- -------------------- SWITCHOVER_STATUS -------------------- READ ONLY PHYSICAL STANDBY MAXIMUM PERFORMANCE MAXIMUM PERFORMANCE NOT ALLOWED 注意备库的SWITCHOVER_STATUS此时是not allowed状态，说明备库日志并未应用完。 此时如果直接执行切换主库的操作，会报错 SQL> alter database commit to switchover to primary with session shutdown ; alter database commit to switchover to primary with session shutdown * ERROR at line 1: ORA-16139: media recovery required 要等这个switchover_status状态变成to primary以后才能切 状态如果为session active也可以直接做下面的切换操作 2.2 执行切换操作 SQL> alter database commit to switchover to primary with session shutdown ; 2.3 打开新的 主库 上一步执行完成后,这个时候新的主库的状态是mount的,需要open SQL> alter database open; 3.在新的备库上（原主库）执行启用日志实时应用模式 3.1 查询状态 SQL> select open_mode from v$database; OPEN_MODE -------------------- READ ONLY 3.2 执行启动日志实时应用 SQL> alter database recover managed standby database using current logfile disconnect from session; 如果之前没有打开数据库,这个时候直接执行上面的命令会报错,需要先关闭恢复,再打开数据库,最后再开实时应用 SQL> alter database recover managed standby database cancel; SQL> ALTER DATABASE OPEN; SQL> alter database recover managed standby database using current logfile disconnect from session; 3.3 查看状态及gap SQL> select open_mode from v$database; OPEN_MODE -------------------- READ ONLY SQL> select status ,gap_status from v$archive_dest_status where dest_id in (1,2); STATUS GAP_STATUS --------- ------------------------ VALID VALID SQL> select switchover_status from v$database; SWITCHOVER_STATUS -------------------- NOT ALLOWED SQL> select open_mode,database_role,protection_mode,protection_level,switchover_status from v$database; OPEN_MODE DATABASE_ROLE PROTECTION_MODE PROTECTION_LEVEL SWITCHOVER_STATUS -------------------- ---------------- -------------------- -------------------- -------------------- READ ONLY WITH APPLY PHYSICAL STANDBY MAXIMUM PERFORMANCE MAXIMUM PERFORMANCE NOT ALLOWED 4.主库（新的主库，原备库）查看状态 SQL> select switchover_status from v$database; SWITCHOVER_STATUS -------------------- TO STANDBY SQL> select status ,gap_status from v$archive_dest_status where dest_id in (1,2); STATUS GAP_STATUS --------- ------------------------ VALID VALID NO GAP SQL> select open_mode,database_role,protection_mode,protection_level,switchover_status from v$database; OPEN_MODE DATABASE_ROLE PROTECTION_MODE PROTECTION_LEVEL SWITCHOVER_STATUS -------------------- ---------------- -------------------- -------------------- -------------------- READ WRITE PRIMARY MAXIMUM PERFORMANCE MAXIMUM PERFORMANCE TO STANDBY 二、FAILOVER Switchover动作是不会引起数据丢失的，Standby可以保证接受并且应用所有的Redo Log数据。 而Failover则不好说，根据不同的保护模式（Protection Mode），一个事务在主库上面是否被commit，是取决于standby上是否接受和应用上日志数据。所以，在进行Failover的时候，是可能会丢数据的。 在进行Failover之后，Primary库实际上是退出了Oracle HA架构体系，成为游离对象。Standby在切换之后就成为新的Primary。这个过程就是角色切换。 1.备库操作 由于主库已经不可访问，我们所有的操作都在备库完成： 检查日志gap的问题，可以查看视图v$archive_gap。 SQL> select thread#, low_sequence#, high_sequence# from v$archive_gap; 如果没有发现明显的gap现象，说明此次的failover不会有数据损失情况。在standby端，要进行关闭apply和结束应用动作。 SQL> alter database recover managed standby database cancel; SQL> alter database recover managed standby database finish force; SQL> select database_role from v$database; SQL> alter database commit to switchover toprimary; SQL> alter database open; 或者 shutdown immediate + startup 2.利用flashback重建DG 如果没有开启flashback,那么通过failover切换的主库相当于就报废了,需要重新做一次dg才能加入到新的dg中去。 为了能够在failover后能够恢复DG,需要在主库上开启flashback 在新的主库上获取SCN号 SQL> select to_char(standby_became_primary_scn) from v$database; 在之前的主库上，也就是现在的备库上执行下面的操作: SQL>startup mount SQL> flashback database to scn 998877665; //这个值为在新主库上查询到的SCN值 SQL> alter database convert to physical standby; SQL> shutdown immediate SQL> startup SQL> alter database recover managed standby database using current logfile disconnect from session; 至此failover 切换和切换后恢复就已经完成 3.注意事项 这里有个坑,如果是一拖N的情况,做failover的时候，不管log_archive_dest_state_N是否设为了defer，默认在启动到primary角色的时候，会将这个参数设置为enable，这意味着会将变为primary角色后产生的redo和归档往其他备库上发送；解决方法是将log_archive_dest_n设为空 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-03-25 22:22:23 "},"dataguard/13.dg-parameters.html":{"url":"dataguard/13.dg-parameters.html","title":"dataguard概念参数查漏补缺","keywords":"","body":" 11g adg的相关概念介绍 一、保护模式 1.最大性能(maximize performance) 2.最大可用(maximize availability) 3.最大保护(maximize protection) 二、日志的传输模式 三、重要参数LOG_ARCHIVE_DEST_n说明 1.SERVICE 2.SYNC 3.ASYNC 4.NET_TIMEOUT 5.REOPEN 6.DB_UNIQUE_NAME 7.VALID_FOR 8.实例 9.以下的特性为可选特性： 三、主备库的srl和rl 1.主库 2.备库 四、级联更新 配置dg的参数说明 11g adg的相关概念介绍 一、保护模式 SELECT DATABASE_ROLE,PROTECTION_MODE,PROTECTION_LEVEL from v$database; 1.最大性能(maximize performance) 这是dataguard默认的保护模式。primay上的事务commit前不需要从standby上收到反馈信息（主数据库的提交操作不等待STANDBY），该模式在primary故障时可能丢失数据，但standby对primary的性能影响最小。 可以使用LGWR ASYNC或者ARCH两种传输模式。 ARCH传输模式：Primary DB上的online redo log写满或其他条件引起redo log写归档的时候，redo log生成的archived log file写到本地归档目录的同时，写入了Standby归档目录。只是Primary db上的online redo log切换不必等Standby上的写归档动作结束。 2.最大可用(maximize availability) 在正常情况下，最大可用模式和最大保护模式一样；在standby不可用时，最大可用模式会自动降低成最大性能模式，所以standby故障不会导致primay不可用。在问题纠正之后，Standby和主数据库进行再同步，至少有一个standby可用的情况下，即使primary down机，也能保证不丢失数据。(不过当问题修复，再同步之前有必要FAILOVER,那么有些数据可能会丢失)。最大可用性模式Standby必须配置Standby Redo log，Oracle推荐最大可用模式使用LGWR ASYNC（异步）模式传输。 采用最大可用的data guard模式，主库往备库传递在线日志(online redo log)信息，在线日志信息写入备用库的standby redo log,这些standby redo log归档后，备用库应用归档日志。 3.最大保护(maximize protection) 最高级别的保护模式。primay上的事务在commit前必须确认redo已经传递到至少一个standby上，如果所有standby不可用，则primary会挂起。该模式能保证零数据丢失。对于最大保护和最高可用性模式，Standby数据库必须配置standby redo log，并且oracle推荐所有数据库都使用LGWR ASYNC模式传输。 二、日志的传输模式 ARCH传输模式：Primary DB上的online redo log写满或其他条件引起redo log写归档的时候，redo log生成的archived log file写到本地归档目录的同时，写入了Standby归档目录。只是Primary db上的online redo log切换不必等Standby上的写归档动作结束。 LGWR还分为LGWR ASYNC(异步)和LGWR SYNC(同步)两种。 最大保护 最大可用 最大性能 进程 LGWR LGWR LGWR或ARCH 网络传输模式 SYNC SYNC LGWR时设置ASYNC 磁盘写操作 AFFIRM AFFIRM NOAFFIRM 备用日志 YES 物理备用需要 LGWR和物理备用时需要 备库类型 物理 ALL ALL 三、重要参数LOG_ARCHIVE_DEST_n说明 这是Data Guard重做传输的主要参数，通常在主数据库上发挥作用。该参数能用于指定ORL文件或者SRL文件的归档日志文件应该去往哪里。 该参数有17个特性，要使用Data Guard将重做数据正确传输到备用数据库，只需设置其中7个特性。 7个特性： 1.SERVICE 指定创建的指向备用数据库的TNSNAMES描述符。 2.SYNC 指定准备使用同步方法传输重做数据，这意味着LGWR进程将等待来自LNS的确认消息，然后才告知客户端事务已经提交。 3.ASYNC 异步传输方式。默认方式。 4.NET_TIMEOUT （最高可用性模式）指定LGWR进程等待LNS进程做出响应的秒数，如果超过指定时间，将因故障放弃备用。默认是30秒，但根据网络的可靠性， 10～15秒会是更恰当的值，具体取决于网络可靠性。不能设置为低于10秒，那样在备用数据库恢复后，将遇到重连失败的情形，因为完成所有重连需要耗费几秒钟的时间。 5.REOPEN 控制Data Guard允许主数据库尝试重连故障备用数据库前等待的时间。 默认为300秒，也就是说，不论备库是否恢复，也要等300秒后才重连备库。可以将其设置为30秒甚至15秒。 6.DB_UNIQUE_NAME 要在LOG_ARCHIVE_DEST_n参数中使用该特性，还需要设置LOG_ARCHIVE_CONFIG参数；否则Data Guard将拒绝连接到该目标。这个用作SERVICE目标（远程）的名称是为连接另一端的数据库指定的唯一名称（备用数据库）。 必须将这个唯一名称输入两端数据库的LOG_ARCHIVE_CONFIG参数中。当主数据库连接备用数据库时，会向备用发送自己的唯一数据库名，同时要求备用返回唯一名称。备用将检查配置参数LOG_ARCHIVE_CONFIG，确保主数据库的唯一名称的确存在。如果不存在，将拒绝连接。如果存在，备用数据库会将自己的唯一名称发回到主LNS进程。如果返回值与该特性中指定的值不匹配，连接将终止。 7.VALID_FOR 建议使用该特性，它的主要作用是定义何时使用LOG_ARCHIVE_DEST_n目标参数，以及应在哪类重做日志文件上运行。 下面是日志文件合法值： ONLINE_LOGFILE 仅归档ORL文件时有效 STANDBY_LOGFILE 仅归档SRL文件时有效 ALL_LOGFILES 无论对于那种重做日志文件类型都有效 下面是角色合法值： PRIMAMRY_ROLE 仅对担当主角色的数据库有效 STANDBY_ROLE 仅对担当备用角色的数据库有效 ALL_ROLES 无论何种数据库角色都有效 8.实例 现在看一下LOG_ARCHIVE_DEST_n，例如，为主库配置一个最高可用性模式的备库，则在主库中设置LOG_ARCHIVE_DEST_n参数，配置可能如下： log_archive_dest_2='service=tyqxdg1 SYNC REOPEN=15 NET_TIMEOUT=15 valid_for=(ONLINE_LOGFILES,PRIMARY_ROLE) db_unique_name=tyqxdg' 再添加一个最高性能模式的备库： log_archive_dest_3='service=tyqxdg2 ASYNC REOPEN=15 valid_for=(ONLINE_LOGFILES,PRIMARY_ROLE) db_unique_name=tyqxdg2' 因为使用适当的DB_UNIQUE_NAME特性，我们也需要定义LOG_ARCHIVE_CONFIG参数： log_archive_config='dg_config=(tyqx,tyqxdg1,tyqxdg2)' 9.以下的特性为可选特性： AFFIRM：SYNC模式的默认方式。要求LNS进程等待RFS对SRL文件执行直接I/O后才返回成功消息。 在Oracle Database 11g中，会为ASYNC目标忽略AFFIRM。 NOAFFIRM：如果未指定，将是ASYNC目标的默认方式。 COMPRESSION：发送间隔的ARCH进程在发送时压缩归档内容。 COMPRESSION=ENABLE MAX_CONNECTIONS：指定子发送间隔时用于备用目标的归档进程数量。 MAX_CONNECTIONS=5 DELAY：指定目标备用数据库的应用进程在该特性定义的延迟秒数之后再应用重做数据。基本废弃。 ALTERNATE：使用替代目标，可以重定向归档进程，以便为归档日志使用备用磁盘。 三、主备库的srl和rl 1.主库 主库的rl的作用不多说 主库的srl在配置完成时，其实是没什么用的，只有当做切换的时候，角色变为standby时才会有用 2.备库 备库的rl其实没什么用的，rl在不存在的时候，每次启动时alert会有警告，一旦切换为主库时会自动创建 备库的srl的作用在于接收主库传过来的redo log，备库再重新apply，这样就可以做到adg的实时同步。 当然，其实备库没有srl也是可以的，这样只是不能做实时同步了，备库就只能收到主库传来的归档日志才可以recover，而且主库配置log_archive_dest_n参数的时候不能用lgwr和sync了。 srl要比主库的rl多一组的原因，我认为是当主库的redo过来太快的时候，多一组就可以用作缓冲，防止切换不过来而造成的不能实时应用。 四、级联更新 有时候生产上，一主多备的需求会变成：一主一备一级联。 这个时候，对于级联库的主备库配置和普通的主备库类似，只是需要注意发送日志的参数里面，log_archive_dest_n要配置成standby的，以及角色要变为standby_logfile，standby_role 配置dg的参数说明 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-24 10:25:31 "},"dataguard/给主备环境新添加redo.html":{"url":"dataguard/给主备环境新添加redo.html","title":"给主备环境新添加redo的注意事项和步骤","keywords":"","body":"主库添加redo 相应的就会添加一组standby logifle 相应的就需要去备库操作 备库直接命令添加,会报错 需要先把实时恢复停掉,将standby_file_management设置为manual,方可正常添加 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-02-26 16:56:28 "},"base/18-Oracle-index-unusable-disable-enable.html":{"url":"base/18-Oracle-index-unusable-disable-enable.html","title":"Oracle索引的unusable、disable、enable","keywords":"","body":" unusable disable和enable invisible unusable ORACLE使索引变成不可用的状态： alter index index_name unusable; 执行成功后，如果后续需要再用到该索引的话，就必须重建。重建后会自动变成usable。 ORACLE官方文档的说法(An unusable index must be rebulit , or dropped and re-created , before it can be used.) unusable状态变回为valid 有两种方式 : 1. rebuild alter index index_name rebuild; 2. drop掉该索引，然后再重建。 drop index index_name; create index index_name on xxxxx; PS: 实际上这两种操作的结果是一样的，都是删除再重新启用，不过rebulid方式更为快捷和简单。 disable和enable enable和disable仅仅只针对函数索引 alter index index_name enable; alter index index_name disable; 两者的区别是：enable和disable仅仅只针对函数索引。 invisible 不可见索引会在表增删改数据时,更新索引.不可见索引在性能优化时测试索引的有效性很有用,不会影响其它会话的执行计划.可以通过设置系统或会话的optimizer_use_invisible_indexes为true,让不可见索引被使用. Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-27 13:35:56 "},"base/7.dbca-option-intro.html":{"url":"base/7.dbca-option-intro.html","title":"Oracle建库时的各组件的用途","keywords":"","body":"http://blog.itpub.net/205377/viewspace-1769332/ oracle10g安装组件各项简单说明 Oracle database 10g ------------------------------------oracle核心部分，软件主体 Oracle Enterprise Manager Console DB ----------企业管理控制台，分布式网格应用，不是这类应用不用选 Enterprise Edition Option -----------------------------企业级版本选项，包含若干小项 Oracle Advance Security -------------------------高级安全选项，比如指纹等外接安全设备的支持 Oracle Partationing --------------------------------分区表，管理海量数据非常有用，企业级应用可选 Oracle Spatial ---------------------------------------服务器要用到Oracle Spatial这项需要保留 Oracle Label Security -----------------------------标签安全选项 Oracle OLAP -----------------------------------------在线分析系统，相对于OLTP，适用于请求分析时间较长，但请求并发较少 Oracle COM Automation Feature --------------COM自动化对象 Data Mining Scoring Engine --------------------数据挖掘选项 Oracle Database Extentions for .Net ---------.net扩展，企业级的 Oracle Net Service Oracle Net Listener -------------------------------监听，必选，否则外界无法接入 Oracle Connection Manager -------------------连接管理，一般用不到 Oracle Call Interface (OCI) ---------------------------必选 Oracle Programmer ------------------------------------一些应用程序的编程库，一般用不到 Oracle XML Development Kit ------------------------XML开发包，结合Oracle Spatial时需要保留 Oracle Windows Interfaces Oracle Service For microsoft Transection Server ------和微软MTS对接的服务，做一些性能分析用，但不通用 Oracle Administration Assisitant For Windows --------- Oracle Counters For Windows performance monitor ----- Oracle object For OLE ------------------------------ Oracle ODBC Driveer --------------------------------使用ODBC的程序访问Oracle支持，建议安装 Oracle Provider For OLE DB -----------------------使用ADO的程序访问Oracle支持，建议安装 Oracle Data Provider For .net ----------------------for .net 的provider iSQL*Plus ------------------------------------------------------强烈不建议安装，通过网页连接Oracle并执行SQL Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-10 15:56:22 "},"base/undo的一些说明.html":{"url":"base/undo的一些说明.html","title":"UNDO的一些说明","keywords":"","body":" undo的作用 1.回退事务 2.读一致性 3.事务恢复 4.倒叙查询(FlashBack Query) undo有2个著名的报错 ora-01555 ora-30036 另外,undo表空间满了对dml有影响 UNDO参数 1.UNDO_MANAGEMENT 2.UNDO_TABLESPACE 3.UNDO_RETENTION undo相关视图 1.显示当前实例正在使用的UNDO表空间 2.显示数据库的所有UNDO表空间 3.显示UNDO表空间统计信息 4.显示UNDO段统计信息 5.显示活动事务信息 6.显示UNDO区信息 一些有用的SQL 查看undo表空间使用率 undo的作用 当使用ROLLBACK语句时回滚事务，撤销DML操作改变的数据 恢复数据库 提供读取的一致性 使用Oracle Flashback Query分析基于先前时间点的数据 使用Oracle Flashback特性从逻辑故障中恢复数据库 1.回退事务 当执行DML操作修改数据时,UNDO数据被存放到UNDO段,而新数据则被存放到数据段中,如果事务操作存在问题,就需要回退事务,以取消事务变化.假定用户A执行了语句UPDATE emp SET sal=1000 WHERE empno=7788后发现,应该修改雇员7963的工资,而不是雇员7788的工资,那么通过执行ROLLBACK语句可以取消事务变化.当执行ROLLBACK命令时,oracle会将UNDO段的UNDO数据800（工资）写回到数据段中. 2.读一致性 用户检索数据库数据时,oracle 总是使用用户只能看到被提交过的数据(读取提交)或特定时间点的数据(SELECT语句时间点).这样可以确保数据的一致性.例如,当用户A执行语句 UPDATE emp SET sal=1000 WHERE empno=7788时,UNDO记录会被存放到回滚段中,而新数据则会存放到EMP段中;假定此时该数据尚未提交,并且用户B执行SELECT sal FROM emp WHERE empno=7788,此时用户B将取得UNDO数据 800,而该数据正是在UNDO记录中取得的. 3.事务恢复 事务恢复是例程恢复的一部分,它是由oracle server自动完成的.如果在数据库运行过程中出现例程失败(如断电,内存故障,后台进程故障等),那么当重启oracle server时,后台进程SMON会自动执行例程恢复,执行例程恢复时,oracle会重新做所有未应用的记录.回退未提交事务. 4.倒叙查询(FlashBack Query) 倒叙查询用于取得特定时间点的数据库数据, 它是9i新增加的特性,假定当前时间为上午11:00,某用户在上午10:00执行UPDATE emp SET sal= 3500 WHERE empno=7788语句,修改并提交了事务(雇员原工资为3000),为了取得10:00之前的雇员工资,用户可以使用倒叙查询特征. undo有2个著名的报错 ora-01555 ora-30036 undo表空间是循环使用的,所以使用率是100%也是经常可以看到的。当undo_retetion时间到期了,就把那一部分到期的undo信息清理掉。 当出现ora-01555，我们会结合undo_retention参数来判断undo的大小到底够不够，那个时候才会去扩展undo的大小。如果没有出现ora-01555，那就不用管undo的大小。另外，undo表空间始终会使用率达到100%的，所以不用过多的看使用率100%。 ora-01555 读数据的时候从buffer读,buffer的数据块头有指针,如果指针有指向undo段的,那么就会去读undo的快照,如果这个查询很长,花费的时间超过了undo_retention里面的快照数据所保存的时间,这个时候快照就被undo移除,所以这个时候就会发生ora-01555 ora-30036 ORA-30036: unable to extend segment by 8 in undo tablespace 'UNDOTBS1' 这个错,就是说明undo表空间已经满了,根据undo_retention设置的时间，里面没有expried或者active的数据又不能释放，并且不能扩展了，所以后面的dml操作都没有做上.，那当然就登录不起撒。 另外,undo表空间满了对dml有影响 undo表空间满了,如果事务都在active，这个时候就不能释放undo空间,而这个时候undo又满了，那么这个时候其他新的事务就只能等待,这个在alert日志就不能直接反应出来。 只能通过查询出问题时间段的awr或者ash，来判断是否有DML操作的等待。 UNDO参数 1.UNDO_MANAGEMENT 该初始化参数用于指定UNDO 数据的管理方式.如果要使用自动管理模式,必须设置该参数为AUTO,如果使用手工管理模式,必须设置该参数为MANUAL,使用自动管理模式时, oracle会使用undo表空间管理undo管理,使用手工管理模式时,oracle会使用回滚段管理undo数据, 需要注意,使用自动管理模式时,如果没有配置初始化参数UNDO_TABLESPACE,oracle会自动选择第一个可用的UNDO表空间存放UNDO数据,如果没有可用的UNDO表空间,oracle会使用SYSTEM回滚段存放UNDO记录,并在ALTER文件中记载警告. 2.UNDO_TABLESPACE 该初始化参数用于指定例程所要使用的UNDO表空间,使用自动UNDO管理模式时,通过配置该参数可以指定例程所要使用的UNDO表空间. 在RAC(Real Application Cluster)结构中,因为一个UNDO表空间不能由多个例程同时使用,所有必须为每个例程配置一个独立的UNDO表空间. 3.UNDO_RETENTION 该初始化参数用于控制UNDO数据的最大保留时间,其默认值为900秒,从9i开始,通过配置该初始化参数,可以指定undo数据的保留时间,从而确定倒叙查询特征(Flashback Query)可以查看到的最早时间点 Oracle提供如下为新数据库设置撤销保留时间间隔的指导： OLTP系统：15分钟 混合： 1小时 DSS系统：3小时 闪回查询：24小时 undo相关视图 1.显示当前实例正在使用的UNDO表空间 show parameter undo_tablespace 2.显示数据库的所有UNDO表空间 SELECT tablespace_name FROMdba_tablespaces WHERE contents=’UNDO’; 3.显示UNDO表空间统计信息 使用自动UNDO管理模式时,需要合理地设置UNDO表空间的尺寸,为例合理规划UNDO表空间尺寸,应在数据库运行的高峰阶段搜集UNDO表空间的统计信息.最终根据该统计信息确定UNDO表空间的尺寸.通过查询动态性能视图V%UNDOSTAT,可以搜集UNDO统计信息. SELECT TO_CHAR(BEGIN_TIME,’HH24:MI:SS’) BEGIN_TIME, TO_CHAR(END_TIME,’HH24:MI:SS’) END_TIME,UNDOBLKS FROM V$UNDOSTAT; BEGIN_TIME用于标识起始统计时间 END_TIME用于标识结束统计时间 UNDOBLKS用于标识UNDO数据所占用的数据块个数 另外，oracle每隔10分钟生成一行统计信息 4.显示UNDO段统计信息 使用自动UNDO 管理模式时,oracle会在UNDO表空间上自动建立10个UNDO段,通过查询动态信息视图V$ROLLNAME,可以显示所有联机UNDO段的名称,通过查询动态性能视图V$ROLLLISTAT,可以显示UNDO段的统计信息.通过在V$ROLLNAME和V$ROLLLISTAT之间执行连接查询,可以监视特定UNDO段的特定信息. SELECT a.name, b.xacts, b.writes, b.extents FROM v$rollname a, v$rollstat b WHERE a.usn=b.usn; 其中： Name用于标识UNDO段的名称 xacts用于标识UNDO段所包含的活动事务个数 Writes用于标识在undo段上所写入的字节数 extents用于标识UNDO段的区个数 5.显示活动事务信息 当执行DML操作时,oracle会将这些操作的旧数据放到UNDO段中 动态性能视图v$session用于显示会话的详细信息 动态性能视图v$transaction用于显示事务的详细信息 动态性能视图v$rollname用于显示联机UNDO段的名称 通过在这3个动态性能视图之间执行连接查询,可以确定正在执行事务操作的会话,事务所使用的UNDO段,以及事务所占用的UNDO块个数. col username format a10 col name format a10 SELECT a.username, b.name, c.used_ublk FROM v$session a, v$rollname b, v$transaction c WHERE a.saddr=c.ses_addr AND b.usn=c.xidusn AND a.username=’SCOTT’; 6.显示UNDO区信息 数据字典视图dba_undo_extents用于显示UNDO表空间所有区的详细信息.包括UNDO区尺寸和状态等信息. SELECT extend_id, bytes, status FROM dba_undo_extents WHERE segment_name’_SYSSMU5$’; 其中： extent_id用于标识区编号 bytes用于标识区尺寸 status用于标识区状态(ACTIVE:表示该区处于活动状态,EXPIRED:标识该区未用) 一些有用的SQL 查看undo表空间使用率 select tablespace_name, sum(total_size) \"total_size_M\", sum(total_free) \"free_size_M\", sum(max_continue) \"最大连续空间/M\", round(sum(total_free) / sum(total_size) * 100) \"剩余百分比/ratio\" from ((select tablespace_name, (0) total_size, round(sum(bytes) / 1024 / 1024, 2) total_free, round(max(bytes) / 1024 / 1024, 2) max_continue from dba_free_space group by tablespace_name) union all (select tablespace_name, round(sum(bytes) / 1024 / 1024, 2), 0, 0 from dba_data_files group by tablespace_name)) group by tablespace_name order by 5 asc; Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-02-23 20:11:58 "},"backup/rman备份中的百分号后面的字母的含义.html":{"url":"backup/rman备份中的百分号后面的字母的含义.html","title":"rman备份中的百分号后面的字母的含义","keywords":"","body":"backup incremental level 0 database format='LEV0%d%t%U%s＿%p' format=string 文件路径和名称的格式串，其中可包含宏变量： 符号 含义 %c copy ID %p backup piece ID %s backup set ID %e log sequence %h log thread ID %d database name %n database name(x填充到8个字符) %I DBID %f file ID %F DBID, day, month, year, and sequencer的复合 %N tablespace name %t timestamp %M mh mm格式 %Y year yyyy格式 %u backup set+time((x填充到8个字符) %U %u%p%c %% % The format specifier %U is replaced with unique filenames for the files when you take backups. the %F element of the format string combines the DBID, day, month, year, and sequence number to generate a unique filename. %F must be included in any control file autobackup format. Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-03-20 16:48:24 "},"backup/rman.html":{"url":"backup/rman.html","title":"利用rman进去备份与恢复","keywords":"","body":" rman中的备份与恢复 创建目录存放相应的备份 rman全备 恢复 只恢复某个数据文件 恢复spfile 恢复全库 参考 rman中的备份与恢复 创建目录存放相应的备份 mkdir -p /orabak/logs mkdir -p /orabak/rmanbak/{datafile,archivelog,controlfile,spfile} rman全备 备份的rman脚本 $ more all_backup.rcv run{ configure controlfile autobackup on; configure controlfile autobackup format for device type disk to '/orabak/rmanbak/controlfile/controlfile_%F.bak'; allocate channel c1 type disk; allocate channel c2 type disk; allocate channel c3 type disk; allocate channel c4 type disk; backup full tag 'dbfull' format '/orabak/rmanbak/datafile/full_%u_%s_%p' database; sql 'alter system archive log current'; backup archivelog all format '/orabak/rmanbak/archivelog/arch_%u_%s_%p'; backup spfile format '/orabak/rmanbak/spfile/spfile_%d_%U'; delete noprompt expired backup; delete noprompt obsolete; release channel c1; release channel c2; release channel c3; release channel c4; } 如果设置了configure controlfile autobackup on; 那么controlfile和spfile都会自动被备份的,当然为了更好的找到它们,我们还是可以指定路径 执行rman脚本 #!/bin/sh export ORACLE_SID=orcl export ORACLE_HOME=/u01/app/oracle/product/11.2.0/db_1 export PATH=$ORACLE_HOME/bin:$PATH export TIMESTAMP=`date +'%Y_%m_%d_%H:%M'` rman target / nocatalog cmdfile=/home/oracle/rmanbak/scripts/all_backup.rcv log=/orabak/logs/rman_bk_all_${TIMESTAMP}.log 恢复 只恢复某个数据文件 保证数据库能启动到mount状态 rman > restore datafile 1; rman > recover datafile 1; rman > alter database open; 恢复spfile # 就算spfile丢失了,可以鼓捣启动到nomount状态,再restore spfile RMAN> startup nomount; RMAN> restore spfile from '/orabak/rmanbak/spfile/spfile_xxxx.bak'; RMAN> startup nomount force; 恢复全库 建设全库都丢了,那么恢复的步骤就是 恢复spfile 恢复controlfile restore数据库 添加archive的目录进行恢复 打开数据库 step1: 恢复spfile RMAN> startup nomount; RMAN> restore spfile from '/orabak/rmanbak/spfile/spfile_xxxx.bak'; RMAN> startup nomount force; step2: 恢复控制文件 RMAN> restore controlfile from '/orabak/rmanbak/controlfile/controlfile_xxx'; //还原控制文件 RMAN> alter database mount; //启动数据库到mount状态 step3: restore数据库 RMAN> list backup of database; //查看备份集 RMAN> restore database; step4: 添加archive的目录进行恢复 RMAN> catalog start with '/orabak/rmanbak/archivelog/'; //将归档的日志也导入进来 RMAN> restore database; //还原数据文件 step5: 打开数据库 RMAN> alter database open; 参考 https://www.cnblogs.com/storymedia/p/4536553.html https://blog.csdn.net/cuiyan1982/article/details/78327506 https://blog.csdn.net/u013012406/article/details/57074395 https://blog.csdn.net/zhuke0203/article/details/71311993 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-03-20 17:35:48 "},"backup/rman备份脚本.html":{"url":"backup/rman备份脚本.html","title":"常用rman备份脚本","keywords":"","body":"rman备份脚本 全备 run{ sql 'alter system switch logfile'; crosscheck archivelog all; backup as backupset full database; crosscheck backup; delete noprompt expired backup; delete noprompt obsolete; delete noprompt archivelog until time 'sysdate-8' all; backup current controlfile; sql 'alter database backup controlfile to trace'; sql 'alter system switch logfile'; } 0级增量备份 run{ sql 'alter system switch logfile'; crosscheck archivelog all; backup as backupset incremental level 0 database; crosscheck backup; delete noprompt expired backup; delete noprompt obsolete; delete noprompt archivelog until time 'sysdate-8' all; backup current controlfile; sql 'alter database backup controlfile to trace'; sql 'alter system switch logfile'; } 0级增量备份与全备的区别： 二者都是全备，但是0级增量备份可以用于增量备份恢复的基础，而单独的全备不能用于增量备份的恢复基础！ 1级增量备份 run{ sql 'alter system switch logfile'; crosscheck archivelog all; backup as backupset incremental level 1 database; crosscheck backup; delete noprompt expired backup; delete noprompt obsolete; delete noprompt archivelog until time 'sysdate-8' all; sql 'alter system switch logfile'; } crontab脚本 0,10,20,30,40,50 * * * * /u01/app/oracle/scripts/rmanL0Call.sh >> /u01/app/oracle/scripts/rmanL0Call.log 2>&1 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-30 13:25:08 "},"backup/数据泵备份.html":{"url":"backup/数据泵备份.html","title":"常用数据泵备份脚本","keywords":"","body":"#!/bin/sh #set environment variable export ORACLE_SID=cddcdb export ORACLE_HOME=/u01/app/oracle/db_1 export NLS_LANG=american_america.zhs16gbk FILE=`date +%Y%m%d` $ORACLE_HOME/bin/expdp system/system123 directory=dump full=y dumpfile=CDDC_DB_$FILE.dmp logfile=dump_d:CDDC_DB_$FILE.log find /dbbak/flashback_recovery_area/dmps/ -name \"*.dmp\" -mtime +30 -exec rm {} \\; find /dbbak/flashback_recovery_area/ -name \"*.log\" -mtime +30 -exec rm {} \\; Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-30 13:24:10 "},"backup/有数据文件的数据恢复.html":{"url":"backup/有数据文件的数据恢复.html","title":"记录一次有数据文件的数据库恢复","keywords":"","body":"背景 一个库由于需要恢复，留存的数据包括所有的数据文件和redo和controlfile 记录下恢复过程 修改pfile中controlfile的位置,用pfile启动到nomount 启动数据库到mount状态,并转储控制文件 根据转储的控制文件修改数据库中datafile的位置 打开数据库 根据alert来修正错误 关键点 关键点1 pfile里面主要修改的就是db_name,要和原库对应的control里面的名字对应上 修改没问题后，可以以spfile的方式启动 关键点2 转储控制文件 alter database backup controlfile to trace as '路径'; 可以查看里面数据文件的位置,再对应上传到服务器的数据文件的位置进行修改 alter database rename file 'path-old-xxx' to 'path-new-xxx'; 关键点3 一直打开alert日志进行追踪,在几个阶段都非常有用 startup nomount; alter database mount; alter database open; 关键点4 如果undo的文件找不到,会报错的,根据alter日志,在mount状态可以先将undo_tablespace修改为已经存在的undotbs2 在mount状态下可以查询select name from v$datafile;来获取相应的数据文件的位置 关键点5 默认的redo的位置可能和规划的位置不一样,可以采取先创建再删除再创建的方式进行替换 删除状态为inactive的redo select * from v$log; alter database drop logifle group x; alter database add logifle group x 'path-xxxx' size xxxM ; 关键点6 临时文件的位置可能和规划的位置不一样,可以采取先添加临时数据文件再删除老的临时文件 alter tablespace temp add tempfile 'path-new-xxxx' size 10G autoextend; alter tablespace temp drop tempfile 'path-old-xxxx'; 关键点7 第一次恢复完,在打开数据库的时候报错: ORA-00704: bootstrap process failure ORA-39700: database must be opened with UPGRADE option 这个说明是老的数据文件对应的数据库版本和新的数据库的版本不一致! 如果老的版本小于新的版本,那么可以更新数据字典来打开数据库; @?/rdbms/admin/catalog.sql @?/rdbms/admin/catproc.sql 如果老的版本大于新的版本,那么就只能装一个和老的版本的一样的库再来重复上面的恢复操作!! 否则,就算执行了上面的2个脚本,也会报如下类似的错误: ORA-00600 [qcisSetPlsqlCtx:tzi init] mos有个文章可以参考 : ORA-600 [qcisSetPlsqlCtx:tzi init] after Database Restart (文档 ID 362036.1) 上面说的主要是干一件事情： 查询所用到的时区的TZ file select NAME, VALUE$ from SYS.PROPS$ where NAME like ('DST_%_TT_VERSION'); 然后去 $ORACLE_HOME/oracore/zoneinfo/ 下查看否有上面提及的TZ file 当然，因为这儿是新的库的版本比老的数据文件对应的数据库版本低，所以按照上面的操作做了也没有多大的用！ Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-04-01 15:24:01 "},"manage/27.alter-database-archivelog.html":{"url":"manage/27.alter-database-archivelog.html","title":"修改数据库实例到归档模式","keywords":"","body":" 修改RAC到归档模式 申请归档磁盘 修改初始化参数 备份spfile 把两个节点的实例都停掉 在第一个实例操作 在第二个实例操作 修改RAC到归档模式 申请归档磁盘 申请归档磁盘,做成asm磁盘组,比如命名叫 +ARCH 修改初始化参数 alter system set log_archive_dest_1='location=+ARCH' sid='*' ; 备份spfile create pfile='/home/oracle/pfile.bak.20181219' from spfile; 把两个节点的实例都停掉 shutdown immediate 在第一个实例操作 startup mount alter database archivelog; alter database open; 在第二个实例操作 startup Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-12-19 10:56:31 "},"dataguard/6.multialive-qianyi.html":{"url":"dataguard/6.multialive-qianyi.html","title":"双活及迁移的一些事","keywords":"","body":" 在时间窗口比较大的情况下，建议步骤： 一些经验分享： 1.巧妙的利用dbca来做备库的配置 2.数据泵在10g的导出脚本参考 3.导出之前的操作 4.在导入之前需要做的准备工作 5.数据泵在11g的导入脚本参考 6.补充导入数据，如同义词 7.特别注意dg对于临时文件的同步有点问题 最近做了几个网省的双活，遇到的情况几乎都是要将以前老版本的10g迁移到11g上，并搭建双活。 方便今后参考，特总结一下： 在时间窗口比较大的情况下，建议步骤： 1.可以提前安装主备的RAC环境 2.在两套RAC上搭建双活 3.在10g的环境做expdp 4.在11g的主库RAC上做impdp 5.在11g的主库上做utlrp编译，以及收集统计信息 6.验证 一些经验分享： 1.巧妙的利用dbca来做备库的配置 做RAC到RAC的双活的时候，为了简化后期的操作步骤，已经在备库创建好了同主库数据库名一致的实例。创建实例时指定db_name、db_unique_name、service_name。在配置过程中只是删除物理文件，其他资源保留。 2.数据泵在10g的导出脚本参考 [oracle@tmp]$ cat exp_orcl0823.sh export ORACLE_SID=orcl nohup expdp \\'/ as sysdba\\' parallel=4 DIRECTORY=dump_dir DUMPFILE=orcl0823_%U.dmp LOGFILE=orcl0823.log full=y job_name=orcl0823_expdp exclude=statistics & 3.导出之前的操作 为了防止新的连接进来，造成数据的不一致。所以可以先把监听停了，然后kill sesion 10g需要在两个节点分别做 alter system kill session 'sid,serial#'; 11g只需要在一个节点做 alter system kill session 'sid,serial#,@inst_id'; 4.在导入之前需要做的准备工作 1.创建相应的表空间和临时表空间 2.相关的用户不需要创建，在imdp的时候用户/密码/权限都会被相应的创建出来 3.查询一下用户/用户表/表空间的所属，看是否存在权限的问题。遇到过一个用户在某些表空间没权限，但它的表却有存放在这个表空间。用 alter user user_name quota tablespace_name 来搞定 5.数据泵在11g的导入脚本参考 [oracle@temp]$ more impdp_orcl0823.sh export ORACLE_SID=orcl nohup impdp \\'/ as sysdba\\' DIRECTORY=dump_dir parallel=4 dumpfile=orcl0823_%U.dmp logfile=impdp_orcl0823.log SCHEMAS=scott,hr,sh cluster=no job_name=impdp_orcl0823 & 6.补充导入数据，如同义词 在双活的部署过程中，发现连接备库的app启动时报表不存在，经排查发现是备库对应的用户使用了同义词去访问同一个库的其他用户的表，但是expdp的时候选用full=y的不会单独备份同义词的。后来经过手工创建同义词搞定 SELECT 'create public synonym ' || synonym_name || ' for ' || table_owner || '.' || table_name || ';' FROM dba_synonyms s WHERE s.owner = 'PUBLIC' AND s.table_owner = UPPER ('&input_owner'); 当然我们也可以在expdp的时候把同义词也导出来： expdp sys/Oracle directory=dump_dir dumpfile=syns.dmp logfile=exp_syns.log full=y include=PUBLIC_SYNONYM/SYNONYM:\\\"IN \\(SELECT synonym_name FROM dba_synonyms WHERE table_owner=\\'USER_NAME\\'\\)\\\" 再导入进去： impdp sys/Oracle directory=dump_dir dumpfile=syns.dmp logfile=imp_syns.log full=y include=synonym include具体怎么写，可以查询数据字典： ``` select * from database_export_objects t 的path那一列 ``` 7.特别注意dg对于临时文件的同步有点问题 在主库上创建的临时表空间，在备库有定义，但是查询gv$tempfile查不到文件。这个也是日了狗了。 可以采用两种办法解决： 方法1：在主库上给相应的临时表空间添加数据文件 alter tablespace xxxx add tempfile '+DATADG' size 10g autoextend on; 方法2：将用户的默认临时表空间指向temp alter user xxx default temporary tablespace temp; Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-12-26 11:17:47 "},"manage/20.awr-workhouse-intro.html":{"url":"manage/20.awr-workhouse-intro.html","title":"awr仓库的运维","keywords":"","body":" 不重启清空共享池--慎用！！！ 重建AWR脚本 手动创建快照 删除快照 清除AWR数据 查看当前的快照保留策略 修改快照的保留间隔 创建基线 删除基线 基线重命名 修改缺省移动窗口基线保留值 管理基线样本 创建单个基线模板 创建重复基线样本 基线样本的删除 查看各个对象占用SYSAUX的详细信息 生成AWR报告 AWR仓库数据的导出与导入 AWR相关的重要视图和数据字典 不重启清空共享池--慎用！！！ alter system flush shared_pool; 重建AWR脚本 @?\\rdbms\\admin\\catawrtb.sql @?\\rdbms\\admin\\utlrp.sql ORACLE 11g需要需要运行如下脚本： @?\\rdbms\\admin\\execsvrm.sql 注意在RAC环境下的话，需要取消集群参数后，待执行完成后再次修改过来： alter system set cluster_database = false scope = spfile; 手动创建快照 BEGIN DBMS_WORKLOAD_REPOSITORY.CREATE_SNAPSHOT(); END; 删除快照 删除99-100的快照 BEGIN DBMS_WORKLOAD_REPOSITORY.DROP_SNAPSHOT_RANGE (low_snap_id => 99, high_snap_id => 100, dbid => xxxx); END; 清除AWR数据 @?\\rdbms\\admin\\catnoawr.sql 查看当前的快照保留策略 select * from dba_hist_wr_control; 修改快照的保留间隔 保留10天，30分钟采集一次 ，topnsql为50 BEGIN DBMS_WORKLOAD_REPOSITORY.MODIFY_SNAPSHOT_SETTINGS( retention => 10*24*60, interval => 30, topnsql => 50, dbid => xxxxx); END; 创建基线 基于快照号创建基线 BEGIN DBMS_WORKLOAD_REPOSITORY.CREATE_BASELINE (start_snap_id => 200, end_snap_id => 201, baseline_name => 'my_baseline', dbid => xxxx, expiration => 10); END; 基于指定时间创建基线 BEGIN DBMS_WORKLOAD_REPOSITORY.CREATE_BASELINE ( start_time => TO_DATE ('2017-04-14 6:00:00', 'yyyy-mm-dd hh24:mi:ss'), end_time => TO_DATE ('2017-04-14 8:00:00', 'yyyy-mm-dd hh24:mi:ss'), baseline_name => 'peak_baseline2', expiration => 10); END; 注意： expiration标识保留时间为10天，如果没有设置则则该基线以及相应的快照被永久保留 通过dba_hist_baseline可以查询到相关信息 删除基线 BEGIN DBMS_WORKLOAD_REPOSITORY.DROP_BASELINE (baseline_name => 'my_baseline', cascade => FALSE, dbid => xxxx); END; 基线重命名 BEGIN DBMS_WORKLOAD_REPOSITORY.RENAME_BASELINE ( old_baseline_name => 'my_baseline', new_baseline_name => 'your_baseline', dbid => xxxx); END; 修改缺省移动窗口基线保留值 --查看缺省的window_size SELECT baseline_name, baseline_type, moving_window_size FROM dba_hist_baseline WHERE baseline_name = 'SYSTEM_MOVING_WINDOW'; BASELINE_NAME BASELINE_TYPE MOVING_WINDOW_SIZE ------------------------ ------------- ------------------ SYSTEM_MOVING_WINDOW MOVING_WINDOW 8 BEGIN DBMS_WORKLOAD_REPOSITORY.MODIFY_BASELINE_WINDOW_SIZE ( window_size => 7, dbid => xxxx); END; / --window_size为天，只能够小于等于当前快照保留时间，否则报错，如下： ERROR at line 1: ORA-13541: system moving window baseline size (864000) greater than retention (691200) ORA-06512: at \"SYS.DBMS_WORKLOAD_REPOSITORY\", line 686 ORA-06512: at line 2 管理基线样本 创建单个基线模板 BEGIN DBMS_WORKLOAD_REPOSITORY.CREATE_BASELINE_TEMPLATE ( start_time => TO_DATE ('2018-08-14 09:00:00', 'yyyy-mm-dd hh24:mi:ss'), end_time => TO_DATE ('2018-08-14 11:00:00', 'yyyy-mm-dd hh24:mi:ss'), baseline_name => 'baseline_single', template_name => 'template_single'', expiration => 10, dbid => xxxx); END; 在上面的示例中，创建了一个单一的基线样本，并且指定了相应的时间范围，基线的名称及保留期限等。那么在这个时间范围内的相应的快照会被保留，同时这个基线可以用于后续在发现性能问题的时候进行比对。 创建重复基线样本 重复的基线样本指的是在将来某个特定的时间范围内，Oracle会参照这个设定的样本自动创建基线。比如，可以创建一个重复的基线样本，使得在2018年每周一9:00-10:00自动生成基线。 SQL> alter session set nls_date_format='yyyy-mm-dd hh24:mi:ss'; BEGIN DBMS_WORKLOAD_REPOSITORY.CREATE_BASELINE_TEMPLATE ( day_of_week => 'monday', hour_in_day => 9, duration => 2, expiration => 30, start_time => '2018-01-01 09:00:00', end_time => '2018-12-31 23:00:00', baseline_name_prefix => 'baseline_2018_mondays', template_name => 'template_2018_mondays', dbid => xxxx); END; / --查看已经创建的基线样本 SQL> select t.template_name, 2 t.template_type, 3 t.start_time, 4 t.end_time, 5 t.day_of_week, 6 t.hour_in_day, 7 t.duration 8 from dba_hist_baseline_template t; TEMPLATE_NAME TEMPLATE_ START_TIME END_TIME DAY_OF_WE HOUR_IN_DAY DURATION --------------------- --------- ------------------- ------------------- --------- ----------- -------- template_single SINGLE 2018-08-14 09:00:00 2018-08-14 11:00:00 template_2018_mondays REPEATING 2018-01-01 09:00:00 2018-12-31 10:00:00 MONDAY 17 3 在上面的示例中创建了一个重复从2018年1月1日起的每周一(day_of_week)会自动生成一个基线，其开始时间为9点(hour_in_day)，其持续时间为2小时(duration)，有效期为30天(expiration)，整个基线的起止时间范围为：2018-01-01 09:00:00至2018-12-31 23:00:00，同时也指定了基线样本的名称以及基线前缀名称。 基线样本的删除 BEGIN DBMS_WORKLOAD_REPOSITORY.DROP_BASELINE_TEMPLATE ( template_name => 'template_single', dbid => xxxx); END; 查看各个对象占用SYSAUX的详细信息 @?/rdbms/admin/awrinfo.sql 生成AWR报告 --单实例下生成AWR报告 SQL> @?/rdbms/admin/awrrpt.sql --RAC环境下生成AWR报告 SQL> @$ORACLE_HOME/rdbms/admin/awrgrpt.sql --指定数据库实例生成AWR报告 SQL> @$ORACLE_HOME/rdbms/admin/awrrpti.sql --生成SQL语句AWR报告 SQL> @$ORACLE_HOME/rdbms/admin/awrsqrpt.sql --指定实例生成SQL语句AWR报告 SQL> @$ORACLE_HOME/rdbms/admin/awrsqrpi.sql --生成比较的AWR报告 SQL> @$ORACLE_HOME/rdbms/admin/awrddrpt.sql --RAC环境下生成比较的AWR报告 @$ORACLE_HOME/rdbms/admin/awrgdrpt.sql AWR仓库数据的导出与导入 导出： SQL> @?/rdbms/admin/awrextr.sql ~~~~~~~~~~~~~ AWR EXTRACT ~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~ This script will extract the AWR data for a range of snapshots ~ ~ into a dump file. The script will prompt users for the ~ ~ following information: ~ ~ (1) database id ~ ~ (2) snapshot range to extract ~ ~ (3) name of directory object ~ ~ (4) name of dump file ~ ~~~~~~~~~~~~~~~~~~~~~ ... 导入: 导入过程也类似 SQL> @?/rdbms/admin/awrload AWR相关的重要视图和数据字典 v$active_session_history : 显示活跃的数据库会话的活动，每秒采样一次 v$metric和v$metric_history：提供度量数据来跟踪系统性能。视图被组织成好几个组，这些组定义在v$metricgroup视图中 DBA_HIST_ACTIVE_SESS_HISTORY:内存中活动会话历史信息 DBA_HIST_BASELINE : 捕获的基线的信息 DBA_HIST_BASELINE_DETAILS: 特定基线的明细信息 DBA_HIST_BASELINE_TEMPLATE：基线模板相关信息 DBA_HIST_DATABASE_INSTANCE：数据库环境 DBA_HIST_DB_CACHE_ADVICE：根据历史数据预测在不同的cache size下的物理读 DBA_HIST_DISPATCHER：每个snapshot下调度进程的信息 DBA_HIST_DYN_REMASTER_STATS：动态remastering进程的统计信息 DBA_HIST_IOSTAT_DETAIL：按未见类型和功能来统计的历史I/O信息 DBA_HIST_SHARED_SERVER_SUMMARY：共享服务器的统计信息 DBA_HIST_SNAPSHOT：快照信息 DBA_HIST_SQL_PLAN：执行计划 DBA_HIST_WR_CONTROL：AWR控制信息 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-27 13:36:06 "},"manage/24.slove-error-1089.html":{"url":"manage/24.slove-error-1089.html","title":"处理一个error-1089问题","keywords":"","body":"kkjcre1p: unable to spawn jobq slave process, error 1089 今天数据库在改ip后，shutdown的时候不能正常关闭，后台alert日志报错： kkjcre1p: unable to spawn jobq slave process, error 1089 查了下资料，参考：Kkjcre1p: Unable To Spawn Jobq Slave Process, Error 1089 [ID 344275.1] 警告原因如下： If a job is about to be spawned when shutdown of database is in progress, you will see these errors in the alert log file and this is perfectly valid. 解决方法： 设置_JOB_QUEUE_INTERVAL更大值，减少出现该警告概率 One workaround that we can suggest is to set an underscore parameter _JOB_QUEUE_INTERVAL=120 or greater value The default value is 60 but when we change to 120 there are less chances of getting the above warnings in the alert log file. 由bug23102157引起，打补丁 补丁链接 https://updates.oracle.com/download/23102157.html Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-12-10 09:29:24 "},"manage/23.oracle-startup-auto.html":{"url":"manage/23.oracle-startup-auto.html","title":"设置Oracle开机自启动","keywords":"","body":"设置Oracle开机自动启动 1.修改dbstart脚本 修改$ORACLE_HOME/bin/dbstart脚本中的ORACLE_HOME_LISTNER=$ORACLE_HOME 2.修改 /etc/oratab 文件 修改 /etc/oratab ，将 orcl:/u01/app/oracle/product/11.2.0/dbhome_1:N修改为 orcl:/u01/app/oracle/product/11.2.0/dbhome_1:Y 3.修改 /etc/rc.d/rc.local 文件 修改/etc/rc.d/rc.local启动文件，添加数据库启动脚本dbstart touch /var/lock/subsys/local su oracle -lc \"/u01/app/oracle/product/11.2.0/dbhome_1/bin/lsnrctl start\" su oracle -lc \"/u01/app/oracle/product/11.2.0/dbhome_1/bin/dbstart\" 注意: 在这个rc.local中的touch /var/lock/subsys/local 它的作用是判断是否已经执行过 rc.local ,如果已经执行过则会建立一个/var/lock/subsys/local文件,否则就回去执行这个/etc/rc.d/rc.local 另外，之前遇到过修改了rc.local脚本但不执行的问题,原因是rc.local文件的权限问题 4.重启服务器验证 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-24 10:26:59 "},"manage/25.where-is-alert.html":{"url":"manage/25.where-is-alert.html","title":"日志的位置","keywords":"","body":"工作中被问的最多的问题就是：alert日志在哪儿找。。 11g版本 从 Oracle 11g 开始，Oracle 以 XML与传统的文本两种格式提供 Alert日志。 新的日志位置由 Automatic Diagnostic Repository (ADR)决定。 可以通过新的初始化参数 DIAGNOSTIC_DEST控制 ADR BASE的位置。 如果没有设定这个初始化参数的位置，而只设置 ORACLE_BASE环境变量的话，那么，各种日志的位置在 ：$ORACLE_BASE/diag/product_type{eg:rdbms}}/product_id{eg:11g}/instance_id 既没有设定DIAGNOSTIC_DEST又没有设定 ORACLE_BASE , 那么日志的位置为:$ORACLE_HOME/log 还可以直接通过查询oracle 11g环境下可以直接通过查询bdump参数，来找到alert日志位置: SQL> show parameter background_dump_dest; NAME TYPE VALUE ------------------------------------ ----------- ------------------------------ background_dump_dest string /u01/app/oracle/product/11.2.0/db_1/rdbms/log 举个例子: 假设为单实例环境 ORACLE_BASE=/u01/app/oracle; ORACLE_HOME=$ORACLE_BASE/product/11.2.0/db_1; ORACLE_SID=orcl 那么数据库alert日志的位置在： /u01/app/oracle/diag/rdbms/orcl/orcl/alertORCL.log 假设为RAC环境 ORACLE_BASE=/u01/app/oracle; ORACLE_HOME=$ORACLE_BASE/product/11.2.0/db_1; ORACLE_SID=orcl1 那么 实例1的数据库alert日志的位置在： /u01/app/oracle/diag/rdbms/orcl/orcl1/alertORCL1.log 实例2的数据库alert日志的位置在： /u01/app/oracle/diag/rdbms/orcl/orcl2/alertORCL2.log 10g版本： 10g相对简单，alert的位置在：$ORACLE_BASE/admin/$ORACLE_SID/bdump 12c 12c与11g类似，但日志并不在bdump目录下，可以通过v$diag_info视图查询 SQL> show parameter dump NAME TYPE VALUE ------------------------------------ ----------- ------------------------------ background_core_dump string partial background_dump_dest string /u01/app/oracle/product/12.2.0 /db_1/rdbms/log core_dump_dest string /u01/app/oracle/diag/rdbms/orc l/racdb11/cdump max_dump_file_size string unlimited shadow_core_dump string partial user_dump_dest string /u01/app/oracle/product/12.2.0 ======================说明========================== adump:审计信息 bdump：后台进程trace和alert log,就是说alert_sid.log日志也存在此处 cdump：core trace,一般是用来日志应用程序的 除非数据库出了问题 否则基本上不会有什么信息 dpdump ：是存放一些登录信息的 pfile ：初始化参数文件 initSID udump ：user dump，前台手动trace的 比如sql trace之后session的trace文件 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-12-17 17:41:57 "},"manage/29.manage-user.html":{"url":"manage/29.manage-user.html","title":"用户管理","keywords":"","body":"用户管理 创建用户 创建的新用户是没有任何权限的，甚至连登陆的数据库的权限都没有，需要为其指定相应的权限。 SQL> create user username 　　 identified by password 　　default tablespace tablespace 　　temporary tablespace tablespace 　　profile profile 　　quota integer/unlimited on tablespace; 示例: SQL> create user mydog 　　identified by mydog　 // 如果密码是数字，请用双引号括起来 　　default tablespace account 　　temporary tablespace temp 　　profile default 　　quota 50m on account; SQL> grant connect, resource to mydog; 　 相关视图 查询用户缺省表空间、临时表空间 SQL> select username, default_tablespace, temporary_tablespace from dba_users; 查询系统资源文件名 SQL> select * from dba_profiles; profile使用 SQL> select username, profile, default_tablespace, temporary_tablespace from dba_users; SQL> create profile my_profile limit 　　　failed_login_attempts 5 　　　idle_time 5; SQL> alter user mydog profile my_profile; 修改用户 SQL> alter user 用户名 　　identified 口令 　　default tablespace tablespace 　　temporary tablespace tablespace 　　profile profile 　　quota integer/unlimited on tablespace; 示例: 1.修改口令字：alter user mydog identified by \"123456\"; 2.修改用户缺省表空间：alter user mydog default tablespace users; 3.修改用户临时表空间：alter user mydog temporary tablespace temp_data; 4.强制用户修改口令字：alter user mydog password expire; 5.将用户加锁：alter user mydog account lock;　// 加锁 6.将用户解锁：alter user mydog account unlock;　// 解锁 删除用户 SQL>drop user 用户名;　//用户没有建任何实体 SQL>drop user 用户名 CASCADE;　// 将用户及其所建实体全部删除 // 当前正连接的用户删除不了,需要先把session kill掉 查询用户会话 1、查询用户会话信息：select username, sid, serial#, machine from v$session; 2、删除用户会话信息：alter system kill session 'sid, serial#'; 3、查询用户SQL语句： select user_name, sql_text from v$open_cursor; 用户权限 权限分类 系统权限：系统规定用户使用数据库的权限。（系统权限是对用户而言) 实体权限：某种权限用户对其它用户的表或视图的存取权限。（是针对表或视图而言的） 系统权限管理 系统权限分类： DBA: 拥有全部特权，是系统最高权限，只有DBA才可以创建数据库结构。 RESOURCE:拥有Resource权限的用户只可以创建实体，不可以创建数据库结构。 CONNECT:拥有Connect权限的用户只可以登录Oracle，不可以创建实体，不可以创建数据库结构。 对于普通用户：授予connect, resource权限。 对于DBA管理用户：授予connect，resource, dba权限。 系统权限授权命令 SQL> grant connect, resource, dba to 用户名1 [,用户名2]...; 示例 SQL> connect system/manager SQL> Create user mydog identified by mydog; SQL> grant connect, resource to mydog; 查询用户拥有哪里权限 SQL> select * from dba_role_privs;　--where grantee='SYS'; SQL> select * from dba_sys_privs; SQL> select * from role_sys_privs;　--where role='DBA'; 系统权限传递： 增加WITH ADMIN OPTION选项，则得到的权限可以传递。 SQL> grant connect, resorce to mydog with admin option;　//可以传递所获权限。 系统权限回收：系统权限只能由DBA用户回收 SQL> Revoke connect, resource from mydog; 系统权限无级联，即A授予B权限，B授予C权限，如果A收回B的权限，C的权限不受影响； 系统权限可以跨用户回收，即A可以直接收回C用户的权限。 实体权限管理 实体权限分类： select, update, insert, alter, index, delete, all　//all包括所有权限 execute　//执行存储过程权限 user01: SQL> grant select, update, insert on product to user02; SQL> grant all on product to user02; user02: SQL> select * from user01.product; // 此时user02查user_tables，不包括user01.product这个表，但如果查all_tables则可以查到，因为它可以访问。 将表的操作权限授予全体用户： 　SQL> grant all on product to public;　// public表示是所有的用户，这里的all权限不包括drop。 实体权限数据字典 SQL> select owner, table_name from all_tables; // 用户可以查询的表 SQL> select table_name from user_tables;　// 用户创建的表 SQL> select grantor, table_schema, table_name, privilege from all_tab_privs; // 获权可以存取的表（被授权的） SQL> select grantee, owner, table_name, privilege from user_tab_privs;　 // 授出权限的表(授出的权限) 实体权限传递(with grant option)： user01: SQL> grant select, update on product to user02 with grant option; // user02得到权限，并可以传递。 实体权限回收： user01: SQL>Revoke select, update on product from user02;　//传递的权限将全部丢失。 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-12-19 12:23:42 "},"manage/28.create-user-profile.html":{"url":"manage/28.create-user-profile.html","title":"给用户创建profile","keywords":"","body":" 创建用户profile 创建密码复杂度校验函数 创建profile 语法树 选项说明 示例 profile后续操作 查看创建的profile 将profile文件分配给用户 profile生效 用户密码过期问题 创建用户profile 创建密码复杂度校验函数 sqlplus / as sysdba SQL> @?/rdbms/admin/utlpwdmg.sql 创建profile 语法树 选项说明 profile部分 profile：配置文件的名称。Oracle数据库以以下方式强迫资源限制： 如果用户超过了connect_time或idle_time的会话资源限制，数据库就回滚当前事务，并结束会话。用户再次执行命令，数据库则返回一个错误 如果用户试图执行超过其他的会话资源限制的操作，数据库放弃操作，回滚当前事务并立即返回错误。用户之后可以提交或回滚当前事务，必须结束会话。 Unlimited：分配该profile的用户对资源使用无限制，当使用密码参数时，unlimited意味着没有对参数加限制。 Default：指定为default意味着忽略对profile中的一些资源限制，Default profile初始定义对资源不限制，可以通过alter profile命令来改变。 Resource_parameter部分 Logical_reads_per_session：每会话允许读的数据块的数目，包括从内存和磁盘读的所有数据块。 Logical_read_per_call：一次执行SQL（解析、执行和提取）调用允许读的数据块最大数目。 Private_sga：指定一个会话可以在共享池（SGA）中所允许分配的最大空间，以字节为单位。（该限制只在使用共享服务器结构时才有效，会话在SGA中的私有空间包括私有的SQL和PL/SQL，但不包括共享的SQL和PL/SQL）。 Composite_limit：指定一个会话的总的资源消耗，以service units单位表示。Oracle数据库以有利的方式计算cpu_per_session，connect_time，logical_reads_per_session和private-sga总的service units Password_parameter部分： Password_life_time：指定同一密码所允许使用的天数。如果同时指定了password_grace_time参数，如果在grace period内没有改变密码，则密码会失效，连接数据库被拒绝。如果没有设置password_grace_time参数，默认值unlimited将引发一个数据库警告，但是允许用户继续连接。 Password_reuse_time和password_reuse_max： 这两个参数必须互相关联设置，password_reuse_time指定了密码不能重用前的天数，而password_reuse_max则指定了当前密码被重用之前密码改变的次数。两个参数都必须被设置为整数。1．如果为这两个参数指定了整数，则用户不能重用密码直到密码被改变了password_reuse_max指定的次数以后在password_reuse_time指定的时间内。如：password_reuse_time=30，password_reuse_max=10，用户可以在30天以后重用该密码，要求密码必须被改变超过10次。 2．如果指定了其中的一个为整数，而另一个为unlimited，则用户永远不能重用一个密码。 3.．如果指定了其中的一个为default，Oracle数据库使用定义在profile中的默认值，默认情况下，所有的参数在profile中都被设置为unlimited，如果没有改变profile默认值，数据库对该值总是默认为unlimited。 4．如果两个参数都设置为unlimited，则数据库忽略他们。 Password_grace_time：指定宽限天数，数据库发出警告到登陆失效前的天数。如果数据库密码在这中间没有被修改，则过期会失效。 Password_verify_function：该字段允许将复杂的PL/SQL密码验证脚本做为参数传递到create profile语句。Oracle数据库提供了一个默认的脚本，但是自己可以创建自己的验证规则或使用第三方软件验证。 对Function名称，指定的是密码验证规则的名称，指定为Null则意味着不使用密码验证功能。如果为密码参数指定表达式，则该表达式可以是任意格式，除了数据库标量子查询。 示例 CREATE PROFILE my_profile LIMIT SESSIONS_PER_USER UNLIMITED #对用户的并发连接会话数不做限制 CPU_PER_SESSION UNLIMITED #对于连接到用户的每一个session的CPU时间的使用不做限制 CPU_PER_CALL 6000 #一次调用消耗的CPU时间不能超过60秒（不超过一分钟） CONNECT_TIME 60 #连接到用户的每次会话时间不能超过60分钟（不超过一个小时） LOGICAL_READS_PER_SESSION DEFAULT #一次会话使用的物理读与逻辑读数据块总量与DEFAULT profile中定义保持一致 LOGICAL_READS_PER_CALL 60000 #一次调用使用的物理读与逻辑读数据块总量不超过60000个数据块 COMPOSITE_LIMIT 6000000 #一次会话总的资源消耗不超过6000000个服务单元（service units） FAILED_LOGIN_ATTEMPTS 10 #帐户被锁定之前允许10次的错误尝试 PASSWORD_LIFE_TIME UNLIMITED #密码不过期 PASSWORD_REUSE_TIME UNLIMITED #密码重置时间不限制 PASSWORD_LOCK_TIME 1/24 #超过错误尝试次数后，用户将被锁定1小时 PASSWORD_GRACE_TIME 10 #当密码过期之后原密码还可以使用10天 PASSWORD_VERIFY_FUNCTION verify_function #使用密码复杂度校验函数verify_function对密码做检查 / profile后续操作 查看创建的profile select * from dba_profiles; 将profile文件分配给用户 SQL> alter user scott profile my_profile; SQL> select USERNAME,PROFILE from dba_users where USERNAME = 'scott'; SQL> alter user scott profile default; SQL> select USERNAME,PROFILE from dba_users where USERNAME = 'scott'; profile生效 PROFILE中有关密码的限制永远生效，不受限制。 PROFILE中有关资源的限制与resource_limit参数的设置有关，为TRUE时生效，为FALSE时(默认)无效。 用户密码过期问题 11g之前版本，默认用户没有密码过期限制，在Oracle 11g 中默认 profile 密码过期时间是180天。 select * from dba_profiles where profile='DEFAULT' and resource_name='PASSWORD_LIFE_TIME'; 过期的密码可用 alter user userXXX identified by xxx; 解决，可修改为和以前一样。 如果想设置密码不过期，可用管理员登陆，执行下面命令： ALTER PROFILE DEFAULT LIMIT PASSWORD_LIFE_TIME UNLIMITED; Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-24 10:27:09 "},"manage/30.解决ora-16597.html":{"url":"manage/30.解决ora-16597.html","title":"解决ora-16597","keywords":"","body":"解决ORA-16597: Data Guard broker detects two or more primaries. 今天用dg broker部署了一套1+3的dg。在做切换演练tyqxdg3-->iscdb1的时候，出现报错： 在操作节点报错如下: DGMGRL> SWITCHOVER TO iscdb1; Performing switchover NOW, please wait... Error: ORA-16597: Data Guard broker detects two or more primary databases Error: ORA-16625: cannot reach database \"iscdb1\" Failed. Unable to switchover, primary database is still \"iscdb1\" DGMGRL> 在tyqxdg3报错如下： DGMGRL> show configuration; Configuration - cfg_1 Protection Mode: MaxPerformance Databases: iscdb1 - Primary database tyqxdg1 - Physical standby database tyqxdg2 - Physical standby database tyqxdg3 - Physical standby database Fast-Start Failover: DISABLED Configuration Status: ORA-16597: Data Guard broker detects two or more primary databases ORA-16625: cannot reach database \"iscdb1\" DGM-17017: unable to determine configuration status 在iscdb1的节点报错如下： DGMGRL> show configuration; 配置 - cfg_1 保护模式: MaxPerformance 数据库: tyqxdg3 - 主数据库 iscdb1 - 物理备用数据库 tyqxdg1 - 物理备用数据库 tyqxdg2 - 物理备用数据库 快速启动故障转移: DISABLED 配置状态: ORA-16534: 正在执行切换, 故障转移或转换操作 DGM-17017: 无法确定配置状态 中间折腾了很久，最后检查了iscdb1的数据库的角色是primarydb,tyqxdg3的角色是pysical_standby 这个说明了什么？ 这个说明了切换其实是已经切换过去了，但是dg broker的相关信息有错误。 最后的解决办法是： 不去动在数据库上面dg的配置，将4套的dg_broker_start设置为false,然后删除broker的配置信息(broker_file指向的文件),再重新打开dg_broker_start=true,再重新配置一次,就搞定了. 注意: 1.一开始使用了dgbroker配置dg，那么不管是在主库还是从库执行alter system set xxx=xxx scope=spfile;都不会记录到spfile里面。但可以用dgmrl 里面的edit 修改参数。 2.show configuration 出现错误的时候，可以执行show database verbose 'dbname' 查看错误。需要注意的是在dgmgrl sys/oracle@pri和dgmgrl sys/oracle@std 两端看到的错误是不同的 3.如果看到Warning: ORA-16714: the value of property StandbyFileManagement isinconsistent with the database setting之类的错误，则修改edit database std set property StandbyFileManagement='auto'; Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-10 15:03:39 "},"manage/33.解决ora-29780.html":{"url":"manage/33.解决ora-29780.html","title":"解决ora-29780","keywords":"","body":"ORA-29780: unable to connect GPnP daemon [CLSGPNP_ERR] 安装完成 11GR2 Grid 之后，使用asmca创建磁盘组的时候遇到如下报错： Started getting following error ORA-29780: unable to connect to GPnP daemon [CLSGPNP_ERR] google 一把 和环境变量有关：(CRS/GRID 是运行正常的). grid@rac1 /oragrid/dbs> env | grep ORA GRID_HOME=/opt/11.2.0/grid $GRID_HOME变量必须和$ORACLE_HOME 保持一致,否则在使用asmca创建磁盘的时候 会认不到asm 磁盘! Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-10 14:58:27 "},"manage/解决ORA-00206.html":{"url":"manage/解决ORA-00206.html","title":"解决ora-00206","keywords":"","body":"问题及描述 环境为RAC 11.2.0.4 执行命令报错: SQL> ALTER DATABASE ADD STANDBY LOGFILE thread 1 group 9 '+ORADATA' SIZE 100M; ALTER DATABASE ADD STANDBY LOGFILE thread 1 group 9 '+ORADATA' SIZE 100M * ERROR at line 1: ORA-00204: error in reading (block 1, # blocks 1) of control file ORA-00202: control file: '+ORADATA/racdg/controlfile/control01.ctl' ORA-15081: failed to submit an I/O operation to a disk 在alert日志中有这样的报错: ORA-15025: could not open disk “/dev/mapper/asm5” ORA-27041: unable to open file Linux-x86_64 Error: 13: Permission denied Additional information: 3 经检查是 问题应该是权限问题，之前的所属的组是grid:asmadmin 改为grid:oinstall之后就好了 在每个节点上的ASM软件所有者具有适当的主要用户组，ASM OSASM，ASM OSDBA，ASM OSPER和数据库OSDBA组分配给他的。 ASM磁盘/设备设置了正确的权限和所有权。 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-02-19 16:43:37 "},"manage/19.ora-13516O-cannot-collect-awr.html":{"url":"manage/19.ora-13516O-cannot-collect-awr.html","title":"解决ora-13516 Oracle无法收集AWR","keywords":"","body":"手工给一个库做快照， begin dbms_workload_repository.create_snapshot; end; 发现报错ORA-13516 ERROR at line 1: ORA-13516: AWR Operation failed: only a subset of SQL can be issued ORA-06512: at \"SYS.DBMS_WORKLOAD_REPOSITORY\", line 174 ORA-06512: at \"SYS.DBMS_WORKLOAD_REPOSITORY\", line 222 ORA-06512: at line 1 保证错的意思是： SQL> !oerr ora 13516 13516, 00000, \"AWR Operation failed: %s\" // *Cause: The operation failed because AWR is not available. The // possible causes are: AWR schema not yet created; AWR // not enabled; AWR schema not initialized; or database // not open or is running in READONLY or STANDBY mode. // *Action: check the above conditions and retry the operation. 经检查是因为mmon进程不存在导致，问了下运维人员，原来是他们在停数据库的时候，使用的shutdown命令停，然后又嫌弃停的时候等待时间过长，所以就又cancel了。然后去查alert日志，证实了这一个说法。。 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-09-08 11:15:31 "},"manage/解决ORA-01105，ORA-01606.html":{"url":"manage/解决ORA-01105，ORA-01606.html","title":"解决ORA-01105，ORA-01606","keywords":"","body":"报错现象 今天在操作RAC某个节点重启，结果重启的时候报错: SQL> startup mount; ORACLE instance started. Total System Global Area 9.4869E+10 bytes Fixed Size 2264056 bytes Variable Size 5.0197E+10 bytes Database Buffers 4.4560E+10 bytes Redo Buffers 109174784 bytes ORA-01105: mount is incompatible with mounts by other instances ORA-01606: parameter not identical to that of another mounted instance 错误说明： $ oerr ora 1105 01105, 00000, \"mount is incompatible with mounts by other instances\" // *Cause: An attempt to mount the database discovered that another instance // mounted a database by the same name, but the mount is not // compatible. Additional errors are reported explaining why. // *Action: See accompanying errors. $ oerr ora 1606 01606, 00000, \"parameter not identical to that of another mounted instance\" // *Cause: A parameter was different on two instances. // *Action: Modify the initialization parameter and restart. 这个错误的意识是说：如果两个节点的参数不一致的话，有可能在启动到mount状态的时候，就会报错： ORA-01105，ORA-01606 解决办法 解决办法是查看初始化参数和隐藏参数在两个节点的值,看哪些不一致 参考隐藏参数 set linesize 333 col name for a35 col description for a66 col value for a30 SELECT i.ksppinm name, i.ksppdesc description, CV.ksppstvl VALUE FROM sys.x$ksppi i, sys.x$ksppcv CV WHERE i.inst_id = USERENV ('Instance') AND CV.inst_id = USERENV ('Instance') AND i.indx = CV.indx AND i.ksppinm LIKE '/_gc%' ESCAPE '/' ORDER BY REPLACE (i.ksppinm, '_', ''); 查看不同的参数 col name format a25 col value format a55 set lines 210 select * from (select name,value,inst_id from gv$parameter where inst_id=1) a full join (select name,value,inst_id from gv$parameter where inst_id=2) b on a.name = b.name where a.value <> b.value; 找到不一致的参数后，修改为两个节点一致，再重启其中报错的实例 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-02-26 16:31:13 "},"manage/37.表碎片分析.html":{"url":"manage/37.表碎片分析.html","title":"表碎片分析与整理","keywords":"","body":" Oracle中的shrink space 一、概述 在9i的时候，使用move进行碎片的整理 在10g的时候，使用shrink space进行碎片的整理 总结 二、使用shrink space整理过程 1.找出碎片率高的表(>50%) 2.开启行迁移 3.进行碎片整理 4.再根据实际情况关闭行迁移 注意事项 Oracle中的shrink space 一、概述 数据库在日常使用过程中，不断的insert，delete，update操作，导致表和索引出现碎片是在所难免的事情，碎片多了，sql的执行效率自然就差了，道理很简单，高水位线（HWL）下的许多数据块都是无数据的，但全表扫描的时候要扫描到高水位线的数据块，也就是说oracle要做许多的无用功！ 在9i的时候，使用move进行碎片的整理 alter table xxx move 高水位以下合并碎片，不移动高水位 alter table xxx move compress 高水位以下合并碎片，同时压缩表，不移动高水位。 缺点： 但是美中不足的是move不移动高水位，并且还要重建索引。 另外，在整个move过程表上TM上一直有6的锁，所以MOVE会影响业务。 在10g的时候，使用shrink space进行碎片的整理 shrink space碎片整理功能不仅能整理碎片还可以收缩高水位,索引也不需要重建 缺点： 在整个shrink space过程中，在迁移数据的时候，在表上获取3级别和6级别的锁。 总结 move不能降低高水位的原因是不能修改rowid，而 alter table shrink space 是可以修改rowid的 move表后index的状态是UNUSABLE的,需要进行rebuild shrink在移动行数据时，也一起维护了index上相应行的数据rowid的信息，当然shrink过程中用来维护index的成本也会比较高。 move使用中会一直有6的锁；shrink space分数据重组和HWM调整2个阶段,第一个阶段只会有3的锁,第二个阶段有6的锁 move+rebuild index效率要高，shrink时间太久，产生归档更多 二、使用shrink space整理过程 segment shrink分为两个阶段： 数据重组(compact):通过一系列insert、delete操作，将数据尽量排列在段的前面。在这个过程中需要在表上加RX锁，即只在需要移动的行上加锁。由于涉及到rowid的改变，需要enable row movement.同时要disable基于rowid的trigger.这一过程对业务影响比较小。 HWM调整：第二阶段是调整HWM位置，释放空闲数据块。此过程需要在表上加X锁，会造成表上的所有DML语句阻塞。在业务特别繁忙的系统上可能造成比较大的影响。 1.找出碎片率高的表(>50%) 主要思路 SELECT table_name, ROUND((blocks * 8/1024), 2) \"高水位空间 M\", ROUND((num_rows * avg_row_len / 1024/1024), 2) \"真实使用空间 M\", ROUND((blocks * 10 / 100) * 8, 2) \"预留空间(pctfree) M\", ROUND((blocks * 8 - (num_rows * avg_row_len / 1024) -blocks * 8 * 10 / 100), 2) \"浪费空间 M\", ((blocks * 8-(num_rows * avg_row_len / 1024))/1024)/(blocks * 8/1024) \"浪费空间 %\" FROM user_tables WHERE table_name = 'table_name'; 在高水位和真实使用的空间之间的差距=浪费空间，而产生浪费空间的原因是高水位的上涨，真实使用的空间变小（大量的delete）而造成的，而这样也会产生大量的碎片。浪费空间 %大于25就需要整理了。 如果以上没有结果,可能是表没有统计信息,可以先收集表的统计信息 这个分析很耗时间可以设定estimate_percent来调整分析的量: exec dbms_stats.gather_table_stats(user,'table_name',CASCADE=>TRUE); 生产环境可以使用下面的语句一次性查出需要做碎片整理的表： col OWNER for a10; col TABLE_NAME for a20; select * from (select t.owner owner, t.table_name table_name, trunc(s.blocks*ts.block_size/1024/1024*1000)/1000 ssize, TRUNC((num_rows*avg_row_len)*1000/((100-pct_free-5)/100)/1024/1024)/1000 est_size, trunc((s.blocks*ts.block_size)/((num_rows*avg_row_len)/((100-pct_free-5)/100))*100)/100 sp, last_analyzed, num_rows, avg_row_len, pct_free, s.blocks from dba_tables t, (SELECT owner,segment_name,sum(blocks) blocks from dba_segments where owner not in ('SYS','OUTLN','SYSTEM','MGMT_VIEW','SYSMAN','DBSNMP','WMSYS','XDB', 'DIP','GOLDENGATE','CTXSYS' ) group by owner ,segment_name )S, dba_tablespaces ts where t.tablespace_name=ts.tablespace_name and t.owner=s.owner and t.table_name=s.segment_name and t.num_rows*avg_row_len >0 and t.owner not in ('SYS','OUTLN','SYSTEM','MGMT_VIEW','SYSMAN','DBSNMP','WMSYS','XDB', 'DIP','GOLDENGATE','CTXSYS' ) and S.blocks>200 and t.last_analyzed is not null) where sp >=50 order by 3; 2.开启行迁移 alter table table_name enable row movement; 3.进行碎片整理 alter table table_name shrink space cascade; # 加cascade可以连带重建索引 连同索引一起压缩，比move方便。 4.再根据实际情况关闭行迁移 alter table table_name disable row movement; 注意事项 开启/关闭行迁移的两个命令都会使表相关联的对象变为无效，操作结束后别忘记重新编译,以防万一，虽然程序下次运行的时候会自动编译，但总是会担心，还是编译掉，确认对象都是有效的比较OK. shrink space compact只执行第一个阶段。 如果系统业务比较繁忙，可以先执行shrink space compact重组数据,然后在业务不忙的时候再执行shrink space降低HWM释放空闲数据块。 shrink必须开启行迁移功能 在表上建有函数索引（包括全文索引）shrink space会失败 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-14 15:51:47 "},"manage/38.索引碎片分析.html":{"url":"manage/38.索引碎片分析.html","title":"索引碎片分析与整理","keywords":"","body":" 索引重建的方法和注意事项 以下情况需要重建索引 重建索引的方法 方法1：drop + create 方法2：alter index rebuild 方法3：alter index rebuild online 3种方法的总结 相关查询语句 查询索引碎片>50%的语句 查询索引高度>3 注意事项与总结 参考文档 索引重建的方法和注意事项 以下情况需要重建索引 索引或索引分区因为介质故障损坏，例如索引所在表空间数据文件被误删除。 索引试图中STATUS列标记为UNUSABLE 索引对应基表move到新表空间 索引计划迁移到新表空间 修改索引的某些存储参数 索引高度>3或者>4 索引的碎片化>75% 重建索引的方法 重新创建 drop index index_name; create index index_name; alter index index_name rebuild; alter index index_name rebuild online; 方法1：drop + create 在create index语句执行过程中会话一直持有TM锁 Imode=4，阻塞了其他会话增删改等DML语句，直到索引创建完成 。 方法2：alter index rebuild When you rebuild an index, you use an existing index as the data source. Creating an index in this manner enables you to change storage characteristics or move to a new tablespace. Rebuilding an index based on an existing data source removes intra-block fragmentation. Compared to dropping the index and using the CREATE INDEX statement, rebuilding an existing index offers better performance. 上面的官方文档很明确的说明了rebuild的原理，以原有索引作为基础进行重新创建（可以通过10046确认），且性能要好于drop然后重新create步骤。 rebuild要持有相关锁，若表有未提交的事务，会报错，因此rebuild前请保证没有相关事务。 rebuild语句执行过程会话一直持有TM锁Imode=4，阻塞其他会话增删改等DML操作。 rebuild还有一个值得关注的地方就是空间问题，Oracle在创建新索引过程中，并不会删除旧索引，直至新索引rebuild成功。 rebuild过程，若查询操作能用到旧索引依然会用旧索引，查询效率不会因rebuild而降低。 rebuild方式创建索引过程需要额外的空闲空间，额外空间的大小基本为旧索引大小，rebuild成功后，rebuild过程占用的额外空间将会被释放。 方法3：alter index rebuild online You have the option of rebuilding the index online. Rebuilding online enables you to update base tables at the same time that you are rebuilding. The following statement rebuilds the emp_name index online rebuild online执行过程中基表可以进行增删改等DML操作，在线rebuild可以保证了业务连续性，比rebuild要高级一些。 rebuild online索引重建过程也需要额外的空闲空间，另外rebuild online过程中旧索引依然可用。 和rebuild不同的一点rebuild online以基表作为基础进行重新创建（可以通过10046确认），因此相对rebuild会慢一些。 在rebuild online过程中，oracle会自动维护一日志(journal)表,通过锁以及dba_objects视图的相关信息可以跟踪到该表。 由于要额外维护一张日志表，那么如果在rebuild online过程中，基表发生了大量的增删改操作，整个rebuild online重建索引过程就会异常的慢。 另外还有一个特别重要的说明一下：虽然rebuild index online在执行期间不会阻塞DML操作，但在开始和结束阶段，需要请求模式为4的TM锁。如果在rebuild index online开始前或结束时，有其它长时间的事务在运行会阻塞 3种方法的总结 drop-->create index,alter index rebulid会阻塞基表的增删改DML操作，alter index rebuild online不会阻塞，保证在线重新创建。 alter index rebulid以及rebuild online重建过程要求有额外的空闲空间，drop-->create index无此要求。 一般情况下rebuild速度最快，针对rebuild online请保证重建开始前与结束前无相关事务，否则会rebuild online会一直处于等待状态。 上述三种重建索引方法各有利弊，在实际生产环境中具体采用哪种方法请结合具体情况酌情处理。 创建索引的语句可以考虑加并行和nologging 相关查询语句 查询索引碎片>50%的语句 col owner format a15; col table_name format a30; col index_name format a30; select idx.owner owner, idx.table_name tablename, idx.index_name index_name, idx.blocks idx_blocks, tbl.blocks tbl_blocks, trunc(idx.blocks/tbl.blocks*100)/100 pct from (select i.owner owner ,i.index_name index_name,SUM(S1.blocks) blocks,i.table_owner table_owner, i.table_name table_name from dba_segments s1,dba_indexes i where s1.owner=i.owner and s1.segment_name=i.index_name and i.owner not in ('SYS','OUTLN','SYSTEM','MGMT_VIEW','SYSMAN','DBSNMP','WMSYS','XDB', 'DIP','GOLDENGATE','CTXSYS' ) GROUP BY i.owner ,i.index_name ,i.table_owner , i.table_name ) idx, (select t.owner owner ,t.table_name table_name,SUM(s2.blocks) blocks from dba_segments s2,dba_tables t where s2.owner=t.owner and s2.segment_name=t.table_name and t.owner not in ('SYS','OUTLN','SYSTEM','MGMT_VIEW','SYSMAN','DBSNMP','WMSYS','XDB', 'DIP','GOLDENGATE','CTXSYS' ) GROUP BY T.OWNER,T.TABLE_NAME ) tbl where idx.table_owner=tbl.owner and idx.table_name=tbl.table_name and (idx.blocks/tbl.blocks)>0.5 and idx.blocks>200 order by 4; 查询索引高度>3 select owner,index_name,table_owner,table_name,BLEVEL from dba_indexes where blevel > 3; 注意事项与总结 生产系统执行任何操作时，需要明确如下几点： 是不是业务时间（或业务高峰期），如果是，则尽量不要进行类此操作。因为在大对象中创建索引时不仅需要较大temp表空间，而且基于表原有索引的所有SQL语句的执行计划都发生变化。这样，这些SQL的重新解释需要大量CPU资源。 当原来索引被删除后，出现大量的全表扫描。这不仅对系统I/O产生压力，而且buffer catch中的已缓存数据块很容易被挤出去，不仅对SGA带来压力，而且对I/O产生恶性循环。 综合CPU、内存、I/O方面资源紧张，在加上正常业务办理需要的各类DML操作，可能导致row lock contention、read by other session等一堆等待，最终系统被出现无法办理业务的等待（系统慢）状态。 因此在进行重建或创建所以之前，很有必要充分考虑生产环境、数据库对象的大小和用途、temp表空间大小，硬件资源、回退方案等等。 注:rebuild和rebuild online的区别 当rebuild 时一般对原先索引进行INDEX FAST FULL SCAN。 当rebuild online的时不用原先索引而执行TABLE ACCESS FULL rebuild和rebuild online都会发生sort，即需要用到temp表空间。 rebuild 会阻塞dml语句而rebuild online则不会。 rebuild online时系统会产生一个SYS_JOURNAL_xxx的IOT类型的系统临时日志表，所有rebuild online时索引的变化都记录在这个表中，当新的索引创建完成后，把这个表的记录维护到新的索引中去，然后drop掉旧的索引，rebuild online就完成了。 参考文档 [1]参考官方文档: Managing Indexes [2]参考metalink Note:272762.1 ======== - Online Index rebuild takes a long time. - ONLINE INDEX REBUILD SCANS THE BASE TABLE AND NOT THE INDEX Symptoms: ========= Performance issues while rebuilding very large indexes. - The offline rebuilds of their index is relatively quick -finishes in 15 minutes. - Issuing index rebuild ONLINE statement => finishes in about an hour. - This behavior of ONLINE index rebuilds makes it a non-option for large tables as it just takes too long to scan the table to rebuild the index. The offline may not be feasible due to due to the 24/7 nature of the database. - This may be a loss of functionality for such situations. - If we attempt to simultaneously ONLINE rebuild the same indexes we may encounter hanging behavior indefinitely (or more than 6 hours). DIAGNOSTICANALYSIS: -------------------- We can trace the sessions rebuilding the indexes with 10046 level 12. Comparing the IO reads for the index-rebuild and the index-rebuild-onlinereveals the following: -ONLINE indexrebuilds It scans thebase table and it doesn't scan the blocks of the index. -OFFLINE index rebuilds It scans the index for the build operation. - This behaviour is across all versions. Cause Cause/Explanation ============= When you rebuild index online, - it will do a full tablescan on thebase table. - At the same time it will maintaina journal table for DML data, which has changed during this index rebuildingoperation. So it shouldtake longer time, specially if you do lots of DML on the same table,whilerebuilding index online. On the other hand, while rebuilding the index without online option, Oraclewill grab the index in X-mode and rebuild a new index segment by selecting thedata from the old index. So here we are - not allowing any DML on the table hence there is nojournal table involved - and it is doing an index scan Hence it will be pretty fast. Fix Solution/Conclusion: =========== - The ONLINE index rebuild reads the base table, and this is by design. - Rebuilding index ONLINE is pretty slow. - Rebuilding index offline is very fast, but it prevents any DML on the basetable. Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-24 10:27:19 "},"manage/query-yincang-parameter.html":{"url":"manage/query-yincang-parameter.html","title":"查看隐藏参数","keywords":"","body":"查看隐藏参数 SELECT a.ksppinm \"Parameter\", decode(p.isses_modifiable,'FALSE',NULL,NULL,NULL,b.ksppstvl) \"Session\", c.ksppstvl \"Instance\", decode(p.isses_modifiable,'FALSE','F','TRUE','T') \"S\", decode(p.issys_modifiable,'FALSE','F','TRUE','T','IMMEDIATE','I','DEFERRED','D') \"I\", decode(p.isdefault,'FALSE','F','TRUE','T') \"D\", a.ksppdesc \"Description\" FROM x$ksppi a, x$ksppcv b, x$ksppsv c, v$parameter p WHERE a.indx = b.indx AND a.indx = c.indx AND p.name(+) = a.ksppinm AND UPPER(a.ksppinm) LIKE UPPER('_MV_REFRESH_USE_STATS') ORDER BY a.ksppinm; Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-30 13:16:51 "},"tunning/15.intro-xxxps.html":{"url":"tunning/15.intro-xxxps.html","title":"XXXPS的概念","keywords":"","body":"各种XXPS概念说明 基本概念 QPS 每秒处理的查询数 TPS 每秒处理的事务数，这是一个系统的处理能力的，最直接指标，一般的基准测试，都会重点测试这个指标。 IOPS 每秒磁盘进行的I/O操作次数,是指单位时间内系统能处理的I/O请求数量，I/O请求通常为读或写数据操作请求。随机读写频繁的应用，如OLTP，IOPS是关键衡量指标。 数据吞吐量(Throughput) 单位时间内可以成功传输的数据数量。对于大量顺序读写的应用，如VOD(Video On Demand)，则更关注吞吐量指标。 机械磁盘IOPS的计算 磁盘完成一个I/O请求所花费的时间，它由寻道时间、旋转延迟和数据传输时间三部分构成。 寻道时间Tseek 指将读写磁头移动至正确的磁道上所需要的时间。寻道时间越短，I/O操作越快，目前磁盘的平均寻道时间一般在3－15ms。 旋转延迟Trotation 指盘片旋转将请求数据所在扇区移至读写磁头下方所需要的时间。旋转延迟取决于磁盘转速，通常使用磁盘旋转一周所需时间的1/2表示。比如，7200 rpm的磁盘平均旋转延迟大约为60*1000/7200/2 = 4.17ms，而转速为15000 rpm的磁盘其平均旋转延迟约为2ms。 数据传输时间Ttransfer 是指完成传输所请求的数据所需要的时间，它取决于数据传输率，其值等于数据大小除以数据传输率。目前IDE/ATA能达到133MB/s，SATA II可达到300MB/s的接口数据传输率，数据传输时间通常远小于前两部分时间。 因此，理论上可以计算出磁盘的平均最大IOPS，即IOPS = 1000 ms/ (Tseek + Troatation)，忽略数据传输时间。假设磁盘平均物理寻道时间为3ms, 磁盘转速为7200,10K,15K rpm，则磁盘IOPS理论最大值分别为， IOPS = 1000 / (3 + 60000/7200/2) = 140 IOPS = 1000 / (3 + 60000/10000/2) = 167 IOPS = 1000 / (3 + 60000/15000/2) = 200 SSD磁盘的IOPS 固态硬盘SSD是一种电子装置， 避免了传统磁盘在寻道和旋转上的时间花费，存储单元寻址开销大大降低，因此IOPS可以非常高，能够达到数万甚至数十万。实际测量中，IOPS数值会受到很多因素的影响，包括I/O负载特征(读写比例，顺序和随机，工作线程数，队列深度，数据记录大小)、系统配置、操作系统、磁盘驱动等等。 因此对比测量磁盘IOPS时，必须在同样的测试基准下进行，即便如何也会产生一定的随机不确定性。通常情况下，IOPS可细分为如下几个指标： Toatal IOPS，混合读写和顺序随机I/O负载情况下的磁盘IOPS，这个与实际I/O情况最为相符，大多数应用关注此指标。 Random Read IOPS，100%随机读负载情况下的IOPS。 Random Write IOPS，100%随机写负载情况下的IOPS。 Sequential Read IOPS，100%顺序负载读情况下的IOPS。 Sequential Write IOPS，100%顺序写负载情况下的IOPS。 IOPS的测试 IOPS的测试benchmark工具主要有Iometer, IoZone, FIO等，可以综合用于测试磁盘在不同情形下的IOPS。对于应用系统，需要首先确定数据的负载特征，然后选择合理的IOPS指标进行测量和对比分析，据此选择合适的存储介质和软件系统。下面的磁盘IOPS数据来自 http://en.wikipedia.org/wiki/IOPS ，给大家一个基本参考。 MySQL的XXPS计算 MySQL中的QPS计算 show global status where Variable_name in('com_select','com_insert','com_delete','com_update'); 等待10秒 show global status where Variable_name in('com_select','com_insert','com_delete','com_update'); 计算差值 MySQL的TPS计算 show global status where Variable_name in('com_insert','com_delete','com_update'); 等待10秒 show global status where Variable_name in('com_insert','com_delete','com_update'); 计算差值 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-02 14:00:34 "},"zaqizaba/21.install-rzsz.html":{"url":"zaqizaba/21.install-rzsz.html","title":"rzsz工具安装","keywords":"","body":"源码安装 wget http://www.ohse.de/uwe/releases/lrzsz-0.12.20.tar.gz tar zxvf lrzsz-0.12.20.tar.gz cd lrzsz-0.12.20 ./configure && make && make install 安装过程默认把lsz和lrz安装到了/usr/local/bin/目录下,再做一次软链接 cd /usr/bin ln -s /usr/local/bin/lrz rz ln -s /usr/local/bin/lsz sz yum安装 yum install -y lrzsz Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-07-26 09:46:35 "},"zaqizaba/22.ssh-copy-id-using-not22port.html":{"url":"zaqizaba/22.ssh-copy-id-using-not22port.html","title":"ssh-copy-id使用非22端口","keywords":"","body":"yum -y install openssh-clients ssh-copy-id -i ~/.ssh/id_rsa.pub user@server 再也不用记如何拼写authorized_keys这个文件名了，是不是很爽，可惜别高兴太早了，ssh-copy-id有一个很要命的问题，那就是缺省它仅仅支持SSH运行在22端口的情况，不过实际上出于安全的需要，我们往往都会更改服务器的SSH端口，比如说改成10022端口，这时候你运行ssh-copy-id就会报错了，直接修改ssh-copy-id脚本当然可以修正这个问题，但是那样显得太生硬了，实际上还有更好的办法： vi ~/.ssh/config 加上内容： Host server Hostname ip Port 10022 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-24 10:27:46 "},"qms数据库整改.html":{"url":"qms数据库整改.html","title":"qms数据库整改","keywords":"","body":"调整顺序 这个地方特别需要强调一下操作的步骤，先做需要重启的操作： 调整数据库实例1的参数 关闭数据库实例1，再调整asm的参数 重启节点1的asm，重启节点1的实例 在没有问题的情况下，再在第2个节点重复上面的操作 以上均没有问题后，再修改操作系统的huge page的参数，方法也是一个节点修改完启动好之后再修改第二个节点 主要注意amm与huge page的问题 一、操作系统 1.设置huge_page 修改/etc/sysctl.conf 中vm.nr_hugepages为（64*1024）/2=32768 修改完成后重启数据库实例，执行 grep Huge /proc/meminfo 查看hugepage是否生效 2.节点1启动ntp服务 配置同节点2的/etc/ntp.conf文件，配置完成后启动ntpd服务service ntpd start，并加入重启自动启动check ntpd on 3.配置历史命令保存与记录时间 编辑/etc/profile 文件，加入如下三行： export HISTFILESIZE=1000 export HISTSIZE=1000 export HISTTIMEFORMAT=%Y-%m-%d:%H-%M-%S 保存后,再 source /etc/profile 二、asm实例 1.增大asm实例的memory_target # su - grid $ sqlplus / as sysasm SQL> create pfile='/tmp/lmpfile.ora' from spfile; SQL> alter system set memory_max_target=2G scope=spfile sid='+ASM1'; SQL> alter system set memory_target=2G scope=spfile sid='+ASM1'; 重启实例 再第二个节点执行同样操作 SQL> alter system set memory_max_target=2G scope=spfile sid='+ASM2'; SQL> alter system set memory_target=2G scope=spfile sid='+ASM2'; 三、数据库方面 0.每做一次需要修改系统参数的操作时都先备份spfile create pfile='/home/oracle/pfile.bak' from spfile; 1.关闭DRM 注意，最好是一个节点一个节点进行操作 # su - oracle SQL> alter system set “_gc_undo_affinity”=FALSE sid='xxx1' scope=spfile; SQL> alter system set “_gc_policy_time”=0 sid='xxx1' scope=spfile; 注意，如果两个节点的参数不一致的话，有可能在启动到mount状态的时候，就会报错： ORA-01105，ORA-01606 解决办法是查看初始化参数和隐藏参数在两个节点的值,看哪些不一致 参考隐藏参数 set linesize 333 col name for a35 col description for a66 col value for a30 SELECT i.ksppinm name, i.ksppdesc description, CV.ksppstvl VALUE FROM sys.x$ksppi i, sys.x$ksppcv CV WHERE i.inst_id = USERENV ('Instance') AND CV.inst_id = USERENV ('Instance') AND i.indx = CV.indx AND i.ksppinm LIKE '/_gc%' ESCAPE '/' ORDER BY REPLACE (i.ksppinm, '_', ''); 查看不同的参数 col name format a25 col value format a55 set lines 210 select * from (select name,value,inst_id from gv$parameter where inst_id=1) a full join (select name,value,inst_id from gv$parameter where inst_id=2) b on a.name = b.name where a.value <> b.value; 2.调整redo大小 查询redo的相关信息 select * from gv$log ; select * from gv$logfile ; alter system switch logfile; 如果有adg,还需要注意standby redo log是否需要调整. 添加 redo log: alter database add logfile thread 1 group xxxxx('+磁盘组的名字','+磁盘组的名字') size 500M; ... alter database add logfile thread 1 group xxxxx('+磁盘组的名字','+磁盘组的名字') size 500M; alter database add logfile thread 2 group xxxxx('+磁盘组的名字','+磁盘组的名字') size 500M; ... alter database add logfile thread 2 group xxxxx('+磁盘组的名字','+磁盘组的名字') size 500M; 切换 alter system switch logfile; 或者 alter system archive log current ; alter system checkpoint 删除以前的redo log alter database drop logfile group XXX; ` 3.高资源消耗表记录有55个 需要与业务结合起来看，根据列出的资源对象，如果是表，则查看其对应的SQL的执行计划是否合理。 4.表并行度 以下几个需要注意，最好是停业务，或者业务不繁忙的时候操作，因为涉及到表和索引的碎片整理等 查询 select owner,table_name,degree from dba_tables where degree>1; 需要与业务人员沟通,看这几个表是做什么，再来判断是否需要关闭并行 5.索引并行度与高度分析 查询高度>3的索引 select owner,index_name,table_owner,table_name,BLEVEL from dba_indexes where blevel > 3; 对这些索引进行重建（rebuild） alter index index_name rebuild; ## 能停业务,可以用它 alter index index_name rebuild online; ##支持dml,但是会有更多的锁 6.表碎片率大于50%的数量有2个记录 通过shrink space来调整以上表的碎片。 alter table table_name enable row movement; ##shrink space前,先开启行迁移 alter table table_name shrink space; 再根据实际情况关闭行迁移 alter table table_name disable row movement; 7.碎片率大于50%的数量记录 col owner format a15; col table_name format a30; col index_name format a30; select idx.owner owner, idx.table_name tablename, idx.index_name index_name, idx.blocks idx_blocks, tbl.blocks tbl_blocks, trunc(idx.blocks/tbl.blocks*100)/100 pct from (select i.owner owner ,i.index_name index_name,SUM(S1.blocks) blocks,i.table_owner table_owner, i.table_name table_name from dba_segments s1,dba_indexes i where s1.owner=i.owner and s1.segment_name=i.index_name and i.owner not in ('SYS','OUTLN','SYSTEM','MGMT_VIEW','SYSMAN','DBSNMP','WMSYS','XDB', 'DIP','GOLDENGATE','CTXSYS' ) GROUP BY i.owner ,i.index_name ,i.table_owner , i.table_name ) idx, (select t.owner owner ,t.table_name table_name,SUM(s2.blocks) blocks from dba_segments s2,dba_tables t where s2.owner=t.owner and s2.segment_name=t.table_name and t.owner not in ('SYS','OUTLN','SYSTEM','MGMT_VIEW','SYSMAN','DBSNMP','WMSYS','XDB', 'DIP','GOLDENGATE','CTXSYS' ) GROUP BY T.OWNER,T.TABLE_NAME ) tbl where idx.table_owner=tbl.owner and idx.table_name=tbl.table_name and (idx.blocks/tbl.blocks)>0.5 and idx.blocks>200 order by 4; 对这些索引进行重建（rebuild） alter index index_name rebuild; ## 能停业务,可以用它 alter index index_name rebuild online; ##支持dml,但是会有更多的锁 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-03-01 10:11:38 "}}